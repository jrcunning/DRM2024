---
title: "DRM bleaching analysis"
author: "R. Cunning"
date: "2024-12-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE)
```

```{r libraries}
# Load libraries
library(sf)
library(sp)
library(gstat)
library(lme4)
library(emmeans)
library(terra)
library(tidyterra)
library(drc)
library(tidyverse)
```

```{r labellers, include = FALSE}
# Create species labeller
species_names <- c(
  AAGA = "Agaricia agaricites",
  AFRA = "Agaricia fragilis",
  AGAR = "Agaricia sp.",
  AGRA = "Agaricia grahamae",
  AHUM = "Agaricia humilis",
  ALAM = "Agaricia lamarcki",
  ACER = "Acropora cervicornis",
  AGAR = "Agaricia sp.",
  APAL = "Acropora palmata",
  APRO = "Acropora prolifera",
  CNAT = "Colpophyllia natans",
  DCYL = "Dendrogyra cylindrus",
  DLAB = "Diploria labyrinthiformis",
  DSTO = "Dichocoenia stokesii",
  EFAS = "Eusmilia fastigiata",
  FFRA = "Favia fragum",
  HCUC = "Helioseris cucullata",
  ISIN = "Isophyllia sinuosa",
  IRIG = "Isophyllia rigida",
  ISOP = "Isophyllia sp.",
  MADR = "Madracis sp.",
  MANG = "Mussa angulosa",
  MARE = "Manicina areolata",
  MAUR = "Madriacis auretenra",
  MCAV = "Montastraea cavernosa",
  MDEC = "Madracis decactis",
  MFER = "Mycetophyllia ferox",
  MALI = "Mycetophyllia aliciae",
  MLAM = "Mycetophyllia lamarckiana",
  MFOR = "Madracis formosa",
  MJAC = "Meandrina jacksoni",
  MMEA = "Meandrina meandrites",
  MSEN = "Madracis senaria",
  MYCE = "Mycetophyllia sp.",
  OANN = "Orbicella annularis",
  OCUL = "Oculina sp.",
  ODIF = "Oculina diffusa",
  OFAV = "Orbicella faveolata",
  OFRA = "Orbicella franksi",
  ORBI = "Orbicella sp.",
  PAST = "Porites astreoides",
  PBRA = "Porites branneri",
  PCLI = "Pseudodiploria clivosa",
  PDIV = "Porites divaricata",
  PFUR = "Porites furcata",
  PORI = "Porites sp.",
  PPOR = "Porites porites",
  PSTR = "Pseudodiploria strigosa",
  SBOU = "Solenastrea bournoni",
  SCOL = "Scolymia sp.",
  SHYA = "Solenastrea hyades",
  SIDE = "Siderastrea sp.",
  SINT = "Stephanocoenia intersepta",
  SOLE = "Solenastrea sp.",
  SRAD = "Siderastrea radians",
  SSID = "Siderastrea siderea",
  UNKN = "Unknown"
)

species_names_2l <- gsub(" ", "\n", species_names)
abbrev_names <- as_tibble(species_names) %>%
  separate(value, into = c("genus", "species"), sep = " ") %>%
  mutate(genus = case_when(species == "sp." ~ genus,
                           species != "sp." ~ gsub("[a-z]+", ".", genus))) %>%
  unite(genus, species, col = "name", sep = " ")
abbrev_names <- c(abbrev_names$name)
names(abbrev_names) <- names(species_names)
```

# Import data

## DRM and DHW data (2014, 2015, 2023)
```{r import_data}
# Load all QC'd data from 2014, 2015, and 2023
load("data/processed/2014.RData")
load("data/processed/2015.RData")
load("data/processed/2023.RData")
df23 <- df23 %>% rename(Depth = EndDepth, Transect = TransectNum)

# Combine all years
all0 <- bind_rows(
  `2014` = df14,
  `2015` = df15,
  `2023` = df23,
  .id = "year"
) %>%
  mutate(dhw.bin = cut(dhw, breaks = c(-1, 3, 6, 9, 12, 15, 18, 22)))

# Count number of sites per subregion per year
nsites <- all0 %>%
  distinct(year, Subregion, Site) %>%
  count(year, Subregion) %>%
  pivot_wider(names_from = year, values_from = n)

# Combine North and South Palm Beach subregions due to low survey numbers
all0 <- all0 %>%
  mutate(Subregion = case_when(Subregion %in% c("North Palm Beach", "South Palm Beach") ~ "Palm Beach",
                               TRUE ~ Subregion))

# Reorder subregion factor levels from north to south
all0 <- all0 %>%
  mutate(Subregion = factor(Subregion, levels = c("Martin", "Palm Beach", "Broward-Miami",
                                                  "Biscayne", "Upper Keys", "Mid-Upper Keys Transition",
                                                  "Middle Keys", "Lower Keys", "Marquesas",
                                                  "Tortugas--Dry Tortugas NP")))

df23 <- all0 %>% filter(year == 2023)

# Plot sites surveyed in each year
all0 %>%
  distinct(year, Subregion, Latitude, Longitude, Site) %>%
  ggplot(aes(x = Longitude, y = Latitude, color = Subregion)) +
  geom_point() +
  facet_wrap(~year)

# Number of corals surveyed each year
all0 %>% count(year)
```

## Symbiont metadata for Florida corals
```{r import_sym_data}
# Import symbiont metadata
sym0 <- read_csv("data/FL_coral_symbiont_genera.csv")

# Summarize symbiont data (get all genera detected in each spp in Florida)
symsumm <- sym0 %>% 
  filter(location == "FL") %>%
  group_by(Species) %>%
  summarize(domsyms = paste0(unique(dominant_genus), collapse = "")) %>%
  mutate(ngen = nchar(domsyms))

# Aggregate symbiont metadata to match coral taxa to match aggregation in DRM dataset
symsumm.ag <- sym0  %>%
  filter(location == "FL") %>%
  mutate(Species = case_when(Species %in% c("AFRA", "AGAR", "AGRA", "AHUM", "ALAM") ~ "AGAR",
                             Species %in% c("MALI", "MLAM", "MYCE", "MFER") ~ "MYCE",
                             Species %in% c("IRIG", "ISIN", "ISOP") ~ "ISOP",
                             Species %in% c("OCUL", "ODIF") ~ "OCUL",
                             Species %in% c("SHYA", "SBOU") ~ "SOLE",
                             Species %in% c("SCOL", "SCUB", "SLAC", "SWEL") ~ "SCOL",
                             Species %in% c("OFAV", "OFRA", "OANN") ~ "ORBI",
                             TRUE ~ Species)) %>%
  drop_na(Species) %>% 
  group_by(Species) %>%
  summarize(domsyms = paste0(unique(dominant_genus), collapse = "")) %>%
  # No data available for AGAR (Agaricia spp. other other AAGA), so assuming these also have C and D (same as AAGA)
  add_row(Species = "AGAR", domsyms = "CD") %>%
  mutate(ngen = nchar(domsyms)) %>%
  mutate(D = grepl("D", domsyms)) 
```

```{r surveys_by_dhw}
# Plot surveys vs. DHW
(surveys.by.dhw <- all0 %>%
  distinct(year, Site, Date, Subregion, dhw) %>%
  ggplot(aes(x = dhw, fill = Subregion)) +
  geom_histogram(breaks = seq(0,22,1)) +
  facet_grid(year ~ ., scales = "free") +
  theme_classic() +
  labs(x = "Degree Heating Weeks", y = "Number of surveys"))

ggsave(filename = "figures/FigS1.png", plot = surveys.by.dhw, width = 183, height = 90, units = "mm")

# (surveys.by.date <- all0 %>%
#   distinct(year, Site, Date, Subregion, dhw) %>%
#   ggplot(aes(x = Date, fill = Subregion)) +
#   geom_histogram() +
#   facet_wrap(~year, ncol = 1, scales = "free") +
#   theme_classic() +
#   labs(x = "Degree Heating Weeks", y = "Number of surveys"))
```

# Bleaching severity 2023

## Map bleaching (all corals)
```{r map_bleaching}
# Get percent of colonies surveyed that were bleached at each site 
pctbl23 <- df23 %>%
  group_by(Site, Subregion, Latitude, Longitude, Week2) %>%
  summarize(BL = sum(Bleaching2 > 1),
            NB = sum(Bleaching2 <= 1),
            pctbl = BL / (BL + NB)) %>%
  ungroup()

pctbl23 <- pctbl23 %>%
  mutate(n = BL + NB)

# Model proportion of bleached colonies in each subregion in each 2-week window of survey
mod <- glm(cbind(BL, NB) ~ Subregion + Week2, family = "binomial", data = pctbl23)
#mod2 <- glm(cbind(BL, NB) ~ Week2, family = "binomial", data = pctbl23)

# Predict proportion of bleached colonies in each Subregion at weeks 34-35 (Week2 = "(33,35]" => (August 20-September 2))) = peak of bleaching
## Get these Subregion probabilities at this time on the log-odds scale (NOT type = 'response')
res <- emmeans(mod, specs = c("Subregion"), at = list(Week2 = factor("(33,35]")))

# Get residuals for each Site at the time it was surveyed (e.g., difference from Subregion mean at time surveyed)...
# ...and then add these residuals to the Subregion's predicted bleaching probability for Weeks 34-35 (peak of bleaching)
# ...to get predicted bleaching severity at that site, if it had been surveyed at peak of bleaching
pctbl23.adj <- pctbl23 %>%
  # Get residuals on the 'working' /logit scale
  mutate(resid = residuals(mod, type = "working")) %>%
  # Join site residuals with logit means for Subregion at weeks 34-35
  left_join(as_tibble(res)) %>%
  # Add residuals to logit mean for Subregion weeks 34-35, then convert to probability scale
  mutate(adj = emmean + resid,
         ## Function to convert logit to probability
         adjprob = exp(adj) / (1 + exp(adj)))

# Plot adjusted bleaching probabilities by subregion
ggplot(pctbl23.adj, aes(x = Subregion, y = adjprob)) +
  geom_violin() +
  geom_jitter(width = 0.15, height = 0)

# Get median adjusted bleaching prevalence by subregion
pctbl23.adj %>%
  group_by(Subregion) %>%
  summarize(medpctbl23.adj = median(adjprob))

# Summarize bleaching prevalence for north (miami up) and south (biscayne to drto) regions
# # Get confidence intervals on site-level bleaching prevalence by subregion and for all keys/drto
pctbl23.adj <- pctbl23.adj %>%
  mutate(region = case_when(Subregion %in% c("Martin", "Palm Beach", "Broward-Miami") ~ "north",
                              TRUE ~ "south"))
north <- filter(pctbl23.adj, region == "north") %>% pull(adjprob)
south <- filter(pctbl23.adj, region == "south") %>% pull(adjprob)

ggplot(pctbl23.adj, aes(x = region, y = adjprob)) + geom_violin()
#ggplot(pctbl23.adj, aes(x = region, y = pctbl)) + geom_violin()

# Test if bleaching prevalence data are normally distributed
shapiro.test(north) # not normal
shapiro.test(south) # not normal

median(north)
quantile(north, c(0.25, 0.75))
IQR(north)
mad(north)

median(south)
quantile(south, c(0.25, 0.75))
mad(south)
```

```{r bleaching_heatmap}
# Interpolate percent bleaching for whole reef tract
# https://geobgu.xyz/r/spatial-interpolation-of-point-data.html

# Create SpatialPointsDataFrame of survey sites
sites23 <- pctbl23.adj %>%
  distinct(Site, Longitude, Latitude, adjprob)
spdat <- sp::SpatialPointsDataFrame(
    coords=sites23[,c('Longitude','Latitude')], 
    data=sites23[,c('Site', 'adjprob')], 
    proj4string = CRS("+init=epsg:4326")
)

# Create empty raster to hold interpolated values
samplegrid <- raster::raster(spdat, res = c(0.005, 0.005))
raster::crs(samplegrid) <- raster::crs(spdat) <- sp::CRS("+init=epsg:4326")
# Run interpolation
idw.model <- gstat(formula=spdat$adjprob~1, locations=spdat, weights = pctbl23.adj$n)
idw.spp <- raster::interpolate(samplegrid, idw.model)

# Clip interpolated raster to just area of hull/polygon surrounding the reef tract
# Create hull/polygon surrounding surveyed sites
pts1 <- st_as_sf(x = sites23, coords = c('Longitude', 'Latitude'))
my_hull <- st_concave_hull(st_union(pts1), ratio = 0.09)
my_hull <- st_buffer(my_hull, dist = 0.015)
my_hull <- my_hull %>% st_set_crs(4326)
idw.spp.reef <- raster::mask(idw.spp, (as_Spatial(my_hull)))

# Convert clipped interpolation to spatraster for plotting
x <- rast(idw.spp.reef)

# PLOT
# Download satellite map for Florida
world <- rnaturalearth::ne_countries(scale = "large", returnclass = "sf")
# Create base map of Florida
basemap <- ggplot() +
  geom_sf(data = world, lwd = 0.1, fill = "gray90") +
  coord_sf(xlim = c(-83.2, -79.8), ylim = c(24.3, 27.3), expand = FALSE) +
  scale_fill_gradient2(high = "firebrick1", mid = "yellow", low = "forestgreen", 
                       midpoint = 0.5, limits = c(0, 1), na.value = NA,
                       labels = scales::label_percent(), name = "Corals\nbleached") +
  theme(text = element_text(size = 10),
        axis.title = element_blank(),
        panel.background = element_rect(fill = "lightsteelblue1"),
        panel.border = element_rect(colour = "black", fill=NA),
        panel.grid = element_blank(),
        legend.position = c(0.2, 0.5),
        legend.background = element_blank())

# Map with interpolated raster
rasterplot <- basemap +
  geom_spatraster(data = x) +
  geom_sf(data = world, lwd = 0.1, fill = "gray90") +
  coord_sf(xlim = c(-83.2, -79.8), ylim = c(24.3, 27.3), expand = FALSE) +
  annotate("point", x = -80.1918, y = 25.7617, size = 0.5) +
  annotate("text", x = -80.25, y = 25.7617, 
           label = "Miami", hjust = 1, vjust = 0, size = 2, fontface = "italic")
rasterplot
ggsave(filename = "figures/Fig1.png", plot = rasterplot, width = 90, height = 90, units = "mm")
```

## Map DHWs
```{r map_dhw}
# Import DHW data from all surveyed sites in 2023
dhw <- read_csv("data/dhw/2023/dhw_processed.csv") %>%
  mutate(across(where(is.character), as_factor)) %>%
  rename(Date = date) %>%
  dplyr::select(Site, Date, dhw)

# Get maximum DHW for each surveyed site
sitemaxdhw <- pctbl23.adj %>%
  distinct(Site, Longitude, Latitude, Subregion) %>%
  right_join(dhw) %>%
  group_by(Site, Subregion) %>%
  summarize(sitemaxdhw = max(dhw))

ggplot(sitemaxdhw, aes(x = Subregion, y = sitemaxdhw, color = Subregion)) + 
  geom_jitter() +
  theme(legend.position = "none")

# Get the minimum and maximum site-specific peak DHW in each Subregion
sitemaxdhw %>%
  group_by(Subregion) %>%
  summarize(minmaxdhw = min(sitemaxdhw),
            maxmaxdhw = max(sitemaxdhw))

# Create DHW map
maxdhw <- dhw %>%
  group_by(Site) %>%
  summarize(maxdhw = max(dhw)) %>%
  right_join(sites23, by = "Site")

# Create SpatialPointsDataFrame of survey sites
dhwdat <- sp::SpatialPointsDataFrame(
    coords=maxdhw[,c('Longitude','Latitude')], 
    data=maxdhw[,c('Site', 'maxdhw')], 
    proj4string = CRS("+init=epsg:4326")
)

# Create empty raster to hold interpolated values
dhwgrid <- raster::raster(dhwdat, res = c(0.005, 0.005))
raster::crs(dhwgrid) <- raster::crs(dhwdat) <- sp::CRS("+init=epsg:4326")
# Run interpolation
dhw.idw.model <- gstat(formula=dhwdat$maxdhw~1, locations=dhwdat)
dhw.idw.spp <- raster::interpolate(dhwgrid, dhw.idw.model)
# Clip
dhw.idw.spp.reef <- raster::mask(dhw.idw.spp, (as_Spatial(my_hull)))

# Convert clipped interpolation to spatraster for plotting
x2 <- rast(dhw.idw.spp.reef)

dhwmap <- basemap +
  geom_spatraster(data = x2) +
  geom_sf(data = world, lwd = 0.1, fill = "gray90") +
  coord_sf(xlim = c(-83.2, -79.8), ylim = c(24.3, 27.3), expand = FALSE) +
  scale_fill_distiller(palette = "Spectral", 
                       limits = c(0, 23), na.value = NA,
                       name = "Max.\nDHW      ")

# Save DHW map as supplementary figure
ggsave(filename = "figures/FigS2.png", plot = dhwmap, width = 90, height = 90, units = "mm")

```

## Species variation in bleaching

### Species ED50s
```{r bleaching_by_species, fig.width = 5, fig.height = 6}
## Modeling species-level bleaching susceptibility vs. dhw
# Get subsetted dataset of coral species observed >80 times
df23.abund <- df23 %>%
  group_by(Species) %>%
  filter(n() > 80)  # 80
df23f <- df23.abund %>%
  group_by(Site, Subregion, Week2, Species, dhw) %>%
  summarize(BL = sum(Bleaching2 > 1),
            NB = sum(Bleaching2 <= 1),
            pctNB = NB / (NB + BL),
            n = n()) %>%
  drop_na() %>%
  droplevels()

#### DRC (tried 3par, 4par, and 5par -- all work, just slight diffs. )
# More pars = less estimable standard errors on ED50... depends how important ED50 inference is
m3 <- drm(pctNB ~ dhw, data = df23f, curveid = Species, weights = n, type = "binomial",
         logDose = NULL, fct = LL.5(
           names = c("hill", "min", "max", "ED50", "f"),
           ## Max parameter is fixed to 1, min is set to 0
           fixed = c(NA, 0, 1, NA, NA)),
    # Hill parameter must be positive (must decrease with incr. dhw)
    #lowerl = c(rep(0, 22), rep(-Inf, 22), rep(0, 22), rep(-Inf, 22)),
    control = drmc(relTol = 1e-7))
AIC(m3)

# Get fitted values
nd <- expand.grid(Species = levels(df23f$Species), dhw = seq(0, 23, 0.1))
pred <- predict(m3, newdata = nd)
drc.res <- as_tibble(bind_cols(nd, prob = pred))

# Get ED50s and SE
ed50s <- ED(m3, 0.5, type = "absolute", interval = "delta", display = FALSE) %>%
  as_tibble() %>%
  mutate(Species = levels(df23f$Species),
         Species = fct_reorder(Species, Estimate))

# Stats on ED50s
#compParm(m3, "ED50", operator = "-")

# Extract slopes? coef 'hill'
# coef(m3)

# # # Sanity check barplot
# ggplot(df23.abund, aes(x = cut(dhw, breaks = seq(0,24,3)), fill = Bleaching3)) +
#   geom_bar(position = "fill") +
#   geom_text(stat = "count", aes(label = after_stat(count)), vjust = "inward", position = "fill", size = 2) +
#   facet_wrap(~Species, scales = "free_y")


# Ridgeline plot
drc.res.ridges <- drc.res %>%
  mutate(Species = factor(Species, levels = levels(ed50s$Species))) %>%
  ggplot(aes(x = dhw, y = Species)) +
  ggridges::geom_ridgeline_gradient(aes(height = (1 - prob), fill = prob)) +
  scale_y_discrete(labels = species_names[as.character(ed50s$Species)]) +
  scale_fill_gradient2(high = "forestgreen", mid = "yellow", low = "firebrick1", 
                       limits = c(0, 1), midpoint = 0.5) +
  geom_point(data = ed50s, aes(x = Estimate), pch = 5, size = 0.75, stroke = 0.25) +
  geom_segment(data = ed50s, aes(y = Species, yend = Species, x = Lower, xend = Upper),
               linewidth = 0.2) +
  scale_x_continuous(expand = c(0, 0)) +
  coord_cartesian(xlim = c(0, 23)) +
  theme_classic() +
  theme(legend.position = "none",
        axis.text.y = element_text(face = "italic", vjust = 0),
        plot.margin = margin(t = 5.5, r = 5.5, b = 5.5, l = -10)) +
  labs(x = "DHW (°C-weeks)", y = "")
  
drc.res.ridges

# Save as Figure2
ggsave(filename = "figures/Fig2.png", plot = drc.res.ridges,
       width = 90, height = 120, units = "mm")

# Ancillary results reported in text
## DHW at which 99% of ACER were bleached
drc.res %>%
  filter(Species == "ACER", signif(prob, 1) <= 0.01) %>%
  summarize(dhw = min(signif(dhw, 2)))
drc.res %>%
  filter(Species == "ACER", prob > 0.975) %>%
  filter(dhw == max(dhw))
drc.res %>%
  filter(Species == "ACER", prob < 0.025) %>%
  filter(dhw == min(dhw))

# DLAB ED50
ed50s %>%
  filter(Species == "DLAB")

ed50s %>%
  filter(Estimate <= 8)
```


### Within-species variation (ED90-ED10)
```{r within_spp_bleaching_variability}
# Get ED50s and SE
ed50s <- ED(m3, 0.5, type = "absolute", interval = "delta", display = FALSE) %>%
  as_tibble() %>%
  mutate(Species = levels(df23f$Species))


# Get ED90s - ED10 differences and SE
ed_vals <- ED(m3, c(0.1, 0.9), type = "absolute", display = FALSE) %>%
  as_tibble() %>%
  mutate(Species = rep(levels(df23f$Species), each = 2),
         Level = rep(c("ED10", "ED90"), times = length(levels(df23f$Species)))) %>%
  rename(SE = `Std. Error`) %>%
  pivot_wider(names_from = Level, values_from = c(Estimate, SE)) %>%
  mutate(
    # Cap ED10 at 23 DHW
    Estimate_ED10 = pmin(Estimate_ED10, 23),  
    SE_ED10 = ifelse(Estimate_ED10 == 23, 0, SE_ED10),  # Set SE to 0 if truncated
    Diff = Estimate_ED10 - Estimate_ED90,  # Compute difference
    SE_Diff = sqrt(SE_ED10^2 + SE_ED90^2)  # Delta Method SE
  )

# Join ED50s and ED90-ED10 diffs
eds <- full_join(ed50s, ed_vals)

# Ancillary result: OFAV ED50 vs ED10
eds %>%
  filter(Species == "OFAV")
eds %>%
  arrange(-Diff)

# Test relationship between number of symbiont genera and tolerance range
# Join with symbiont data
eds <- full_join(eds, symsumm)
# Model tolerance range with number of symbiont genera as predictor, weighted by SE_Diff
mod3 <- lm(Diff ~ ngen, data = eds, weights = 1/SE_Diff^2)
#mod2 <- quantreg::rq(Diff ~ ngen, data = eds, weights = 1/SE_Diff^2)
anova(mod3)

# Get stats to annotate plot
r_val <- sqrt(summary(mod3)$r.squared)
p_val <- summary(mod3)$coefficients[2, 4]
anno <- substitute(italic("R") == r * ";" ~ italic("p") == p, 
                   list(r = signif(r_val, 2), p = signif(p_val, 2)))

# Plot
pos <- position_jitter(width = 0.15, seed = 21) # Make jitter position for plotting
eds <- eds %>% mutate(D = grepl("D", domsyms), A = grepl("A", domsyms))
fig3 <- ggplot(eds, aes(x = ngen, y = Diff)) +
  geom_line(data = data.frame(x = c(1, 4), 
                              y = c(coef(mod3)[1] + coef(mod3)[2] * 1, 
                                    coef(mod3)[1] + coef(mod3)[2] * 4)),
            aes(x = x, y = y), color = "black", alpha = 0.3, linewidth = 2) +
  geom_pointrange(aes(ymin = Diff - SE_Diff, ymax = Diff + SE_Diff), 
                  position = pos, alpha = 0.6, stroke = 0, size = 0.75, linewidth = 0.25) +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]), position = pos,
                           fontface = "italic", size = 2.5, segment.size = 0.25, seed = 8,
                           min.segment.length = 0.3) +
  annotate("text", x = -Inf, y = Inf, label = anno, hjust = -0.1, vjust = 1, size = 2.5) +
  #ggpubr::stat_cor() +
  labs(x = "Number of Symbiodiniaceae genera", 
       y = "Intraspecific bleaching variability (ED90-ED10)") +
  theme_classic()
fig3

ggsave(filename = "figures/Fig3.png", plot = fig3, width = 90, height = 90, units = "mm")
```


# Temporal shifts in bleaching, 2014-15-23

```{r aggregate_subset_data}
# Aggregate Agaricia spp. other than AAGA, Mycetophyllia spp., Isophyllia spp., Oculina spp., Solenastrea spp., Scolymia spp.
all1 <- all0 %>%
  mutate(Species = case_when(Species %in% c("AFRA", "AGAR", "AGRA", "AHUM", "ALAM") ~ "AGAR",
                             Species %in% c("MALI", "MLAM", "MYCE", "MFER") ~ "MYCE",
                             Species %in% c("IRIG", "ISIN", "ISOP") ~ "ISOP",
                             Species %in% c("OCUL", "ODIF") ~ "OCUL",
                             Species %in% c("SHYA", "SBOU") ~ "SOLE",
                             Species %in% c("SCOL", "SCUB", "SLAC", "SWEL") ~ "SCOL",
                             Species %in% c("OFAV", "OFRA", "OANN") ~ "ORBI",
                             TRUE ~ Species)) %>%
  drop_na(Species)

# Keep only those species observed at least 20 times in each year
spp_to_include <- all1 %>%
  count(Species, year) %>%
  group_by(Species) %>%
  dplyr::filter(min(n) >= 20)  # 20 is a good cutoff

allf <- all1 %>%
  filter(Species %in% spp_to_include$Species)

## Group data at species+site-level to fit group-level models instead of subject-level models -- fits faster
allg <- allf %>%
  group_by(year, Week2, Subregion, Site, dhw, dhw.bin, Species) %>%
  summarize(BL = sum(Bleaching2 > 1),
            NB = sum(Bleaching2 <= 1)) %>%
  ungroup()

# How many observations including 2014/2015/2023 filtered?
nrow(allf)
allf %>% count(year)
```

## All corals - ED50s (glmer)
```{r bleaching_by_dhw_across_years}
# Model differences in bleaching severity between years with DHW as continuous predictor
dhw.mod <- glmer(cbind(BL, NB) ~ dhw + year + year:Week2 + (dhw + year | Species) + (year | Subregion),  
                     family = "binomial", data = allg, verbose = FALSE,
                     nAGQ = 0, control = glmerControl(optimizer = "nloptwrap"))

# Function to get DHW's that cause 50% bleaching for each year
ed50s.fun <- function(dhw.mod) {
  dhw.res <- emmeans(dhw.mod, specs = c("dhw", "year", "Week2"), type = "response",
                     at = list(dhw = seq(0, 23, 0.01), Week2 = c("(36,38]", "(33,35]")), 
                     rg.limit = 20000, level = 0.84)
  dhw.res2 <- subset(dhw.res,
                     (year == "2014" & Week2 == "(36,38]") |
                     (year == "2015" & Week2 == "(36,38]") |
                     (year == "2023" & Week2 == "(33,35]"))
  bleach50 <- as.tibble(dhw.res2) %>%
    group_by(year) %>%
    slice(which.min(abs(prob - 0.5))) %>%
    pull(dhw)
  diff2015 <- bleach50[2]-bleach50[1]
  diff2023 <- bleach50[3]-bleach50[1]
  res <- c(bleach50, diff2015, diff2023)
  res <- setNames(res, c("2014", "2015", "2023", "2015-2014", "2023-2014"))
  return(res)
}

# Get point estimates for ED50s (DHW's that cause 50% bleaching)
bleach50 <- ed50s.fun(dhw.mod)
bleach50

# Bootstrap the calculation of ED50
## re.form = NA: does not account for random effects (conf interval), re.form = NULL: does (prediction interval)
## https://stackoverflow.com/questions/67098467/on-the-predict-mermod-function-arguments
# boot.out <- bootMer(dhw.mod, FUN = ed50s.fun, nsim = 200, seed = 123, re.form = NULL,
#                     parallel = "multicore", ncpus = 20)
# saveRDS(boot.out, file = "data/processed/boot.out.rds")
boot.out <- readRDS(file = "data/processed/boot.out.rds")
## Get confidence intervals from Bootstrap
lower <- apply(boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE)))
upper <- apply(boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))
se <- apply(boot.out$t, 2, sd)

ed50conf <- tibble(
  year = names(bleach50), 
  ed50 = bleach50,
  se = se,
  lower = lower,
  upper = upper)


# For plotting, Get emmeans for just the specific 2-week windows of interest in each year (corresp. to max. bleaching), And select just the range of peak DHWs experienced across sites in each year
# Get max and min DHW for conducted surveys as bounds
all0 %>% group_by(year) %>%
  summarize(maxdhw = max(dhw),
            mindhw = min(dhw))
dhw.res <- emmeans(dhw.mod, specs = c("dhw", "year", "Week2"), type = "response",
                   at = list(dhw = seq(0, 23, 0.1)), rg.limit = 20000, level = 0.84)
dhw.res2 <- subset(dhw.res,
  (year == "2014" & Week2 == "(36,38]" & dhw <= 8.11 & dhw > 0.48) |
  (year == "2015" & Week2 == "(36,38]" & dhw <= 8.90 & dhw > 0) |
  (year == "2023" & Week2 == "(33,35]" & dhw <= 21.5 & dhw > 1.06) 
)

# Plot
dhw.bleach.plot <- ggplot(as.tibble(dhw.res2), aes(x = dhw, y = prob, group = year)) +
  # Add lines and conf intervals for each year
  geom_ribbon(aes(ymin = prob - SE, ymax = prob + SE), lwd = 0, alpha = 0.1) +
  geom_line(aes(color = prob), lwd = 2) +
  geom_text(data = slice(ed50conf, 1:3), 
            aes(x = c(8,9.5,20.5), y = c(0.8, 0.65, 0.97), label = year)) +
  # Add line segments at ED50s
  geom_segment(data = slice(ed50conf, 1:3),
               aes(x = ed50, xend = ed50, y = 0.492, yend = 0), lty = 2, lwd = 0.2) +
  geom_point(data = slice(ed50conf, 1:3), aes(y = 0.5, x = ed50), pch = 1, stroke = 0.2) +
  # Annotate increase in heat tolerance
  annotate("segment", x = 3.9, xend = 11.5, y = 0.05, lwd = 0.2, 
           arrow = arrow(type = "closed", length = unit(3, "mm"))) +
  scale_x_continuous(limits = c(-1, 22), breaks = seq(0, 24, 4), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0), breaks = seq(0, 1, 0.1), 
                     labels = scales::label_percent()) +
  scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
                        limits = c(0, 1), midpoint = 0.5) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "Degree Heating Weeks (°C-weeks)", y = "Bleaching prevalence") +
  coord_cartesian(clip = "off")

```


## All corals - ∆ED50, ∆°C
```{r change_degC_thresh}
# Load dhw.per.degC
dhw.per.degC <- read_csv("data/processed/dhw.per.degC.csv")
dhw.per.degC.se <- dhw.per.degC$dhw.per.degC.se
dhw.per.degC <- dhw.per.degC$dhw.per.degC

# Convert change in ed50s (DHW) to change in tolerance (°C) 
## Propagate errors (quadrature methhod for relative error propagation)
degC <- ed50conf %>%
  filter(year %in% c("2023-2014", "2015-2014")) %>%
  mutate(degC = ed50 / dhw.per.degC,
         degC.se = sqrt((se/ed50)^2 + (dhw.per.degC.se/dhw.per.degC)^2) * degC,
         degC.lower = degC - (1.96 * degC.se),
         degC.upper = degC + (1.96 * degC.se)) %>%
  separate(year, into = c("year", "2014"))

# Get change in heat tolerance from 2014-2013 in degC with 95% C.I.
finaldegC <- degC %>% 
  filter(year == 2023) %>%
  select(degC, degC.lower, degC.upper)
# 0.99°C [95% C.I. = 0.804-1.17°C]

# Annotate and save bleaching response curves plot // Fig4
(dhw.bleach.plot <- dhw.bleach.plot +
  annotate("text", x = 11.7, y = 0.082, hjust = 0, size = 3, 
           label = paste0("Bleaching threshold\n+", signif(ed50conf$ed50[[5]], 2),
                          " DHW = +", signif(finaldegC$degC, 2), "°C")))

ggsave(filename = "figures/Fig4.png", plot = dhw.bleach.plot, width = 100, height = 90, units = "mm")

```

## Species - ∆ED50 2014-15-23

```{r species_bleaching_by_year_dhw, fig.width = 7, fig.height = 7}
# Model differences in bleaching severity between years with DHW
dhw.sp.mod <- glmer(
  cbind(BL, NB) ~ Species + dhw + Species:dhw + year + Species:year + year:Week2 + (year|Subregion),  
  family = "binomial", data = allg, verbose = FALSE,
  nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))
#### relevant reading: https://stats.oarc.ucla.edu/stata/seminars/deciphering-interactions-in-logistic-regression/#:~:text=If%20the%20differences%20are%20not,or%20odds%20ratios%20or%20probability%3F

# Get emmeans for just the specific 2-week windows of interest in each year (corresp. to max. bleaching)
# And select just the range of peak DHWs experienced across sites in each year
dhw.sp.res <- emmeans(dhw.sp.mod, specs = c("Species", "dhw", "year", "Week2"), type = "response",
                      at = list(dhw = seq(0, 23, 0.05), Week2 = c("(36,38]", "(33,35]")), 
                      rg.limit = 200000, level = 0.84)
dhw.sp.res2 <- subset(dhw.sp.res,
  (year == "2014" & Week2 == "(36,38]" & dhw <= 8.11 & dhw > 0.48) |
  (year == "2015" & Week2 == "(36,38]" & dhw <= 8.90 & dhw > 0) |
  (year == "2023" & Week2 == "(33,35]" & dhw <= 21.5 & dhw > 1.06) 
)
dhw.sp.res22 <- subset(dhw.sp.res,
  (year == "2014" & Week2 == "(36,38]") |
  (year == "2015" & Week2 == "(36,38]") |
  (year == "2023" & Week2 == "(33,35]")
)

# Plot
(dhw.sp.bleach.plot <- ggplot(as.tibble(dhw.sp.res2), aes(x = dhw, y = prob, group = year)) +
  facet_wrap(~Species, labeller = labeller(Species = abbrev_names)) +
  geom_ribbon(aes(ymin = prob - SE, ymax = prob + SE), lwd = 0, alpha = 0.2) +
  geom_line(aes(color = year), lwd = 0.5, alpha = 0.9) +
  geom_hline(aes(yintercept = 0.5), lty = 2, lwd = 0.25) +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0), breaks = seq(0, 1, 0.25),
                     labels = scales::label_percent()) +
  # scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
  #                       limits = c(0, 1), midpoint = 0.5) +
  theme_classic() +
  theme(legend.position = c(0.8, 0.04),
        legend.direction = "horizontal",
        strip.background = element_blank(),
        strip.text = element_text(face = "italic")) +
  labs(x = "Degree Heating Weeks (°C-weeks)", y = "Bleaching prevalence", color = "") +
  coord_cartesian(clip = "off"))

ggsave(filename = "figures/FigS4.png", plot = dhw.sp.bleach.plot, width = 140, height = 140, units = "mm")


# Function to get ED50s (DHW's that cause 50% bleaching for each year for each species) AND
## change in ED50s from 2014-2015, and 2014-2023
sp.ed50s.fun <- function(dhw.sp.mod) {
  dhw.sp.res <- emmeans(dhw.sp.mod, specs = c("Species", "dhw", "year", "Week2"), type = "response",
                   at = list(dhw = seq(0, 23, 0.05), Week2 = c("(36,38]", "(33,35]")), 
                   rg.limit = 200000, level = 0.84)
  dhw.sp.res22 <- subset(dhw.sp.res,
    (year == "2014" & Week2 == "(36,38]") |
    (year == "2015" & Week2 == "(36,38]") |
    (year == "2023" & Week2 == "(33,35]") 
  )
  bleach50 <- as.tibble(dhw.sp.res22) %>%
    group_by(Species, year) %>%
    slice(which.min(abs(prob - 0.5)))
  bleachdiffs <- bleach50 %>%
    group_by(Species) %>%
    summarize("2015-2014" = dhw[year=="2015"] - dhw[year=="2014"],
              "2023-2014" = dhw[year=="2023"] - dhw[year=="2014"]) %>%
    pivot_longer(2:3)
  names <- c(paste(bleach50$Species, bleach50$year), paste(bleachdiffs$Species, bleachdiffs$name))
  vals <- c(bleach50$dhw, bleachdiffs$value)
  vals <- setNames(vals, names)
  return(vals)
}

# Get point estimates for ED50s and ∆ED50s
sp.bleach50 <- sp.ed50s.fun(dhw.sp.mod)

# Bootstrap ED50s for SE/confidence intervals
## re.form = NA: does not account for random effects (conf interval), re.form = NULL: does (prediction interval)
## https://stackoverflow.com/questions/67098467/on-the-predict-mermod-function-arguments
# sp.boot.out <- bootMer(dhw.sp.mod, FUN = sp.ed50s.fun, nsim = 1000, seed = 123, re.form = NULL,
#                        parallel = "multicore", ncpus = 20)
# saveRDS(sp.boot.out, file = "data/processed/sp.boot.out.rds")
sp.boot.out <- readRDS(file = "data/processed/sp.boot.out.rds")
## Get confidence intervals from Bootstrap
sp.lower <- apply(sp.boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE)))
sp.upper <- apply(sp.boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))
## Get standard error from Bootstrap
sp.se <- apply(sp.boot.out$t, 2, sd)

sp.ed50conf <- tibble(
  year = names(sp.bleach50), 
  ed50 = sp.bleach50,
  se = sp.se,
  lower = sp.lower,
  upper = sp.upper) %>%
  separate(year, into = c("Species", "year"), sep = " ")
```

### ∆ED50 --> ∆°C
```{r sp.changeED50, fig.width = 7, fig.height = 8}
# Convert ∆ED50s to degC with error propagation
sp.degC <- sp.ed50conf %>%
  filter(year == "2023-2014") %>%
  mutate(degC = ed50 / dhw.per.degC,
         # pmax(ed50, 0.1) uses 0.1 as a constant for cases (PFUR/PDIV) with ed50 = 0 (can't div. by 0), which serves to propagate the absolute error
         degC.se = sqrt((se/pmax(ed50, 0.1))^2 + (dhw.per.degC.se/dhw.per.degC)^2) * pmax(degC, 0.1),
         degC.lower = degC - (1.96 * degC.se),
         degC.upper = degC + (1.96 * degC.se)) %>%
  separate(year, into = c("year", "2014")) %>%
  mutate(Species = fct_reorder(Species, degC))


# Plot change in heat tolerance in degC for all species
## Need to decide whether to use SE or CI for error bars
(finplot <- sp.degC %>%
  ggplot(aes(x = Species, y = degC)) +
  geom_point() +
  #geom_errorbar(aes(ymin = lower.degC, ymax = upper.degC), width = 0) +
  geom_errorbar(aes(ymin = degC - degC.se, ymax = degC + degC.se), width = 0.2) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(y = "Change in heat tolerance (°C)        "))

sp.degC %>% arrange(-degC)
```

### ∆°C vs. density + symbionts

```{r bleachthresh_vs_density, fig.width = 10}
densdiffs <- readRDS("data/processed/dens20142023.rds")

# Combine net changes in heat tolerance with changes in density and levels of symbiont diversity across species
net <- sp.degC %>%
  left_join(select(as.tibble(densdiffs), Species, estimate, SE)) %>%
  left_join(symsumm.ag) %>%
  drop_na(estimate)

# Model change in tolerance vs. change in density
# Passing Bablok regression
PBreg <- mcr::mcreg(net$estimate+3, net$degC+3,
               method.reg = "PaBa",  method.ci = "bootstrap", nsamples = 9999)
summary(PBreg)

PBfit <- mcr::calcResponse(PBreg, x.levels = seq(1.645, 4.178, 0.1), 
                      alpha = 0.1) %>% as_tibble()
PBfit <- PBfit %>%
  mutate(estimate = X - 3, degC = Y - 3)

# Plot
myticks <- c(-0.9, -0.75, -0.5, -0.25, 0, 0.5, 1, 2)
myticks2 <- log(myticks + 1)
set.seed(8)
(dens_sym_viz <- net %>%
  ggplot(aes(x = estimate, y = degC)) + 
  geom_line(data = PBfit, color = "black", lwd = 1, alpha = 0.4) +
  geom_errorbar(aes(ymin = degC - degC.se, 
                    ymax = degC + degC.se), width = 0, alpha = 0.7, lwd = 0.3) +
  geom_errorbar(aes(xmin = estimate - SE, xmax = estimate + SE), width = 0, alpha = 0.7, lwd = 0.3) +
  geom_point(aes(color = factor(ngen)), size = 4, alpha = 0.7, stroke = 0) + 
  
  #geom_smooth(method = "lm", se = FALSE) +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]),
                           fontface = "italic", size = 3, segment.size = 0.25, seed = 8) +
  scale_x_continuous(labels = ~ paste0(round(100 * (exp(.x) - 1), 0), "%"), breaks = myticks2) +
  scale_color_brewer(name = "Symbiont\nGenera",
                     palette = "RdYlBu", direction = -1,
                     na.translate = FALSE) +
  labs(x = "Change in population size (2014-2023)", 
       y = "Change in bleaching threshold (°C)") +
  theme_classic() +
  theme(legend.position = c(0.075,0.1),
        legend.key.width = unit(-10, "mm"),
        legend.key.spacing.y = unit(-3, "mm"), 
        legend.spacing.y = unit(-5, "mm"),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 8, margin = margin(b = -2)),
        legend.margin = margin(-10, 0, 0, 0),
        legend.background = element_blank(),
        legend.key = element_blank()) +
   guides(
    color = guide_legend(
      reverse = TRUE,
      title.hjust = 0.5,  # Further adjusts alignment
      override.aes = list(size = 3)  # Adjusts point size in legend
    ))) +
  coord_cartesian(ylim = c(min(PBfit$degC), max(PBfit$degC)))



# For main text: use this fig showing absolute degC and estimate on x-axis and ngen as color.
# Then, model and produce effect plots for either supplement or as multipanel?



# STATISTICALLY MODEL DENSITY AND SYMBIONT EFFECTS

# Remove missing values
net_clean <- na.omit(net[, c("Species", "degC", "estimate", "ngen", "degC.se", "SE", "D")])

# Center ngen so that the intercept represents `degC = 0` when `estimate = 0` and `ngen = 1`
net_clean$ngen_centered <- net_clean$ngen - 1

# Fit the model, with intercept zero at estimate = 0 and ngen = 1
#  Weight observations using the standard error of the degC response
ols_model_adjusted <- lm(degC ~ 0 + estimate + ngen_centered, data = net_clean, weights = 1/degC.se^2)
# Check intercept
predict(ols_model_adjusted, newdata = data.frame(estimate = 0, ngen_centered = 0))
# Check residuals
#plot(ols_model_adjusted)

# Check model summary
(summary_ols <- summary(ols_model_adjusted))
# Partition variance

# Extract model coefficients
ols_slope_estimate <- coef(ols_model_adjusted)["estimate"]
ols_slope_ngen <- coef(ols_model_adjusted)["ngen_centered"]

# Compute contributions of each predictor
net_clean$Estimate_Contribution <- ols_slope_estimate * net_clean$estimate
net_clean$Ngen_Contribution <- ols_slope_ngen * (net_clean$ngen - 1)

# Compute residual variation (unexplained variation)
net_clean$Unexplained_Variation <- net_clean$degC - (net_clean$Estimate_Contribution + net_clean$Ngen_Contribution)

# Verify that the sum matches observed degC exactly
net_clean$Check_Sum <- net_clean$Estimate_Contribution + net_clean$Ngen_Contribution + net_clean$Unexplained_Variation
all.equal(net_clean$Check_Sum, net_clean$degC)  # Should return TRUE

# Plot contributions of each predictor to observed degC values
out <- net_clean %>%
  select("Species", "degC", "degC.se", 
         "Estimate_Contribution", "Ngen_Contribution", "Unexplained_Variation") %>%
  pivot_longer(cols = 4:6) %>%
  arrange(degC) %>%
  mutate(Species = fct_reorder(Species, degC))

(decomp <- ggplot(out, aes(x = Species, y = value, fill = name)) +
  geom_col(position = "stack", alpha = 1) +
  geom_point(aes(y = degC, shape = "Net change (±SE)"), size = 2) +
  geom_errorbar(aes(ymin = degC - degC.se, ymax = degC + degC.se), width = 0) +
  scale_x_discrete(labels = abbrev_names[as.character(out$Species)]) +
  scale_fill_manual(name = "Modeled contributions", 
                      labels = c("Population size", "Symbiont genera", "Unexplained"),
                      values = c("#67a9cf", "#ef8a62", "#C0C0C0")) +
  scale_shape_manual(name = "", values = 16) +
  theme_classic() +
  theme(axis.text.x = element_text(face = "italic", angle = 45, hjust = 1, size = 10),
        axis.title.y = element_text(size = 12),
        legend.text = element_text(size = 10),  # Decrease legend text size
        legend.title = element_text(size = 10),  # Decrease legend title size
        legend.key.size = unit(0.4, "cm"),  # Reduce legend key size
        legend.spacing.y = unit(-0.2, "cm")) +  # Reduce vertical space between legend items +
  theme(legend.position = c(0.12, 0.86),
        legend.background = element_blank(),  # Transparent legend panel
        legend.key = element_blank()) +
  labs(x = "", y = "Change in bleaching threshold (°C)") +
  guides(fill = guide_legend(ncol = 1, override.aes = list(shape = NA)),
         shape = guide_legend(order = 1, label.theme = element_text(size = 10))))

# Create partial residual effect plots showing density changes and symbiont diversity effects while controlling for the other predictor
# Compute adjusted degC while preserving species-level variation
# net_clean$Adj_degC_Estimate1 <- (ols_slope_estimate * net_clean$estimate) + residuals(ols_model_adjusted)
# net_clean$Adj_degC_Ngen1 <- (ols_slope_ngen * (net_clean$ngen - 1)) + residuals(ols_model_adjusted)
# net_clean$Residual_Variation1 <- residuals(ols_model_adjusted)
#^^^ one way to calculate. 
#VVV another way. equivalent, but more explicit because ngen_centered = 0 and estimate = 0 are specified in predict
net_clean$Adj_degC_Estimate <- predict(ols_model_adjusted, newdata = data.frame(estimate = net_clean$estimate, ngen_centered = 0)) + residuals(ols_model_adjusted)
net_clean$Adj_degC_Ngen <- predict(ols_model_adjusted, newdata = data.frame(estimate = 0, ngen_centered = net_clean$ngen_centered)) + residuals(ols_model_adjusted)
net_clean$Residual_Variation <- residuals(ols_model_adjusted)
### We're adding the total residuals for both effect plots. is this correct? or do we need get partial residuals?

# Add jitter to ngen to prevent overlap
set.seed(42)
net_clean$Jittered_Ngen <- jitter(net_clean$ngen, amount = 0.15)

# Generate regression lines data using correct centering
estimate_seq <- seq(min(net_clean$estimate), max(net_clean$estimate), length.out = 100)
ngen_seq <- seq(min(net_clean$ngen), max(net_clean$ngen), length.out = 100)

regression_line_estimate <- data.frame(
  estimate = estimate_seq,
  predicted_degC = ols_slope_estimate * estimate_seq
)

regression_line_ngen <- data.frame(
  ngen = ngen_seq,
  predicted_degC = ols_slope_ngen * (ngen_seq - 1)
)

# Plot Effect of Estimate on Adjusted degC (Holding ngen = 1, with residuals)
p1 <- ggplot(net_clean, aes(x = estimate, y = Adj_degC_Estimate)) +
  geom_line(data = regression_line_estimate, aes(x = estimate, y = predicted_degC), 
            color = "#67a9cf", linewidth = 1.5, alpha = 1) +
  geom_point(size = 3, alpha = 0.7, color = "#7F7F7F", stroke = 0) +
  geom_errorbar(aes(ymin = Adj_degC_Estimate - degC.se, ymax = Adj_degC_Estimate + degC.se), 
                width = 0, alpha = 0.7, lwd = 0.3) +
  geom_errorbar(aes(xmin = estimate - SE, xmax = estimate + SE), width = 0, alpha = 0.7, lwd = 0.3) +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]),
                           fontface = "italic", size = 3, seed = 8) +
  scale_x_continuous(labels = ~ paste0(round(100 * (exp(.x) - 1), 0), "%"), breaks = myticks2) +
  
  labs(x = "Change in population size (2014-2023)", 
       y = "Change in bleaching threshold (°C)\n(adjusted for symbiont genera = 1)") +
  theme_classic()

# Plot Effect of Ngen on Adjusted degC (Holding estimate = 0, with residuals)
p2 <- ggplot(net_clean, aes(x = Jittered_Ngen, y = Adj_degC_Ngen)) +
  geom_line(data = regression_line_ngen, aes(x = ngen, y = predicted_degC), 
            color = "#ef8a62", linewidth = 1.5, alpha = 1) +
  geom_point(size = 3, alpha = 0.7, color = "#7F7F7F", stroke = 0) +
  geom_errorbar(aes(ymin = Adj_degC_Ngen - degC.se, ymax = Adj_degC_Ngen + degC.se), 
                width = 0, alpha = 0.7, lwd = 0.3) +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]),
                           fontface = "italic", size = 3, seed = 8) +
  labs(x = "Number of symbiont genera", 
       y = "Change in bleaching threshold (°C)\n(adjusted for density change = 0)") +
  scale_size_continuous(range = c(2, 5)) +
  theme_classic()

ps <- cowplot::plot_grid(p1, p2, nrow = 1, labels = c("B", "C"))

s5 <- cowplot::plot_grid(decomp, ps, nrow = 2, rel_heights = c(0.55, 0.45), labels = "A")
s5
ggsave(filename = "figures/FigS5.png", plot = s5, width = 190, height = 200, units = "mm")



# Add statistical info to Fig5
# Extract coefficients and p-values for plotting
estimate_coef <- round(summary_ols$coefficients["estimate", "Estimate"], 3)
estimate_pval <- signif(summary_ols$coefficients["estimate", "Pr(>|t|)"], 3)
ngen_coef <- round(summary_ols$coefficients["ngen_centered", "Estimate"], 3)
ngen_pval <- signif(summary_ols$coefficients["ngen_centered", "Pr(>|t|)"], 3)
r2_value <- round(summary_ols$r.squared, 3)

# ✅ Define annotation text
stat_text <- paste0(
  "Population Effect: ", "p = ", estimate_pval, "\n",
  "Symbiont Effect: ", "p = ", ngen_pval, "\n",
  "R² = ", r2_value
)

# ✅ Add right-aligned annotations in the top-right corner
(fig5 <- dens_sym_viz +
    annotate("text", 
           x = max(net$estimate + net$SE), y = max(PBfit$degC),  # Top-right corner
           label = stat_text, 
           hjust = 1, vjust = 1,  # Right-align text
           size = 2.5) +
    coord_cartesian(ylim = c(min(PBfit$degC), max(PBfit$degC))))

ggsave(filename = "figures/Fig5.png", plot = fig5,
       width = 110, height = 100, units = "mm")
```

# Coral colony size analyses

## Bleaching in large vs. small colonies in 2023

```{r size_effects_2023}
# Model bleaching severity by Width, species, and dhw. 
# There are some corals with Width < 4 -- these were included because Height should have been at least 4. In these cases change Width to 4.
df23.abund <- df23.abund %>%
  mutate(Width2 = case_when(Width >= 4 ~ Width,
                            Width < 4 ~ 4)) %>%
  droplevels()

# Fit model
mod <- glmer(Bleaching2 > 1 ~ Species * Width2 * dhw + Week2 + (1|Subregion), 
             family = "binomial", data = df23.abund,
             nAGQ = 0, control = glmerControl(optimizer = "nloptwrap"), verbose = FALSE)

# Test for significant effect of width for each species at DHW = 15
res <- emtrends(mod, specs = c("Species", "dhw"), var = "Width2", 
                at = list(dhw = 15))

# Get significant species
sig <- as.tibble(summary(res, infer = TRUE)) %>%
  filter(p.value < 0.01)

# Get fitted values for bleaching probability as a function of size for significant species
pred0 <- as.tibble(emmeans(mod, specs = c("Width2", "dhw"), by = "Species", 
                          at = list(Width2 = seq(4,500,1), dhw = 15), 
                          type = "response", rg.limit = 103000)) 
pred <- pred0 %>%
  filter(Species %in% sig$Species) %>%
  left_join(dplyr::select(sig, dhw, Species, asymp.LCL), by = c("dhw", "Species"))

# Get actual observed size ranges for these species
actual <- filter(df23.abund) %>%
  drop_na(Species) %>%
  group_by(Species) %>%
  summarize(min = min(Width2, na.rm = T), max = max(Width2, na.rm = T)) %>%
  mutate(ad = map(max, ~expand_grid(Width2 = seq(4, ., 1)))) %>%
  unnest(ad)
pred2 <- pred %>%
  semi_join(actual, by = c("Species", "Width2"))
  
# Get species full names for plotting
mynames <- pred2 %>%
  left_join(tibble(name = abbrev_names, Species = names(abbrev_names))) %>%
  group_by(Species, name) %>%
  summarize(maxw = max(Width2)) %>%
  distinct(Species, name, maxw)

# Calculate relative risk of large (90th percentile) and small (4cm) colonies of each species
p90 <- actual %>%
  group_by(Species) %>%
  summarize(Width2 = round(quantile(Width2, 0.99))) %>%
  bind_rows(filter(actual, Width2 == 4)) %>%
  filter(Species %in% sig$Species)
p90andsmall <- pred2 %>%
  right_join(p90, by = c("Species", "Width2"))
RR <- p90andsmall %>%
  group_by(Species) %>%
  summarize(max = max(response),
            RR = max(response) / response[Width2 == 4]) %>%
  inner_join(p90 %>% filter(Width2 != 4), by = "Species")


# Plot fitted probabilities within the range of observed Widths for each significant species
(sizeplot <- ggplot(pred2, aes(x = Width2, y = response, group = Species)) +
  coord_trans(x = "log") +
  scale_x_continuous(breaks = c(4, 16, 64, 256), expand = expansion(mult = c(0.05, 0.1))) +
  facet_wrap(~Species, scales = "free_x", labeller = labeller(Species = abbrev_names)) +
  geom_line(aes(color = response)) +
  geom_point(aes(x = Width2, y = response), data = p90andsmall, pch = 1, size = 0.5) +
  geom_text(aes(x = Width2, y = max.x - 0.2, label = paste0(round(RR, 1), "x")), data = RR,
            hjust = 0.5, fontface = "italic", size = 3) +
  scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
                        limits = c(0, 1), midpoint = 0.5) +
  geom_ribbon(aes(ymin = asymp.LCL.x, ymax = asymp.UCL), alpha = 0.1, lwd = 0) +
  ylim(0, 1) +
  labs(x = "Colony width (cm)", y = "Probability of bleaching at 15 DHWs") +
  theme_classic() +
  theme(legend.position = "none",
        strip.text = element_text(face = "italic", hjust = 0),
        strip.background = element_blank()))

ggsave(filename = "figures/FigS6.png", plot = sizeplot,
       width = 120, height = 100, units = "mm")


# Sanity checks for size effects
# Plot actual proportions binned by size class a confirmation
# filter(df23.abund) %>%
#   filter(Species %in% sig$Species) %>%
#   group_by(Species) %>%
#   mutate(Width.bin = cut(log(Width), breaks = 10)) %>%
#   ggplot(aes(x = Width.bin, fill = Bleaching2 > 1)) +
#   geom_bar(position = "fill") +
#   facet_wrap(~Species, scales = "free")
```

## Temporal change in size-frequency
```{r size_frequency}
# Combine 2014 and 2015 data and compare to 2023 size-frequency
allw <- allf %>%
  mutate(Width2 = case_when(Width >= 4 ~ Width,
                            Width < 4 ~ 4)) %>%
  mutate(year = case_when(year %in% c("2014", "2015") ~ "2014/15",
                         TRUE ~ year))


sizefreq <- ggplot(allw, aes(x = log(Width2), fill = factor(year), color = factor(year))) + 
  #geom_histogram(aes(y = ..density..), alpha = 0.4, position = "identity") +
  geom_density(alpha = 0.4) + 
  facet_wrap(~Species, scales = "free",  labeller = labeller(Species = abbrev_names)) + 
  scale_fill_brewer(palette = "Set1") +
  scale_color_brewer(palette = "Set1") +
  scale_x_continuous(breaks = log(c(4, 16, 64, 256)), expand = expansion(mult = c(0.05, 0.1)),
                     labels = c(4, 16, 64, 256)) +
  labs(x = "Log Colony Width (cm)", y = "Density", fill = "Year", color = "Year") +
  theme_classic() +
  theme(legend.position = "none",
        strip.text = element_text(face = "italic", hjust = 0),
        strip.background = element_blank())

# Fit model
wmod <- lmer(log(Width2) ~ year * Species + (1|Species:Subregion), data = allw)

# Get EMMs
emms <- emmeans(wmod, specs = "year", by = "Species")

# Test for significant difference in 2023
sigs <- rbind(contrast(emms, "pairwise")) %>%
  as_tibble() %>%
  filter(p.value < 0.01)


# Convert from log scale to actual size
emms_size <- summary(emms) %>%
  mutate(Estimated_Size = exp(emmean)) %>%
  select(Species, year, Estimated_Size)

# Calculate the difference between 2023 and 2014-2015
size_change0 <- emms_size %>%
  pivot_wider(names_from = year, values_from = Estimated_Size) %>%
  mutate(Change = `2023` - `2014/15`,
         pct = (`2023` - `2014/15`) / `2014/15`)# %>% # Change in mean size
  #filter(Species %in% sigs$Species)

pos <- allw %>%
  group_by(Species, year) %>%
  summarize(max.y = max(density(Width2)$y),
            max.x = max(log(Width2))) %>%
  group_by(Species) %>%
  summarize(max.y = max(max.y),
            max.x = max.x)

size_change1 <- full_join(pos, size_change0)

size_change2 <- size_change1 %>%
  pivot_longer(cols = c("2014/15", "2023"), names_to = "year", values_to = "Estimated_Size") %>%
  mutate(log_size = log(Estimated_Size))

sizefreq <- sizefreq +
  geom_text(data = size_change1, inherit.aes = FALSE,
            aes(x = Inf, y = Inf, label = paste0("avg.=", round(`2014/15`, 1), "cm")), 
            vjust = 1, hjust = 1, color = "#F8766D", size = 3) +
  geom_text(data = size_change1, inherit.aes = FALSE,
            aes(x = Inf, y = Inf, label = paste0("avg.=", round(`2023`, 1), "cm")), 
            vjust = 2.5, hjust = 1, color = "#619CFF", size = 3) +
  geom_text(data = sigs, inherit.aes = FALSE,
            aes(x = Inf, y = Inf, label = paste0("p=", signif(p.value,2))),
            vjust = 4, hjust = 1, color = "black", size = 3, fontface = "bold") +
  theme(legend.position = c(0.7, 0.1))

ggsave("figures/FigS7.png", plot = sizefreq, width = 220, height = 220, units = "mm")
```

