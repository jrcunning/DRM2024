---
title: "symbionts"
author: "R. Cunning"
date: "2026-02-26"
output: html_document
---

# Process ITS2 data
```{r}
library(tidyverse)
library(janitor)
library(phyloseq)
library(stringr)
library(readxl)

## ============================================================
## 1) Read + prep metadata
## ============================================================
md <- read_csv("data/sym_composition/sym_metadata.csv") %>%
  mutate(
    year = as.integer(str_sub(collection_date, 1, 4)),
    era  = case_when(
      year < 2005  ~ "2001-03",
      year > 2019  ~ "2020-21"
    ),
    era = factor(era, levels = c("2001-03", "2020-21"))
  )

## ============================================================
## 2) Read ITS2 VARIANTS (your original method, with minimal QC)
##    - builds phyloseq with DIV x sample counts + clade taxonomy
## ============================================================

# Pawar run
sam0 <- read_tsv("data/sym_composition/20240723T194127_Pawar_Run /post_med_seqs/500_20240730T092802_DBV_20240730T195050.seqs.absolute.abund_and_meta.txt") %>%
  clean_names() %>%
  select(sample_uid, sample_name, fastq_fwd_file_name, fastq_rev_file_name, data_set_uid, data_set_name,
         host_genus, host_species, collection_latitude, collection_longitude, collection_date, collection_depth, post_med_absolute) %>%
  slice(1:(n() - 1)) # Remove last row - not a sample
sam1 <- as.matrix(sam0)
#hie <- as_tibble(sam1) %>% left_join(md, by = "sample_name")
rownames(sam1) <- sam0$sample_name
sam <- sample_data(data.frame(sam1))

taxnames <- read_tsv(
  file = "data/sym_composition/20240723T194127_Pawar_Run /post_med_seqs/500_20240730T092802_DBV_20240730T195050.seqs.absolute.abund_and_meta.txt",
  n_max = 0) %>%
  select(-(1:39)) %>%
  names(.)
tax0 <- data_frame(
  DIV = taxnames,
  clade = str_extract(DIV, "[A-Z]")
)
tax1 <- as.matrix(tax0)
rownames(tax1) <- tax0$DIV
tax <- tax_table(tax1)

otu0 <- read_tsv(
  file = "data/sym_composition/20240723T194127_Pawar_Run /post_med_seqs/500_20240730T092802_DBV_20240730T195050.seqs.absolute.abund_and_meta.txt") %>% 
  select(-1, -(3:39))
otu1 <- as.matrix(otu0[, -1])
rownames(otu1) <- otu0$sample_name
otu <- otu_table(otu1, taxa_are_rows = FALSE)

variants_pawar <- phyloseq(otu, tax, sam)


## ============================================================
## 4) QC: drop low-read samples + drop zero-sum taxa
## ============================================================
low <- sample_sums(variants_pawar) < 50
table(low) #31
variants <- subset_samples(variants_pawar, !low)
variants <- prune_taxa(taxa_sums(variants) != 0, variants)
# Filter out clade G (likely a free-living contaminant)
variants <- prune_taxa(
  as.vector(tax_table(variants)[, "clade"]) != "G",
  variants
)

## ============================================================
## 5) Build clade-level relative abundance + dominant clade + metadata
## ============================================================
outnew <- variants %>%
  transform_sample_counts(function(x) x / sum(x)) %>%
  psmelt() %>%
  as_tibble() %>%
  transmute(
    sample_name,
    clade = as.character(clade),
    rel_abund = as.numeric(Abundance)
  ) %>%
  group_by(sample_name, clade) %>%
  summarize(rel_abund = sum(rel_abund), .groups = "drop") %>%
  pivot_wider(names_from = clade, values_from = rel_abund, values_fill = 0) %>%
  mutate(across(any_of(c("A","B","C","D","G")), ~replace_na(.x, 0))) %>%
  mutate(
    dominant_clade = {
      clades <- intersect(c("A","B","C","D","G"), names(.))
      m <- as.matrix(select(., all_of(clades)))
      clades[max.col(m, ties.method = "first")]
    }
  ) %>%
  left_join(
    md %>%
      select(
        sample_name,
        host_genus, host_species,
        collection_date, era,
        collection_subregion,
        collection_site,
        collection_latitude, collection_longitude,
        collection_depth_ft
      ),
    by = "sample_name"
  ) %>%
  rename(
    date      = collection_date,
    subregion = collection_subregion,
    site      = collection_site,
    latitude  = collection_latitude,
    longitude = collection_longitude,
    depth     = collection_depth_ft
  ) %>%
  relocate(sample_name, host_genus, host_species, date, era, subregion, site,
           latitude, longitude, depth, dominant_clade, .before = 1)

## 

write_csv(outnew, file = "data/processed/symbiont_composition.csv")

```


# Analyze symbiont composition shifts per species
```{r}
# ============================================================
# Symbiont community shift (Upper Keys)
# Era comparison: 2001–03 vs 2020–21
#
# This script:
#   1) Builds a cleaned dataset (dat_keep) with Species codes and clade proportions
#   2) HARD-CODES depth standardization (quantile depth bins + IPW reweighting)
#   3) Extracts the EXACT era compositions being compared (comp_std) for plotting
#   4) Computes point-estimate distances (res_point) from those same compositions
#   5) Computes bootstrap uncertainty (res_boot) by resampling within era within species
#   6) Writes symbiont_shifts.csv used downstream
#
# Key design choice:
#   - Depth standardization is assumed to be feasible for all species in this analysis
#   - Therefore there is NO fallback branch (no unweighted means)
#   - The depth standardization "engine" is written ONCE and reused for point + bootstrap
# ============================================================

# ----------------------------
# PARAMETERS (stable for this analysis)
# ----------------------------
ERA1 <- "2001-03"
ERA2 <- "2020-21"
CLADE_COLS <- c("A","B","C","D")

MIN_N  <- 4        # minimum samples per era per species
N_BINS <- 3        # number of pooled depth quantile bins per species
B      <- 1000      # bootstrap draws
CONF   <- 0.84     # CI level (0.84 -> 8th–92nd percentiles)
lo <- (1 - CONF) / 2
hi <- 1 - lo


# ============================================================
# 1) SPECIES LABEL -> 4-LETTER CODE -> AGGREGATED CODE
#    (same mapping logic as before)
# ============================================================

species_names <- c(
  AAGA="Agaricia agaricites", AFRA="Agaricia fragilis", AGAR="Agaricia spp.",
  AGRA="Agaricia grahamae",   AHUM="Agaricia humilis",  ALAM="Agaricia lamarcki",
  ACER="Acropora cervicornis", APAL="Acropora palmata", APRO="Acropora prolifera",
  CNAT="Colpophyllia natans", DCYL="Dendrogyra cylindrus", DLAB="Diploria labyrinthiformis",
  DSTO="Dichocoenia stokesii", EFAS="Eusmilia fastigiata", FFRA="Favia fragum",
  HCUC="Helioseris cucullata", ISIN="Isophyllia sinuosa", IRIG="Isophyllia rigida",
  ISOP="Isophyllia spp.", MADR="Madracis spp.", MANG="Mussa angulosa", MARE="Manicina areolata",
  MCAV="Montastraea cavernosa", MDEC="Madracis decactis", MFER="Mycetophyllia ferox",
  MALI="Mycetophyllia aliciae", MLAM="Mycetophyllia lamarckiana", MFOR="Madracis formosa",
  MJAC="Meandrina jacksoni", MMEA="Meandrina meandrites", MSEN="Madracis senaria",
  MYCE="Mycetophyllia sp.", OANN="Orbicella annularis", OCUL="Oculina spp.",
  ODIF="Oculina diffusa", OFAV="Orbicella faveolata", OFRA="Orbicella franksi",
  ORBI="Orbicella spp.", PAST="Porites astreoides", PBRA="Porites branneri",
  PBRC="Porites (branching)", PCLI="Pseudodiploria clivosa", PDIV="Porites divaricata",
  PFUR="Porites furcata", PORI="Porites sp.", PPOR="Porites porites",
  PSTR="Pseudodiploria strigosa", SBOU="Solenastrea bournoni", SCOL="Scolymia spp.",
  SHYA="Solenastrea hyades", SIDE="Siderastrea spp.", SINT="Stephanocoenia intersepta",
  SOLE="Solenastrea spp.", SRAD="Siderastrea radians", SSID="Siderastrea siderea",
  UNKN="Unknown"
)

lookup <- tibble(code = names(species_names), species_name = unname(species_names)) %>%
  distinct(species_name, .keep_all = TRUE) %>%
  mutate(
    species_lc = str_to_lower(species_name),
    epithet_lc = str_to_lower(word(species_name, -1))
  )

code_from_species <- function(x) {
  x  <- as.character(x)
  xl <- str_to_lower(str_squish(x))
  
  out <- ifelse(str_detect(x, "^[A-Z]{4}$"), x, NA_character_)
  out <- coalesce(out, lookup$code[match(xl, lookup$species_lc)])
  out <- coalesce(out, lookup$code[match(xl, lookup$epithet_lc)])
  coalesce(out, "UNKN")
}

aggregate_species_code <- function(code) {
  case_when(
    code %in% c("AFRA","AGAR","AGRA","AHUM","ALAM") ~ "AGAR",
    code %in% c("MALI","MLAM","MYCE","MFER")        ~ "MYCE",
    code %in% c("IRIG","ISIN","ISOP")               ~ "ISOP",
    code %in% c("OCUL","ODIF")                      ~ "OCUL",
    code %in% c("SHYA","SBOU")                      ~ "SOLE",
    code %in% c("OFAV","OFRA","OANN")               ~ "ORBI",
    TRUE ~ code
  )
}


# ============================================================
# 2) PREP DATA (eras, depth numeric, clades -> proportions, keepers)
# ============================================================

stopifnot(all(c("host_species","era","depth") %in% names(outnew)))

dat <- outnew %>%
  mutate(
    Species_raw = host_species,
    Species = aggregate_species_code(code_from_species(Species_raw)),
    era   = as.character(era),
    depth = as.numeric(depth)
  ) %>%
  filter(era %in% c(ERA1, ERA2)) %>%
  mutate(across(all_of(CLADE_COLS), ~replace_na(.x, 0))) %>%
  rowwise() %>%
  mutate(
    s = sum(c_across(all_of(CLADE_COLS))),
    across(all_of(CLADE_COLS), ~ ifelse(s > 0, .x / s, .x))
  ) %>%
  ungroup() %>%
  select(-s)

keepers <- dat %>%
  count(Species, era) %>%
  pivot_wider(names_from = era, values_from = n, values_fill = 0) %>%
  filter(.data[[ERA1]] >= MIN_N, .data[[ERA2]] >= MIN_N, Species != "UNKN") %>%
  pull(Species)

dat_keep <- dat %>% filter(Species %in% keepers)


# ============================================================
# 3) DISTANCE METRICS (computed from mean compositions)
# ============================================================

tv_dist <- function(p, q) 0.5 * sum(abs(p - q))

hellinger_dist <- function(p, q) {
  sqrt(0.5 * sum((sqrt(p) - sqrt(q))^2))
}

jsd_dist <- function(p, q) {
  m <- 0.5 * (p + q)
  kl <- function(a, b) {
    keep <- a > 0
    sum(a[keep] * (log2(a[keep]) - log2(b[keep])))
  }
  sqrt(0.5 * kl(p, m) + 0.5 * kl(q, m))
}


# ============================================================
# 4) DEPTH STANDARDIZATION ENGINE (written ONCE, reused everywhere)
#
# For ONE species-level dataframe g:
#   - Define pooled depth quantile bin edges (N_BINS)
#   - Bin each sample to depth_bin
#   - Compute pooled (target) depth-bin distribution
#   - Compute per-era inverse-probability weights so each era matches pooled target
#   - Compute weighted mean clade composition per era
#
# Returns:
#   tibble with 2 rows (ERA1 and ERA2) and columns: era, A, B, C, D
# ============================================================

depth_std_comps <- function(g) {
  
  # Depth standardization requires depth; drop missing depth rows
  g <- g %>% filter(!is.na(depth))
  
  # Must have enough samples per era after dropping NA depth
  g1 <- filter(g, era == ERA1)
  g2 <- filter(g, era == ERA2)
  if (nrow(g1) < MIN_N || nrow(g2) < MIN_N) return(NULL)
  
  # (a) pooled quantile edges on depth
  edges <- quantile(
    g$depth,
    probs = seq(0, 1, length.out = N_BINS + 1),
    na.rm = TRUE
  ) %>% as.numeric() %>% unique()
  
  # If edges collapse (should not happen if depth_std is truly always feasible),
  # return NULL so downstream can ignore this draw/species.
  if (length(edges) <= 2) return(NULL)
  
  # (b) assign each row to a depth bin
  gb <- g %>%
    mutate(depth_bin = cut(depth, breaks = edges, include.lowest = TRUE))
  
  # (c) pooled target distribution across bins (within this species)
  target <- gb %>%
    count(depth_bin) %>%
    mutate(p_target = n / sum(n)) %>%
    select(depth_bin, p_target)
  
  # (d) add weights so each era matches pooled target
  gbw <- gb %>%
    group_by(era) %>%
    group_modify(~{
      subg <- .x
      
      # source distribution for this era
      src <- subg %>%
        count(depth_bin) %>%
        mutate(p_src = n / sum(n)) %>%
        select(depth_bin, p_src)
      
      # align src to target bins
      aligned <- target %>%
        left_join(src, by = "depth_bin") %>%
        mutate(p_src = replace_na(p_src, 0))
      
      # per-bin multipliers: target / source
      w_bin <- aligned$p_target / ifelse(aligned$p_src == 0, NA_real_, aligned$p_src)
      w_bin[is.na(w_bin) | is.infinite(w_bin)] <- 0
      
      # attach a row weight w based on each row's depth_bin
      subg %>%
        left_join(tibble(depth_bin = aligned$depth_bin, w = w_bin), by = "depth_bin")
    }) %>%
    ungroup()
  
  # (e) weighted mean clade composition per era
  comp <- gbw %>%
    group_by(era) %>%
    summarize(across(all_of(CLADE_COLS), ~ weighted.mean(.x, w, na.rm = TRUE)),
              .groups = "drop") %>%
    # renormalize defensively (should already sum to ~1)
    rowwise() %>%
    mutate(s = sum(c_across(all_of(CLADE_COLS))),
           across(all_of(CLADE_COLS), ~ .x / s)) %>%
    ungroup() %>%
    select(-s)
  
  comp
}


# ============================================================
# 5) POINT ESTIMATES + PLOTTING TABLE FROM THE SAME COMPOSITIONS
#
# We compute the depth-standardized era compositions ONCE per species,
# then:
#   - comp_std is used for plotting (tidy long format)
#   - res_point distances are computed from the same compositions
# ============================================================

species_comp <- dat_keep %>%
  group_by(Species) %>%
  group_nest() %>%
  mutate(comp = map(data, depth_std_comps)) %>%
  filter(!map_lgl(comp, is.null)) %>%
  select(-data)

# (a) Exact compositions being compared (for plotting)
comp_std <- species_comp %>%
  select(Species, comp) %>%
  unnest(comp) %>%  # columns: Species, era, A,B,C,D
  pivot_longer(all_of(CLADE_COLS), names_to = "clade", values_to = "p")

# (b) Point estimate distances (from the same comps)
res_point <- species_comp %>%
  transmute(
    Species,
    depth_std = TRUE,
    n1 = dat_keep %>% filter(era == ERA1) %>% count(Species) %>% right_join(tibble(Species), by="Species") %>% pull(n) %>% replace_na(0),
    n2 = dat_keep %>% filter(era == ERA2) %>% count(Species) %>% right_join(tibble(Species), by="Species") %>% pull(n) %>% replace_na(0),
    TV = map_dbl(comp, ~{
      p1 <- .x %>% filter(era == ERA1) %>% select(all_of(CLADE_COLS)) %>% as.numeric()
      p2 <- .x %>% filter(era == ERA2) %>% select(all_of(CLADE_COLS)) %>% as.numeric()
      tv_dist(p1, p2)
    }),
    Hellinger = map_dbl(comp, ~{
      p1 <- .x %>% filter(era == ERA1) %>% select(all_of(CLADE_COLS)) %>% as.numeric()
      p2 <- .x %>% filter(era == ERA2) %>% select(all_of(CLADE_COLS)) %>% as.numeric()
      hellinger_dist(p1, p2)
    }),
    JSD = map_dbl(comp, ~{
      p1 <- .x %>% filter(era == ERA1) %>% select(all_of(CLADE_COLS)) %>% as.numeric()
      p2 <- .x %>% filter(era == ERA2) %>% select(all_of(CLADE_COLS)) %>% as.numeric()
      jsd_dist(p1, p2)
    })
  ) %>%
  arrange(desc(TV))


# ============================================================
# 6) BOOTSTRAP UNCERTAINTY (resample within era; reuse same engine)
#
# For each species, each draw:
#   - bootstrap sample ERA1 rows and ERA2 rows separately (same sizes as observed)
#   - recompute depth-standardized comps via depth_std_comps()
#   - compute distances from those comps
#
# NOTE: weights MUST be recomputed per draw because resampling changes
#       the pooled depth distribution and quantile bin edges.
# ============================================================

set.seed(123)
res_boot <- dat_keep %>%
  group_by(Species) %>%
  group_modify(~{
    g  <- .x
    g1 <- filter(g, era == ERA1)
    g2 <- filter(g, era == ERA2)
    
    # require MIN_N per era (should already be true)
    if (nrow(g1) < MIN_N || nrow(g2) < MIN_N) return(tibble())
    
    draws <- replicate(B, {
      b1 <- g1[sample.int(nrow(g1), nrow(g1), replace = TRUE), , drop = FALSE]
      b2 <- g2[sample.int(nrow(g2), nrow(g2), replace = TRUE), , drop = FALSE]
      
      comp <- depth_std_comps(bind_rows(b1, b2))
      if (is.null(comp)) return(c(TV = NA, Hel = NA, JSD = NA))
      
      p1 <- comp %>% filter(era == ERA1) %>% select(all_of(CLADE_COLS)) %>% as.numeric()
      p2 <- comp %>% filter(era == ERA2) %>% select(all_of(CLADE_COLS)) %>% as.numeric()
      
      c(
        TV  = tv_dist(p1, p2),
        Hel = hellinger_dist(p1, p2),
        JSD = jsd_dist(p1, p2)
      )
    })
    
    draws <- as.data.frame(t(draws))
    
    tibble(
      n1 = nrow(g1), n2 = nrow(g2),
      depth_std_frac = 1,  # hard-coded assumption for this analysis
      TV_med  = median(draws$TV,  na.rm = TRUE),
      TV_lo   = quantile(draws$TV,  lo, na.rm = TRUE),
      TV_hi   = quantile(draws$TV,  hi, na.rm = TRUE),
      Hel_med = median(draws$Hel, na.rm = TRUE),
      Hel_lo  = quantile(draws$Hel, lo, na.rm = TRUE),
      Hel_hi  = quantile(draws$Hel, hi, na.rm = TRUE),
      JSD_med = median(draws$JSD, na.rm = TRUE),
      JSD_lo  = quantile(draws$JSD, lo, na.rm = TRUE),
      JSD_hi  = quantile(draws$JSD, hi, na.rm = TRUE)
    )
  }) %>%
  ungroup() %>%
  arrange(desc(TV_med))

res_boot %>%
  pivot_longer(5:13) %>%
  separate(name, into = c("metric", "point")) %>%
  pivot_wider(names_from = "point", values_from = "value") %>%
  ggplot(aes(x = Species, y = med, color = metric)) +
  geom_point()


# ============================================================
# 7) EXPORT TABLE USED DOWNSTREAM (symbiont_shifts.csv)
# ============================================================

ress <- res_boot %>%
  select(Species, med = Hel_med, lo = Hel_lo, hi = Hel_hi) %>%
  mutate(
    se = (hi - lo) / 2,
    w  = 1 / se^2
  )

write_csv(ress, file = "data/processed/symbiont_shifts.csv")

# ============================================================
# 8) PLOT community compositions for each era in each species
# ============================================================
species_names_it <- setNames(
 paste0("italic('", species_names, "')"),
 names(species_names)
)

figsy <- comp_std %>% left_join(ress) %>%
  mutate(genus = case_match(clade, "A" ~ "Symbiodinium", "B" ~ "Breviolum", 
                            "C" ~ "Cladocopium", "D" ~ "Durusdinium"),
         Species = fct_reorder(Species, med),
         hel = paste("H =", round(med, 2))) %>%
  ggplot(aes(x = era, y = p, fill = genus)) +
  geom_col(width = 0.85) +
  facet_wrap(~ Species + hel, ncol = 3, labeller = labeller(
    Species = as_labeller(species_names_it, label_parsed))) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_fill_manual(values = c("#b3cde3", "#ccebc5", "#fbb4ae", "#decbe4")) +
  labs(x = NULL, y = "Depth-standardized mean clade composition", fill = "Genus") +
  theme_bw() +
  theme(legend.text = element_text(face = "italic"))

ggsave(filename = "figures/FigSY.png", width = 180, height = 150, units = "mm")

```

