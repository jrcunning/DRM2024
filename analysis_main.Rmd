---
title: "DRM bleaching analysis"
author: "R. Cunning"
date: "2024-12-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE)
```

```{r libraries}
# Load libraries
library(sf)
library(sp)
library(gstat)
library(lme4)
library(emmeans)
library(terra)
library(tidyterra)
library(drc)
library(tidyverse)
```

```{r labellers, include = FALSE}
# Create species labeller
species_names <- c(
  AAGA = "Agaricia agaricites",
  AFRA = "Agaricia fragilis",
  AGAR = "Agaricia sp.",
  AGRA = "Agaricia grahamae",
  AHUM = "Agaricia humilis",
  ALAM = "Agaricia lamarcki",
  ACER = "Acropora cervicornis",
  AGAR = "Agaricia sp.",
  APAL = "Acropora palmata",
  APRO = "Acropora prolifera",
  CNAT = "Colpophyllia natans",
  DCYL = "Dendrogyra cylindrus",
  DLAB = "Diploria labyrinthiformis",
  DSTO = "Dichocoenia stokesii",
  EFAS = "Eusmilia fastigiata",
  FFRA = "Favia fragum",
  HCUC = "Helioseris cucullata",
  ISIN = "Isophyllia sinuosa",
  IRIG = "Isophyllia rigida",
  ISOP = "Isophyllia sp.",
  MADR = "Madracis sp.",
  MANG = "Mussa angulosa",
  MARE = "Manicina areolata",
  MAUR = "Madriacis auretenra",
  MCAV = "Montastraea cavernosa",
  MDEC = "Madracis decactis",
  MFER = "Mycetophyllia ferox",
  MALI = "Mycetophyllia aliciae",
  MLAM = "Mycetophyllia lamarckiana",
  MFOR = "Madracis formosa",
  MJAC = "Meandrina jacksoni",
  MMEA = "Meandrina meandrites",
  MSEN = "Madracis senaria",
  MYCE = "Mycetophyllia sp.",
  OANN = "Orbicella annularis",
  OCUL = "Oculina sp.",
  ODIF = "Oculina diffusa",
  OFAV = "Orbicella faveolata",
  OFRA = "Orbicella franksi",
  ORBI = "Orbicella sp.",
  PAST = "Porites astreoides",
  PBRA = "Porites branneri",
  PCLI = "Pseudodiploria clivosa",
  PDIV = "Porites divaricata",
  PFUR = "Porites furcata",
  PORI = "Porites sp.",
  PPOR = "Porites porites",
  PSTR = "Pseudodiploria strigosa",
  SBOU = "Solenastrea bournoni",
  SCOL = "Scolymia sp.",
  SHYA = "Solenastrea hyades",
  SIDE = "Siderastrea sp.",
  SINT = "Stephanocoenia intersepta",
  SOLE = "Solenastrea sp.",
  SRAD = "Siderastrea radians",
  SSID = "Siderastrea siderea",
  UNKN = "Unknown"
)

species_names_2l <- gsub(" ", "\n", species_names)
abbrev_names <- as_tibble(species_names) %>%
  separate(value, into = c("genus", "species"), sep = " ") %>%
  mutate(genus = case_when(species == "sp." ~ genus,
                           species != "sp." ~ gsub("[a-z]+", ".", genus))) %>%
  unite(genus, species, col = "name", sep = " ")
abbrev_names <- c(abbrev_names$name)
names(abbrev_names) <- names(species_names)
```

# Import data

## DRM and DHW data (2014, 2015, 2023)
```{r import_data}
# Load all QC'd data from 2014, 2015, and 2023
load("output/2014.RData")
load("output/2015.RData")
load("output/2023.RData")
df23 <- df23 %>% rename(Depth = EndDepth, Transect = TransectNum)

# Combine all years
all0 <- bind_rows(
  `2014` = df14,
  `2015` = df15,
  `2023` = df23,
  .id = "year"
) %>%
  mutate(dhw.bin = cut(dhw, breaks = c(-1, 3, 6, 9, 12, 15, 18, 22)))

# Count number of sites per subregion per year
nsites <- all0 %>%
  distinct(year, Subregion, Site) %>%
  count(year, Subregion) %>%
  pivot_wider(names_from = year, values_from = n)

# Combine North and South Palm Beach subregions due to low survey numbers
all0 <- all0 %>%
  mutate(Subregion = case_when(Subregion %in% c("North Palm Beach", "South Palm Beach") ~ "Palm Beach",
                               TRUE ~ Subregion))

# Reorder subregion factor levels from north to south
all0 <- all0 %>%
  mutate(Subregion = factor(Subregion, levels = c("Martin", "Palm Beach", "Broward-Miami",
                                                  "Biscayne", "Upper Keys", "Mid-Upper Keys Transition",
                                                  "Middle Keys", "Lower Keys", "Marquesas",
                                                  "Tortugas--Dry Tortugas NP")))

df23 <- all0 %>% filter(year == 2023)

# Plot sites surveyed in each year
all0 %>%
  distinct(year, Subregion, Latitude, Longitude, Site) %>%
  ggplot(aes(x = Longitude, y = Latitude, color = Subregion)) +
  geom_point() +
  facet_wrap(~year)

# Number of corals surveyed each year
all0 %>% count(year)
```

## Symbiont metadata for Florida corals
```{r}
# Import symbiont metadata
library(gsheet)
sheet_url <- "https://docs.google.com/spreadsheets/d/1r1MyUA4Vk50SMjkuRM4XfLcv2-Ve1afp/edit?usp=sharing&ouid=100793581009007740691&rtpof=true&sd=true"
sym0 <- gsheet2tbl(sheet_url)

# Summarize symbiont data (get all genera detected in each spp in Florida)
symsumm <- sym0 %>% 
  filter(location == "FL") %>%
  group_by(Species) %>%
  summarize(domsyms = paste0(unique(most_dom_sym_study), collapse = "")) %>%
  mutate(ngen = nchar(domsyms))

# Aggregate symbiont metadata to match coral taxa to match aggregation in DRM dataset
symsumm.ag <- sym0  %>%
  filter(location == "FL") %>%
  mutate(Species = case_when(Species %in% c("AFRA", "AGAR", "AGRA", "AHUM", "ALAM") ~ "AGAR",
                             Species %in% c("MALI", "MLAM", "MYCE", "MFER") ~ "MYCE",
                             Species %in% c("IRIG", "ISIN", "ISOP") ~ "ISOP",
                             Species %in% c("OCUL", "ODIF") ~ "OCUL",
                             Species %in% c("SHYA", "SBOU") ~ "SOLE",
                             Species %in% c("SCOL", "SCUB", "SLAC", "SWEL") ~ "SCOL",
                             Species %in% c("OFAV", "OFRA", "OANN") ~ "ORBI",
                             TRUE ~ Species)) %>%
  drop_na(Species) %>% 
  group_by(Species) %>%
  summarize(domsyms = paste0(unique(most_dom_sym_study), collapse = "")) %>%
  mutate(ngen = nchar(domsyms)) %>%
  print(n = nrow(.)) %>%
  mutate(D = grepl("D", domsyms)) 
```

```{r}
# Plot surveys vs. DHW
(surveys.by.dhw <- all0 %>%
  distinct(year, Site, Date, Subregion, dhw) %>%
  ggplot(aes(x = dhw, fill = Subregion)) +
  geom_histogram(breaks = seq(0,22,1)) +
  facet_grid(year ~ ., scales = "free_y") +
  theme_classic() +
  labs(x = "Degree Heating Weeks", y = "Number of surveys",
       title = "Timing of surveys relative to heat stress accumulation"))

ggsave(filename = "figures/FigS1.png", plot = surveys.by.dhw, width = 183, height = 90, units = "mm")
```

# 2023 bleaching severity

## Map bleaching (all corals)
```{r map_bleaching}
# Get percent of colonies surveyed that were bleached at each site 
pctbl23 <- df23 %>%
  group_by(Site, Subregion, Latitude, Longitude, Week2) %>%
  summarize(BL = sum(Bleaching2 > 1),
            NB = sum(Bleaching2 <= 1),
            pctbl = BL / (BL + NB)) %>%
  ungroup()

pctbl23 <- pctbl23 %>%
  mutate(n = BL + NB)

# Model proportion of bleached colonies in each subregion in each 2-week window of survey
mod <- glm(cbind(BL, NB) ~ Subregion + Week2, family = "binomial", data = pctbl23)
#mod2 <- glm(cbind(BL, NB) ~ Week2, family = "binomial", data = pctbl23)

# Predict proportion of bleached colonies in each Subregion at weeks 34-35 (Week2 = "(33,35]" => (August 20-September 2))) = peak of bleaching
## Get these Subregion probabilities at this time on the log-odds scale (NOT type = 'response')
res <- emmeans(mod, specs = c("Subregion"), at = list(Week2 = factor("(33,35]")))

# Get residuals for each Site at the time it was surveyed (e.g., difference from Subregion mean at time surveyed)...
# ...and then add these residuals to the Subregion's predicted bleaching probability for Weeks 34-35 (peak of bleaching)
# ...to get predicted bleaching severity at that site, if it had been surveyed at peak of bleaching
pctbl23.adj <- pctbl23 %>%
  # Get residuals on the 'working' /logit scale
  mutate(resid = residuals(mod, type = "working")) %>%
  # Join site residuals with logit means for Subregion at weeks 34-35
  left_join(as_tibble(res)) %>%
  # Add residuals to logit mean for Subregion weeks 34-35, then convert to probability scale
  mutate(adj = emmean + resid,
         ## Function to convert logit to probability
         adjprob = exp(adj) / (1 + exp(adj)))

# Plot adjusted bleaching probabilities by subregion
ggplot(pctbl23.adj, aes(x = Subregion, y = adjprob)) +
  geom_violin() +
  geom_jitter(width = 0.15, height = 0)

# Get median adjusted bleaching prevalence by subregion
pctbl23.adj %>%
  group_by(Subregion) %>%
  summarize(medpctbl23.adj = median(adjprob))

# Summarize bleaching prevalence for north (miami up) and south (biscayne to drto) regions
# # Get confidence intervals on site-level bleaching prevalence by subregion and for all keys/drto
pctbl23.adj <- pctbl23.adj %>%
  mutate(region = case_when(Subregion %in% c("Martin", "Palm Beach", "Broward-Miami") ~ "north",
                              TRUE ~ "south"))
north <- filter(pctbl23.adj, region == "north") %>% pull(adjprob)
south <- filter(pctbl23.adj, region == "south") %>% pull(adjprob)

ggplot(pctbl23.adj, aes(x = region, y = adjprob)) + geom_violin()
#ggplot(pctbl23.adj, aes(x = region, y = pctbl)) + geom_violin()

# Test if bleaching prevalence data are normally distributed
shapiro.test(north) # not normal
shapiro.test(south) # not normal

median(north)
quantile(north, c(0.25, 0.75))
IQR(north)
mad(north)

median(south)
quantile(south, c(0.25, 0.75))
mad(south)
```

```{r interpolation}
# Interpolate percent bleaching for whole reef tract
# https://geobgu.xyz/r/spatial-interpolation-of-point-data.html

# Create SpatialPointsDataFrame of survey sites
sites23 <- pctbl23.adj %>%
  distinct(Site, Longitude, Latitude, adjprob)
spdat <- sp::SpatialPointsDataFrame(
    coords=sites23[,c('Longitude','Latitude')], 
    data=sites23[,c('Site', 'adjprob')], 
    proj4string = CRS("+init=epsg:4326")
)

# Create empty raster to hold interpolated values
samplegrid <- raster::raster(spdat, res = c(0.005, 0.005))
raster::crs(samplegrid) <- raster::crs(spdat) <- sp::CRS("+init=epsg:4326")
# Run interpolation
idw.model <- gstat(formula=spdat$adjprob~1, locations=spdat, weights = pctbl23.adj$n)
idw.spp <- raster::interpolate(samplegrid, idw.model)

# Clip interpolated raster to just area of hull/polygon surrounding the reef tract
# Create hull/polygon surrounding surveyed sites
pts1 <- st_as_sf(x = sites23, coords = c('Longitude', 'Latitude'))
my_hull <- st_concave_hull(st_union(pts1), ratio = 0.09)
my_hull <- st_buffer(my_hull, dist = 0.015)
my_hull <- my_hull %>% st_set_crs(4326)
idw.spp.reef <- raster::mask(idw.spp, (as_Spatial(my_hull)))

# Convert clipped interpolation to spatraster for plotting
x <- rast(idw.spp.reef)

# PLOT
# Download satellite map for Florida
world <- rnaturalearth::ne_countries(scale = "large", returnclass = "sf")
# Create base map of Florida
basemap <- ggplot() +
  geom_sf(data = world, lwd = 0.1, fill = "gray90") +
  coord_sf(xlim = c(-83.2, -79.8), ylim = c(24.3, 27.3), expand = FALSE) +
  scale_fill_gradient2(high = "firebrick1", mid = "yellow", low = "forestgreen", 
                       midpoint = 0.5, limits = c(0, 1), na.value = NA,
                       labels = scales::label_percent(), name = "Corals\nbleached") +
  theme(text = element_text(size = 10),
        axis.title = element_blank(),
        panel.background = element_rect(fill = "lightsteelblue1"),
        panel.border = element_rect(colour = "black", fill=NA),
        panel.grid = element_blank(),
        legend.position = c(0.2, 0.5),
        legend.background = element_blank())

# Map with interpolated raster
rasterplot <- basemap +
  geom_spatraster(data = x) +
  geom_sf(data = world, lwd = 0.1, fill = "gray90") +
  coord_sf(xlim = c(-83.2, -79.8), ylim = c(24.3, 27.3), expand = FALSE)

ggsave(filename = "figures/Fig1.png", plot = rasterplot, width = 90, height = 90, units = "mm")
```

## Map DHWs
```{r map_dhw}
dhw <- read_csv("data/dhw/2023/dhw_processed.csv") %>%
  mutate(across(where(is.character), as_factor)) %>%
  rename(Date = date) %>%
  dplyr::select(Site, Date, dhw)

maxdhw <- dhw %>%
  group_by(Site) %>%
  summarize(maxdhw = max(dhw)) %>%
  right_join(sites23, by = "Site")

# Create SpatialPointsDataFrame of survey sites
dhwdat <- sp::SpatialPointsDataFrame(
    coords=maxdhw[,c('Longitude','Latitude')], 
    data=maxdhw[,c('Site', 'maxdhw')], 
    proj4string = CRS("+init=epsg:4326")
)

# Create empty raster to hold interpolated values
dhwgrid <- raster::raster(dhwdat, res = c(0.005, 0.005))
raster::crs(dhwgrid) <- raster::crs(dhwdat) <- sp::CRS("+init=epsg:4326")
# Run interpolation
dhw.idw.model <- gstat(formula=dhwdat$maxdhw~1, locations=dhwdat)
dhw.idw.spp <- raster::interpolate(dhwgrid, dhw.idw.model)
# Clip
dhw.idw.spp.reef <- raster::mask(dhw.idw.spp, (as_Spatial(my_hull)))

# Convert clipped interpolation to spatraster for plotting
x2 <- rast(dhw.idw.spp.reef)

dhwmap <- basemap +
  geom_spatraster(data = x2) +
  geom_sf(data = world, lwd = 0.1, fill = "gray90") +
  coord_sf(xlim = c(-83.2, -79.8), ylim = c(24.3, 27.3), expand = FALSE) +
  scale_fill_distiller(palette = "Spectral", 
                       limits = c(0, 23), na.value = NA,
                       name = "Max.\nDHW      ")

# Save DHW map as supplementary figure
ggsave(filename = "figures/FigS2.png", plot = dhwmap, width = 90, height = 90, units = "mm")

```

## Species variation in bleaching

### Species ED50s
```{r bleaching_by_species, fig.width = 5, fig.height = 6}
## Modeling species-level bleaching susceptibility vs. dhw
# Get subsetted dataset of coral species observed >80 times
df23.abund <- df23 %>%
  group_by(Species) %>%
  filter(n() > 80)
df23f <- df23.abund %>%
  group_by(Site, Subregion, Week2, Species, dhw) %>%
  summarize(BL = sum(Bleaching2 > 1),
            NB = sum(Bleaching2 <= 1),
            pctNB = NB / (NB + BL),
            n = n()) %>%
  drop_na() %>%
  droplevels()

#### DRC (tried 3par, 4par, and 5par -- all work, just slight diffs. )
# More pars = less estimable standard errors on ED50... depends how important ED50 inference is
m3 <- drm(pctNB ~ dhw, data = df23f, curveid = Species, weights = n, type = "binomial",
         logDose = NULL, fct = LL.5(
           names = c("hill", "min", "max", "ED50", "f"),
           ## Max parameter is fixed to 1, min is set to 0
           fixed = c(NA, 0, 1, NA, NA)),
    # Hill parameter must be positive (must decrease with incr. dhw)
    #lowerl = c(rep(0, 22), rep(-Inf, 22), rep(0, 22), rep(-Inf, 22)),
    control = drmc(relTol = 1e-7))
AIC(m3)

# Get fitted values
nd <- expand.grid(Species = levels(df23f$Species), dhw = seq(0, 23, 0.1))
pred <- predict(m3, newdata = nd)
drc.res <- as_tibble(bind_cols(nd, prob = pred))
drc.ord <- ED(m3, 0.5, type = "absolute", display = FALSE) %>%
  as_tibble() %>%
  mutate(Species = levels(df23f$Species),
         Species = fct_reorder(Species, Estimate))

# Stats on ED50s
# compParm(m3, "ED50", operator = "-")

# Extract slopes? coef 'hill'
# coef(m3)

# # # Sanity check barplot
# ggplot(df23.abund, aes(x = cut(dhw, breaks = seq(0,24,3)), fill = Bleaching3)) +
#   geom_bar(position = "fill") +
#   geom_text(stat = "count", aes(label = after_stat(count)), vjust = "inward", position = "fill", size = 2) +
#   facet_wrap(~Species, scales = "free_y")


# Ridgeline plot
drc.res.ridges <- drc.res %>%
  mutate(Species = factor(Species, levels = levels(drc.ord$Species))) %>%
  ggplot(aes(x = dhw, y = Species)) +
  ggridges::geom_ridgeline_gradient(aes(height = (1 - prob), fill = prob)) +
  scale_y_discrete(labels = species_names[as.character(drc.ord$Species)]) +
  scale_fill_gradient2(high = "forestgreen", mid = "yellow", low = "firebrick1", 
                       limits = c(0, 1), midpoint = 0.5) +
  geom_point(data = drc.ord, aes(x = Estimate), pch = 5, size = 0.5) +
  theme_classic() +
  theme(legend.position = "none",
        axis.text.y = element_text(face = "italic")) +
  labs(x = "Degree Heating Weeks", y = "")

# Save as Figure2
ggsave(filename = "figures/Fig2.png", plot = drc.res.ridges,
       width = 100, height = 120, units = "mm")
```


### Within-species variation (ED90-ED10)
```{r within_spp_bleaching_variability, fig.width = 8, fig.height = 5}
# Tolerance range within species - from 10% to 90% of colonies bleached, by Species
span1090 <- drc.res %>%
  group_by(Species) %>%
  slice(which.min(abs(prob - 0.9)),
        which.min(abs(prob - 0.1))) %>%
  summarize(min = min(dhw), max = max(dhw)) %>%
  mutate(span = max - min) %>%
  arrange(-span)

# # Calculate percent of colonies of each species bleached at 23 DHW
# pbleach <- drc.res %>%
#   filter(dhw == 23) %>%
#   mutate(pbleach = 1 - prob)

# Join within-species variation with symbiont metadata
out <- drc.ord %>%
  left_join(span1090) %>%
  left_join(symsumm)

# Plot species' range vs. ed50, size points by number of symbiont genera
set.seed(12344)
plot1090 <- ggplot(out, aes(x = Estimate, y = span)) +
  geom_point(aes(size = ngen^4), alpha = 0.7) + #, color = most_dom_sym)) +
  #geom_point(aes(color = factor(n_symbiont_genera))) +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]),
                           fontface = "italic", size = 3, lineheight = 0.75) +
  labs(x = "Median tolerance (DHW ED50)",
       y = "Range in tolerance (DHW ED90 - ED10)") +
  theme_classic() +
  scale_size_continuous(breaks = c(1^4,2^4,3^4,4^4)) +
  theme(legend.position = "none")

ggsave(filename = "figures/Fig3.png", plot = plot1090, width = 90, height = 90, units = "mm")




# Test relationship between number of symbiont genera and tolerance range
mod <- lm(span ~ ngen, data = out)
p_value <- summary(mod)$coefficients[2, 4]

set.seed(1231)
ngen <- ggplot(out, aes(x = ngen, y = span)) +
  geom_point() +
  stat_smooth(geom = "line", method = "lm", se = FALSE, alpha = 0.3, linewidth = 1) +
  ggpubr::stat_cor() +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]),
                           fontface = "italic", size = 4, lineheight = 0.75) +
  labs(x = "Number of Symbiodiniaceae genera", y = "Intraspecific bleaching variability (ED90-ED10)") +
  theme_classic()

ggsave(filename = "figures/FigS3.png", plot = ngen, width = 140, height = 120, units = "mm")
```


# 2014-15-23 bleaching severity 

```{r aggregate_subset_data}
# Aggregate Agaricia spp. other than AAGA, Mycetophyllia spp., Isophyllia spp., Oculina spp., Solenastrea spp., Scolymia spp.
all1 <- all0 %>%
  mutate(Species = case_when(Species %in% c("AFRA", "AGAR", "AGRA", "AHUM", "ALAM") ~ "AGAR",
                             Species %in% c("MALI", "MLAM", "MYCE", "MFER") ~ "MYCE",
                             Species %in% c("IRIG", "ISIN", "ISOP") ~ "ISOP",
                             Species %in% c("OCUL", "ODIF") ~ "OCUL",
                             Species %in% c("SHYA", "SBOU") ~ "SOLE",
                             Species %in% c("SCOL", "SCUB", "SLAC", "SWEL") ~ "SCOL",
                             Species %in% c("OFAV", "OFRA", "OANN") ~ "ORBI",
                             TRUE ~ Species)) %>%
  drop_na(Species)

# Keep only those species observed at least 20 times in each year
spp_to_include <- all1 %>%
  count(Species, year) %>%
  group_by(Species) %>%
  dplyr::filter(min(n) >= 20)  # 20 is a good cutoff

allf <- all1 %>%
  filter(Species %in% spp_to_include$Species)

## Group data at species+site-level to fit group-level models instead of subject-level models -- fits faster
allg <- allf %>%
  group_by(year, Week2, Subregion, Site, dhw, dhw.bin, Species) %>%
  summarize(BL = sum(Bleaching2 > 1),
            NB = sum(Bleaching2 <= 1)) %>%
  ungroup()

# How many observations including 2014/2015/2023 filtered?
nrow(allf)
allf %>% count(year)
```

## All corals - ED50s (glmer)
```{r bleaching_by_dhw_across_years}
# Model differences in bleaching severity between years with DHW as continuous predictor
dhw.mod <- glmer(cbind(BL, NB) ~ dhw + year + year:Week2 + (dhw + year | Species) + (year | Subregion),  
                     family = "binomial", data = allg, verbose = FALSE,
                     nAGQ = 0, control = glmerControl(optimizer = "nloptwrap"))

# Function to get DHW's that cause 50% bleaching for each year
ed50s.fun <- function(dhw.mod) {
  dhw.res <- emmeans(dhw.mod, specs = c("dhw", "year", "Week2"), type = "response",
                     at = list(dhw = seq(0, 23, 0.01), Week2 = c("(36,38]", "(33,35]")), 
                     rg.limit = 20000, level = 0.84)
  dhw.res2 <- subset(dhw.res,
                     (year == "2014" & Week2 == "(36,38]") |
                     (year == "2015" & Week2 == "(36,38]") |
                     (year == "2023" & Week2 == "(33,35]"))
  bleach50 <- as.tibble(dhw.res2) %>%
    group_by(year) %>%
    slice(which.min(abs(prob - 0.5))) %>%
    pull(dhw)
  diff2015 <- bleach50[2]-bleach50[1]
  diff2023 <- bleach50[3]-bleach50[1]
  res <- c(bleach50, diff2015, diff2023)
  res <- setNames(res, c("2014", "2015", "2023", "2015-2014", "2023-2014"))
  return(res)
}

# Get point estimates for ED50s (DHW's that cause 50% bleaching)
bleach50 <- ed50s.fun(dhw.mod)
bleach50

# Bootstrap the calculation of ED50
## re.form = NA: does not account for random effects (conf interval), re.form = NULL: does (prediction interval)
## https://stackoverflow.com/questions/67098467/on-the-predict-mermod-function-arguments
# boot.out <- bootMer(dhw.mod, FUN = ed50s.fun, nsim = 200, seed = 123, re.form = NULL,
#                     parallel = "multicore", ncpus = 20)
# saveRDS(boot.out, file = "output/boot.out.rds")
boot.out <- readRDS(file = "output/boot.out.rds")
## Get confidence intervals from Bootstrap
lower <- apply(boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE)))
upper <- apply(boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))
se <- apply(boot.out$t, 2, sd)

ed50conf <- tibble(
  year = names(bleach50), 
  ed50 = bleach50,
  se = se,
  lower = lower,
  upper = upper)


# For plotting, Get emmeans for just the specific 2-week windows of interest in each year (corresp. to max. bleaching), And select just the range of peak DHWs experienced across sites in each year
# Get max and min DHW for conducted surveys as bounds
all0 %>% group_by(year) %>%
  summarize(maxdhw = max(dhw),
            mindhw = min(dhw))
dhw.res <- emmeans(dhw.mod, specs = c("dhw", "year", "Week2"), type = "response",
                   at = list(dhw = seq(0, 23, 0.1)), rg.limit = 20000, level = 0.84)
dhw.res2 <- subset(dhw.res,
  (year == "2014" & Week2 == "(36,38]" & dhw <= 8.11 & dhw > 0.48) |
  (year == "2015" & Week2 == "(36,38]" & dhw <= 8.90 & dhw > 0) |
  (year == "2023" & Week2 == "(33,35]" & dhw <= 21.5 & dhw > 1.06) 
)

# Plot
(dhw.bleach.plot <- ggplot(as.tibble(dhw.res2), aes(x = dhw, y = prob, group = year)) +
  # Add lines and conf intervals for each year
  geom_ribbon(aes(ymin = prob - SE, ymax = prob + SE), lwd = 0, alpha = 0.1) +
  geom_line(aes(color = prob), lwd = 2) +
  geom_text(data = slice(ed50conf, 1:3), 
            aes(x = c(8,9.5,20.5), y = c(0.8, 0.65, 0.97), label = year)) +
  # Add line segments at ED50s
  geom_segment(data = slice(ed50conf, 1:3),
               aes(x = ed50, xend = ed50, y = 0.492, yend = 0), lty = 2, lwd = 0.2) +
  geom_point(data = slice(ed50conf, 1:3), aes(y = 0.5, x = ed50), pch = 1, stroke = 0.2) +
  # Annotate increase in heat tolerance
  annotate("segment", x = 3.9, xend = 11.5, y = 0.05, lwd = 0.2, 
           arrow = arrow(type = "closed", length = unit(3, "mm"))) +
  annotate("text", x = 11.7, y = 0.082, hjust = 0, size = 3, label = "Bleaching threshold\n+7.6 DHW = +0.97°C") +
  # Annotate extreme bleaching in 2023
  # annotate("point", x = 21.4, y = 0.906, pch = 1, stroke = 0.2) +
  # annotate("segment", x = 21.4, y = 0.9, yend = 0.47, lty = 2, lwd = 0.2) +
  # annotate("text", x = 21.2, y = 0.51, hjust = 1, size = 3, label = "Extreme bleaching\n>2x threshold") +
  scale_x_continuous(limits = c(-1, 22), breaks = seq(0, 24, 4), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0), breaks = seq(0, 1, 0.1), 
                     labels = scales::label_percent()) +
  scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
                        limits = c(0, 1), midpoint = 0.5) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "Degree Heating Weeks (°C-weeks)", y = "Bleaching prevalence") +
  coord_cartesian(clip = "off"))

# Add error bars (± SE) around ED50 estimates
# dhw.bleach.plot +
#   geom_errorbar(data = slice(ed50conf, 1:3),
#                aes(x = ed50, y = 0.5, xmin = ed50 - se, xmax = ed50 + se),
#                width = 0.02, alpha = 0.5)

# Save plot
ggsave(filename = "figures/Fig4.png", plot = dhw.bleach.plot, width = 100, height = 90, units = "mm")
```


## All corals - ∆ED50, ∆°C
```{r change_degC_thresh}
# Specify degC per DHW
degC.per.DHW <- 0.1273714

# Back-calculate change in ed50s (DHW) to change in tolerance (°C) 
degC <- ed50conf %>%
  filter(year %in% c("2023-2014", "2015-2014")) %>%
  mutate(ed50.degC = ed50 * degC.per.DHW,
         se.degC = se * degC.per.DHW,
         lower.degC = lower * degC.per.DHW,
         upper.degC = upper * degC.per.DHW) %>%
  separate(year, into = c("year", "2014"))

# Plot overall change in heat tolerance relative to 2014 in degC
degC %>%
  select(year, ed50.degC, se.degC, lower.degC, upper.degC) %>%
  ggplot(aes(x = year, y = ed50.degC)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower.degC, ymax = upper.degC), width = 0.2) +
  ylim(0, 1.2) +
  labs(y = "Change in heat tolerance from 2014 (°C)") +
  theme_classic()

# Change over time from 2014-2023 in degC
ed50conf %>%
  filter(year == "2023-2014") %>%
  mutate(across(c("ed50", "se", "lower", "upper"), ~ . * degC.per.DHW, .names = "{.col}.degC"))

# 0.97°C [95% C.I. = 0.777-1.06°C]
```

## Species - ED50s 2014-15-23

```{r species_bleaching_by_year_dhw, fig.width = 7, fig.height = 7}
# Model differences in bleaching severity between years with DHW
dhw.sp.mod <- glmer(
  cbind(BL, NB) ~ Species + dhw + Species:dhw + year + Species:year + year:Week2 + (year|Subregion),  
  family = "binomial", data = allg, verbose = FALSE,
  nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))
#### relevant reading: https://stats.oarc.ucla.edu/stata/seminars/deciphering-interactions-in-logistic-regression/#:~:text=If%20the%20differences%20are%20not,or%20odds%20ratios%20or%20probability%3F

# Get emmeans for just the specific 2-week windows of interest in each year (corresp. to max. bleaching)
# And select just the range of peak DHWs experienced across sites in each year
dhw.sp.res <- emmeans(dhw.sp.mod, specs = c("Species", "dhw", "year", "Week2"), type = "response",
                      at = list(dhw = seq(0, 23, 0.05), Week2 = c("(36,38]", "(33,35]")), 
                      rg.limit = 200000, level = 0.84)
dhw.sp.res2 <- subset(dhw.sp.res,
  (year == "2014" & Week2 == "(36,38]" & dhw <= 8.11 & dhw > 0.48) |
  (year == "2015" & Week2 == "(36,38]" & dhw <= 8.90 & dhw > 0) |
  (year == "2023" & Week2 == "(33,35]" & dhw <= 21.5 & dhw > 1.06) 
)
dhw.sp.res22 <- subset(dhw.sp.res,
  (year == "2014" & Week2 == "(36,38]") |
  (year == "2015" & Week2 == "(36,38]") |
  (year == "2023" & Week2 == "(33,35]")
)

# Plot
(dhw.sp.bleach.plot <- ggplot(as.tibble(dhw.sp.res2), aes(x = dhw, y = prob, group = year)) +
  facet_wrap(~Species, labeller = labeller(Species = abbrev_names)) +
  geom_ribbon(aes(ymin = prob - SE, ymax = prob + SE), lwd = 0, alpha = 0.2) +
  geom_line(aes(color = year), lwd = 0.5, alpha = 0.9) +
  geom_hline(aes(yintercept = 0.5), lty = 2, lwd = 0.25) +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0), breaks = seq(0, 1, 0.25),
                     labels = scales::label_percent()) +
  # scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
  #                       limits = c(0, 1), midpoint = 0.5) +
  theme_classic() +
  theme(legend.position = c(0.8, 0.04),
        legend.direction = "horizontal",
        strip.background = element_blank(),
        strip.text = element_text(face = "italic")) +
  labs(x = "Degree Heating Weeks (°C-weeks)", y = "Bleaching prevalence", color = "") +
  coord_cartesian(clip = "off"))

ggsave(filename = "figures/FigS4.png", plot = dhw.sp.bleach.plot, width = 140, height = 140, units = "mm")


# Function to get ED50s (DHW's that cause 50% bleaching for each year for each species) AND
## change in ED50s from 2014-2015, and 2014-2023
sp.ed50s.fun <- function(dhw.sp.mod) {
  dhw.sp.res <- emmeans(dhw.sp.mod, specs = c("Species", "dhw", "year", "Week2"), type = "response",
                   at = list(dhw = seq(0, 23, 0.05), Week2 = c("(36,38]", "(33,35]")), 
                   rg.limit = 200000, level = 0.84)
  dhw.sp.res22 <- subset(dhw.sp.res,
    (year == "2014" & Week2 == "(36,38]") |
    (year == "2015" & Week2 == "(36,38]") |
    (year == "2023" & Week2 == "(33,35]") 
  )
  bleach50 <- as.tibble(dhw.sp.res22) %>%
    group_by(Species, year) %>%
    slice(which.min(abs(prob - 0.5)))
  bleachdiffs <- bleach50 %>%
    group_by(Species) %>%
    summarize("2015-2014" = dhw[year=="2015"] - dhw[year=="2014"],
              "2023-2014" = dhw[year=="2023"] - dhw[year=="2014"]) %>%
    pivot_longer(2:3)
  names <- c(paste(bleach50$Species, bleach50$year), paste(bleachdiffs$Species, bleachdiffs$name))
  vals <- c(bleach50$dhw, bleachdiffs$value)
  vals <- setNames(vals, names)
  return(vals)
}

# Get point estimates for ED50s and ∆ED50s
sp.bleach50 <- sp.ed50s.fun(dhw.sp.mod)

# Bootstrap ED50s for SE/confidence intervals
## re.form = NA: does not account for random effects (conf interval), re.form = NULL: does (prediction interval)
## https://stackoverflow.com/questions/67098467/on-the-predict-mermod-function-arguments
# sp.boot.out <- bootMer(dhw.sp.mod, FUN = sp.ed50s.fun, nsim = 1000, seed = 123, re.form = NULL,
#                        parallel = "multicore", ncpus = 20)
# saveRDS(sp.boot.out, file = "output/sp.boot.out.rds")
sp.boot.out <- readRDS(file = "output/sp.boot.out.rds")
## Get confidence intervals from Bootstrap
sp.lower <- apply(sp.boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE)))
sp.upper <- apply(sp.boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))
## Get standard error from Bootstrap
sp.se <- apply(sp.boot.out$t, 2, sd)

sp.ed50conf <- tibble(
  year = names(sp.bleach50), 
  ed50 = sp.bleach50,
  se = sp.se,
  lower = sp.lower,
  upper = sp.upper) %>%
  separate(year, into = c("Species", "year"), sep = " ")

# # Plot ED50s for each species for each year
# sp.ed50conf %>%
#   filter(year %in% c("2014", "2015", "2023")) %>%
#   ggplot(aes(x = year, y = ed50)) +
#     geom_point() +
#     geom_errorbar(aes(ymin = ed50 - se, ymax = ed50 + se), width = 0.2) +
#     facet_wrap(~Species, scales = "free_y") +
#     labs(y = "ED50 (DHWs to 50% bleaching)") +
#     theme_classic()
```

### ∆ED50 -> ∆°C
```{r sp.changeED50, fig.width = 7, fig.height = 8}
degC.per.DHW <- 0.1273714
# Convert ∆ED50s to degC
sp.degC <- sp.ed50conf %>%
  filter(year %in% c("2015-2014", "2023-2014")) %>%
  mutate(across(c("ed50", "se", "lower", "upper"), ~ . * degC.per.DHW, .names = "{.col}.degC")) %>%
  separate(year, into = c("year", "2014"))

# # Plot ED50 vs. year for all Species
# sp.ed50conf %>%
#   filter(year %in% c("2014", "2015", "2023")) %>%
#   ggplot(aes(x = as.numeric(year), y = ed50)) + 
#   geom_point() +
#   #geom_errorbar(aes(ymin = lower, ymax = upper)) +
#   #geom_smooth(method = "lm", se = FALSE) +
#   geom_path(data = filter(sp.ed50conf, year != "2015")) +
#   facet_wrap(~Species) +
#   theme_classic()

# Get net change in ∆DHW/year from 2014 - 2023, convert to degC
nets <- sp.ed50conf %>%
  filter(year == "2023-2014") %>%
  mutate(neted50 = ed50, neted50.SE = se) %>%
  dplyr::select(Species, neted50, neted50.SE) %>%
  mutate(degC = neted50 * degC.per.DHW, degC.se = neted50.SE * degC.per.DHW) %>%
  dplyr::select(Species, degC, degC.se)

# Plot change in tolerance for all Species
findat <- nets %>%
  mutate(Species = fct_reorder(Species, degC)) 

(finplot <- findat %>%
  ggplot(aes(x = Species, y = degC)) +
  geom_point() +
  #geom_errorbar(aes(ymin = lower.degC, ymax = upper.degC), width = 0) +
  geom_errorbar(aes(ymin = degC - degC.se, ymax = degC + degC.se), width = 0.2) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(y = "Change in heat tolerance (°C)        "))

ggsave(finplot, filename = "figures/FigS5.png", width = 100, height = 100, units = "mm")
```

### ∆°C vs. symbionts
```{r spp_degC_syms}
# Join aggregated symbiont dataset with ∆°C data for coral taxa
symsumm.ag <- symsumm.ag %>%
  full_join(findat)

# # Plot ∆°C vs. number of symbiont genera
library(ggrepel)
ggplot(symsumm.ag, aes(x = ngen, y = degC)) +
  geom_point(size = 2, alpha = 0.6) +
  geom_text_repel(aes(label = abbrev_names[Species]), fontface = 3) +
  geom_smooth(method = "lm", se = F, color = "gray40") +
  theme_classic() +
  labs(x = "Number of symbiont genera", y = "Change in heat tolerance (°C)")

# Test for statistical significance
mod <- lm(degC ~ ngen + D, data = filter(symsumm.ag, ngen > 0))
anova(mod)
# No significant effect of number of symbiont genera on overall change in heat tolerance
```

### ∆°C vs. density changes

```{r bleachthresh_vs_density, fig.width = 10}
#densres <- readRDS("output/density.rds")
densdiffs <- readRDS("output/dens20142023.rds")

# Combine net changes in heat tolerance and density across species
net <- findat %>%
  left_join(select(as.tibble(densdiffs), Species, estimate, SE)) %>%
  drop_na()

# Model change in tolerance vs. change in density
# Passing Bablok regression
PBreg <- mcr::mcreg(net$estimate+3, net$degC+3,
               method.reg = "PaBa",  method.ci = "bootstrap", nsamples = 9999)
summary(PBreg)

PBfit <- mcr::calcResponse(PBreg, x.levels = seq(1.645, 4.178, 0.1), 
                      alpha = 0.1) %>% as_tibble()
PBfit <- PBfit %>%
  mutate(estimate = X - 3,
         degC = Y - 3)

# Plot
myticks <- c(-0.9, -0.75, -0.5, -0.25, 0, 0.5, 1, 2)
myticks2 <- log(myticks + 1)
set.seed(5)
(tol_dens_plot2 <- net %>%
  left_join(readxl::read_xlsx("data/species_metadata.xlsx")) %>%
  ggplot(aes(x = estimate, y = degC)) + 
  geom_errorbar(aes(ymin = degC - degC.se, 
                    ymax = degC + degC.se), width = 0, alpha = 0.7, lwd = 0.3) +
  geom_errorbar(aes(xmin = estimate - SE, xmax = estimate + SE), width = 0, alpha = 0.7, lwd = 0.3) +
  geom_point(size = 4, alpha = 0.7, stroke = 0) + # aes(size = (n_symbiont_genera)^2)
  geom_line(data = PBfit, color = "black", lwd = 1, alpha = 0.4) +
  #geom_smooth(method = "lm", se = FALSE) +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]),
                           fontface = "italic", size = 3, lineheight = 0.75) +
  scale_x_continuous(labels = ~ paste0(round(100 * (exp(.x) - 1), 0), "%"), breaks = myticks2) +
  labs(x = "Change in abundance (2014-2023)", 
       y = "Change in bleaching threshold (°C)") +
  theme_classic() +
  theme(legend.position = "none"))

ggsave(filename = "figures/Fig5.png", plot = tol_dens_plot2,
       width = 110, height = 100, units = "mm")

# # Retest relationship without Orbicella or branching Porites, since these may have "increased in density" due to partial mortality causing them to be recorded as separate colonies
# # Model change in tolerance vs. change in density
# # Passing Bablok regression
# net2 <- net %>% filter(!Species %in% c("ORBI", "PDIV", "PFUR"))
# PBreg2 <- mcr::mcreg(net2$estimate+3, net2$degC+3,
#                method.reg = "PaBa",  method.ci = "bootstrap", nsamples = 9999)
# summary(PBreg2)
# 
# PBfit <- mcr::calcResponse(PBreg, x.levels = seq(1.645, 4.178, 0.1), 
#                       alpha = 0.1) %>% as_tibble()
# PBfit <- PBfit %>%
#   mutate(estimate = X - 3,
#          degC.dec = Y - 3)
# 
# # It is not significant if you take out ORBI, PDIV, PFUR, PPOR...
# # But genets separating into ramets is still the same as not losing genets from the population, so even if that is mechanism of increase in density, still consistent with inference of loss of genotypes driving tolerance increase...
# 
```

### ∆°C vs. density + symbionts
```{r}
# Partial residuals approach
# Combine net changes in heat tolerance and density across species
net <- findat %>%
  left_join(select(as.tibble(densdiffs), Species, estimate, SE)) %>%
  drop_na() %>%
  left_join(symsumm.ag)
net_clean <- na.omit(net[, c("Species", "degC", "estimate", "ngen")])

# Multiple regression:  ∆°C vs. density changes and number of symbiont genera
mod <- lm(degC ~ estimate + ngen, data = net_clean)
anova(mod)
summary(mod)

# Adjusted degC for estimate (holding ngen = 1)
net_clean$adj_degC_est_fixed <- predict(mod, newdata = data.frame(
  estimate = net_clean$estimate,
  ngen = 1
)) + residuals(mod)

# Plot for estimate (holding ngen = 1)
ggplot(net_clean, aes(x = estimate, y = adj_degC_est_fixed)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  geom_label_repel(aes(label = Species)) +
  labs(x = "Density Changes (estimate)", 
       y = "Adjusted degC (ngen fixed at 1)",
       title = "Effect of Estimate on degC (Adjusted for ngen = 1)") +
  theme_minimal()


# Adjusted degC for ngen (holding estimate = 0)
net_clean$adj_degC_ngen_fixed <- predict(mod, newdata = data.frame(
  estimate = 0,
  ngen = net_clean$ngen
)) + residuals(mod)

# Plot for ngen (holding estimate = 0)
ggplot(net_clean, aes(x = ngen, y = adj_degC_ngen_fixed)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  geom_label_repel(aes(label = Species)) +
  labs(x = "Number of Symbiont Genera (ngen)", 
       y = "Adjusted degC (estimate fixed at 0)",
       title = "Effect of ngen on degC (Adjusted for Estimate = 0)") +
  theme_minimal()
```

```{r}
# TOTAL LEAST SQUARES (ASSUMES UNIFORM ERROR IN X AND Y)
# Remove rows with missing values in relevant columns
net_clean <- na.omit(net[, c("Species", "degC", "degC.se", "estimate", "SE", "ngen")])

# Extract predictors and response for Total Least Squares (TLS)
X <- as.matrix(net_clean[, c("estimate", "ngen")])
y <- as.matrix(net_clean$degC)

# Stack predictors and response for TLS (Principal Component Analysis approach)
XY <- cbind(X, y)

# Perform Principal Component Analysis (PCA) for TLS
pca <- prcomp(XY, center = TRUE, scale. = TRUE)

# TLS regression coefficients (derived from last principal component)
tls_slope <- -pca$rotation[, ncol(pca$rotation)][1:2] / pca$rotation[, ncol(pca$rotation)][3]
tls_intercept <- mean(y) - colMeans(X) %*% tls_slope

# Compute adjusted degC values for visualization
net_clean$adj_degC_est_tls <- tls_intercept + 
  tls_slope[1] * net_clean$estimate + 
  tls_slope[2] * 1 + 
  (net_clean$degC - mean(net_clean$degC))

net_clean$adj_degC_ngen_tls <- tls_intercept + 
  tls_slope[1] * 0 + 
  tls_slope[2] * net_clean$ngen + 
  (net_clean$degC - mean(net_clean$degC))

# Add jittered ngen values for visualization
net_clean$jittered_ngen <- jitter(net_clean$ngen, amount = 0.15)

# ✅ Plot for estimate (holding ngen = 1) with properly aligned error bars
plot_est <- ggplot(net_clean, aes(x = estimate, y = adj_degC_est_tls)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = TRUE) +
  geom_errorbar(aes(ymin = adj_degC_est_tls - degC.se, ymax = adj_degC_est_tls + degC.se), width = 0.02) +
  geom_errorbarh(aes(xmin = estimate - SE, xmax = estimate + SE), height = 0.02) +
  geom_label_repel(aes(label = Species)) +
  labs(x = "Density Changes (estimate)", 
       y = "Adjusted degC (ngen fixed at 1)", 
       title = "Total Least Squares: Effect of Estimate on degC (Adjusted for ngen = 1)") +
  theme_minimal()

# ✅ Plot for ngen (holding estimate = 0) with properly aligned error bars
plot_ngen <- ggplot(net_clean, aes(x = jittered_ngen, y = adj_degC_ngen_tls)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = TRUE) +
  geom_errorbar(aes(x = jittered_ngen, ymin = adj_degC_ngen_tls - degC.se, ymax = adj_degC_ngen_tls + degC.se), width = 0.2) +
  geom_label_repel(aes(label = Species)) +
  labs(x = "Number of Symbiont Genera (ngen) (Jittered)", 
       y = "Adjusted degC (estimate fixed at 0)", 
       title = "Total Least Squares: Effect of ngen on degC (Adjusted for Estimate = 0)") +
  theme_minimal()

# Arrange plots together
ggpubr::ggarrange(plot_est, plot_ngen, ncol = 2, nrow = 1)
```




## Subregions - ED50s

```{r subregion_bleaching_by_year_dhw}
# Model differences in bleaching severity between years with DHW
dhw.reg.mod <- glmer(
  cbind(BL, NB) ~ Subregion + dhw + Subregion:dhw + year + Subregion:year + year:Week2 + (dhw+year|Species),  
  family = "binomial", data = allg, verbose = FALSE,
  nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))

# Best formula: cbind(BL, NB) ~ dhw * year + year:Week2 + (dhw+year|Species) + (year|Subregion)
#### Or DHW + year may be better.....DHW * Year or DHW + YEAR???
#### relevant reading: https://stats.oarc.ucla.edu/stata/seminars/deciphering-interactions-in-logistic-regression/#:~:text=If%20the%20differences%20are%20not,or%20odds%20ratios%20or%20probability%3F
anova(dhw.reg.mod)


# Get emmeans for just the specific 2-week windows of interest in each year (corresp. to max. bleaching)
# And select just the range of peak DHWs experienced across sites in each year
dhw.reg.res <- emmeans(dhw.reg.mod, specs = c("Subregion", "dhw", "year", "Week2"), 
                       type = "response",
                   at = list(dhw = seq(0, 23, 0.1), Week2 = c("(36,38]", "(33,35]")), 
                   rg.limit = 200000, level = 0.84)
dhw.reg.res2 <- subset(dhw.reg.res,
  (year == "2014" & Week2 == "(36,38]" & dhw <= 8.11 & dhw > 0.97) |
  (year == "2015" & Week2 == "(36,38]" & dhw <= 8.9 & dhw > 0) |
  (year == "2022" & Week2 == "(37,39]" & dhw <= 8.07 & dhw > 0) |
  (year == "2023" & Week2 == "(33,35]" & dhw <= 22.1 & dhw > 1.53) 
)
dhw.reg.res22 <- subset(dhw.reg.res,
  (year == "2014" & Week2 == "(36,38]") |
  (year == "2015" & Week2 == "(36,38]") |
  (year == "2022" & Week2 == "(37,39]") |
  (year == "2023" & Week2 == "(33,35]")
)

# Plot
(dhw.reg.bleach.plot <- ggplot(as.tibble(dhw.reg.res2), aes(x = dhw, y = prob, group = year)) +
  facet_wrap(~Subregion) +
  #geom_ribbon(aes(ymin = prob - SE, ymax = prob + SE), lwd = 0, alpha = 0.4) +
  geom_line(aes(color = year), lwd = 1, alpha = 0.9) +
  geom_hline(aes(yintercept = 0.5), lty = 2) +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0), breaks = seq(0, 1, 0.1)) +
  # scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
  #                       limits = c(0, 1), midpoint = 0.5) +
  theme_classic() +
  #theme(legend.position = "none") +
  labs(x = "DHWs", y = "Probability of bleaching"))


# Function to get ED50s (DHW's that cause 50% bleaching for each year for each species) AND
## change in ED50s from 2014-2015, and 2014-2023
reg.ed50s.fun <- function(dhw.reg.mod) {
  dhw.reg.res <- emmeans(dhw.reg.mod, specs = c("Subregion", "dhw", "year", "Week2"), type = "response",
                   at = list(dhw = seq(0, 23, 0.1), Week2 = c("(36,38]", "(33,35]")), rg.limit = 200000, level = 0.84)
  dhw.reg.res22 <- subset(dhw.reg.res,
    (year == "2014" & Week2 == "(36,38]") |
    (year == "2015" & Week2 == "(36,38]") |
    (year == "2023" & Week2 == "(33,35]") 
  )
  bleach50 <- as.tibble(dhw.reg.res22) %>%
    group_by(Subregion, year) %>%
    slice(which.min(abs(prob - 0.5)))
  bleachdiffs <- bleach50 %>%
    group_by(Subregion) %>%
    summarize("2015-2014" = dhw[year=="2015"] - dhw[year=="2014"],
              "2023-2014" = dhw[year=="2023"] - dhw[year=="2014"]) %>%
    pivot_longer(2:3)
  names <- c(paste(bleach50$Subregion, bleach50$year), paste(bleachdiffs$Subregion, bleachdiffs$name))
  vals <- c(bleach50$dhw, bleachdiffs$value)
  vals <- setNames(vals, names)
  return(vals)
}

# Get point estimates for ED50s and ∆ED50s
reg.bleach50 <- reg.ed50s.fun(dhw.reg.mod)

# Bootstrap ED50s for SE/confidence intervals
## re.form = NA: does not account for random effects (conf interval), re.form = NULL: does (prediction interval)
## https://stackoverflow.com/questions/67098467/on-the-predict-mermod-function-arguments
# reg.boot.out <- bootMer(dhw.reg.mod, FUN = reg.ed50s.fun, nsim = 100, seed = 123, re.form = NULL,
#                        parallel = "multicore", ncpus = 10)
# saveRDS(reg.boot.out, file = "output/reg.boot.out.rds")
reg.boot.out <- readRDS(file = "output/reg.boot.out.rds")
## Get confidence intervals from Bootstrap
reg.lower <- apply(reg.boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE)))
reg.upper <- apply(reg.boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))
## Get standard error from Bootstrap
reg.se <- apply(reg.boot.out$t, 2, sd)

reg.ed50conf <- tibble(
  name = names(reg.bleach50), 
  ed50 = reg.bleach50,
  se = reg.se,
  lower = reg.lower,
  upper = reg.upper) %>%
  mutate(year = gsub("\\D+", "", name),
         Subregion = gsub("\\d+", "", name)) %>%
  mutate(Subregion = gsub("\\ -", " ", Subregion)) %>%
  mutate(Subregion = trimws(Subregion, "right"))

# # Plot ED50s for each subregion for each year
reg.ed50conf %>%
  filter(year %in% c("2014", "2015", "2023")) %>%
  ggplot(aes(x = year, y = ed50)) +
    geom_point() +
    geom_errorbar(aes(ymin = ed50 - se, ymax = ed50 + se), width = 0.2) +
    facet_wrap(~Subregion, scales = "free_y") +
    labs(y = "ED50 (DHWs to 50% bleaching)") +
    theme_classic()

# Changes in heat tolerance for each region
out <- reg.ed50conf %>%
  filter(year == "20232014")
```

```{r subregion_bleachthresh_vs_density}
#densres <- readRDS("output/density.rds")
densdiffs <- readRDS("output/dens20142023subregions.rds")
# nmds <- cent %>%
#   group_by(Subregion) %>%
#   summarize(dMDS1 = MDS1[year=="2023"]-MDS1[year=="2014"],
#             dMDS2 = MDS2[year=="2023"]-MDS2[year=="2014"])

# Combine net changes in heat tolerance and density across species
net <- out %>%
  left_join(select(as.tibble(densdiffs), Subregion, estimate, SE))# %>%
  # left_join(nmds)

ggplot(net, aes(x = estimate, y = ed50)) + 
  geom_label(aes(label = Subregion)) +
  theme_classic() +
  #xlim(-0.2, 1) +
  labs(x = "Change in MDS2 2023-2014",
       y = "Change in ED50 2014-2023 (DHW)")

# mod <- lm(ed50 ~ dMDS1 + dMDS2, data = net)
# summary(mod)
# anova(mod)
# net
```


# Size diffs

## 2023 - probability at 15 DHWs

```{r size_effects_2023}
# Model bleaching severity by Width, species, and dhw. 
# There are some corals with Width < 4 -- these were included because Height should have been at least 4. In these cases change Width to 4.
df23.abund <- df23.abund %>%
  mutate(Width2 = case_when(Width >= 4 ~ Width,
                            Width < 4 ~ 4)) %>%
  droplevels()

# mod <- glm(Bleaching2 > 1 ~ Width2 * Species, family = "binomial", data = df23.abund)
# summary(emtrends(mod, specs = "Species", var = "Width2"), infer = TRUE) %>% arrange(p.value)
# nd <- expand.grid(Width2 = seq(4,200,1), Species = levels(df23.abund$Species))
# pred <- predict(mod, newdata = nd, re.form = NA, type = "response")
# bind_cols(nd, pred) %>%
#   ggplot(aes(x = Width2, y = ...3)) +
#   geom_line() +
#   facet_wrap(~Species)

# Fit model
mod <- glmer(Bleaching2 > 1 ~ Species * Width2 * dhw + Week2 + (1|Subregion), 
             family = "binomial", data = df23.abund,
             nAGQ = 0, control = glmerControl(optimizer = "nloptwrap"), verbose = FALSE)
#plot(mod, which = 1)
#summary(mod)
# Fit model
modr <- glmer(Bleaching2 <= 1 ~ Species * Width2 * dhw + Week2 + (1|Subregion), 
             family = "binomial", data = df23.abund,
             nAGQ = 0, control = glmerControl(optimizer = "nloptwrap"), verbose = FALSE)

# Test if significant effect of width for each species at DHW = 15
res <- emtrends(mod, specs = c("Species", "dhw"), var = "Width2", at = list(dhw = 15))

# Get significant species
sig <- as.tibble(summary(res, infer = TRUE)) %>%
  filter(p.value < 0.01)

# Get fitted values for bleaching probability as a function of size for significant species
pred0 <- as.tibble(emmeans(mod, specs = c("Width2", "dhw"), by = "Species", 
                          at = list(Width2 = seq(4,500,1), dhw = 15), 
                          type = "response", rg.limit = 103000)) 

predr <- as.tibble(emmeans(modr, specs = c("Width2", "dhw"), by = "Species", 
                          at = list(Width2 = seq(4,250,1), dhw = 15), 
                          type = "response", rg.limit = 103000)) 
predodds %>% filter(Species == "PAST", Width2 == 4)
# 1.06 = log odds of being bleached
# exp(1.06) = 2.88, so odds of being bleaching are 2.88 to 1. 1 in 3.88 are resistant.
pred0 %>% filter(Species == "PAST", Width2 == 4)
1/(1-0.744)

pred <- pred0 %>%
  filter(Species %in% sig$Species) %>%
  left_join(dplyr::select(sig, dhw, Species, asymp.LCL), by = c("dhw", "Species"))
# Get actual observed size ranges for these species
actual <- filter(df23.abund) %>%
  drop_na(Species) %>%
  group_by(Species) %>%
  summarize(min = min(Width2, na.rm = T), max = max(Width2, na.rm = T)) %>%
  mutate(ad = map(max, ~expand_grid(Width2 = seq(4, ., 1)))) %>%
  unnest(ad)
pred2 <- pred %>%
  semi_join(actual, by = c("Species", "Width2"))
  
# Get species full names for plotting
mynames <- pred2 %>%
  left_join(tibble(name = abbrev_names, Species = names(abbrev_names))) %>%
  group_by(Species, name) %>%
  summarize(maxw = max(Width2)) %>%
  distinct(Species, name, maxw)
# Plot fitted probabilities within the range of observed Widths for each significant species
(sizeplot <- ggplot(pred2, aes(x = Width2, y = response, group = Species)) +
  coord_trans(x = "log") +
  scale_x_continuous(breaks = c(4, 16, 64, 256), expand = expansion(mult = c(0.05, 0.1))) +
  facet_wrap(~Species, scales = "free_x", labeller = labeller(Species = abbrev_names)) +
  geom_line(aes(color = response)) +
  scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
                        limits = c(0, 1), midpoint = 0.5) +
  geom_ribbon(aes(ymin = asymp.LCL.x, ymax = asymp.UCL), alpha = 0.1, lwd = 0) +
  geom_text(data = mynames, aes(label = name, x = maxw), y = 0, hjust = 1, vjust = 0, size = 3, fontface = "italic") +
  #geom_errorbar(aes(ymin = response - SE, ymax = response + SE)) +
  ylim(0, 1) +
  labs(x = "Colony width (cm)", y = "Probability of bleaching at 15 DHWs") +
  theme_classic() +
  theme(legend.position = "none",
        strip.text = element_blank(),
        strip.background = element_blank()))

ggsave(filename = "output/sizeplot.png", plot = sizeplot,
       width = 120, height = 100, units = "mm")

# SUBSET FIGURE FOR BIOTA
tdf <- filter(predr, Species %in% c("CNAT", "SINT", "MCAV", "PAST", "PSTR", "SSID")) %>%
  mutate(Species = factor(Species, levels = c("PAST", "SINT", "CNAT", "MCAV", "SSID", "PSTR"))) %>%
  rename(asymp.LCL.x = asymp.LCL) %>%
  semi_join(actual, by = c("Species", "Width2"))
# Get species full names for plotting
mynames2 <- tdf %>%
  left_join(tibble(name = abbrev_names, Species = names(abbrev_names))) %>%
  mutate(Species = factor(Species, levels = c("PAST", "SINT", "CNAT", "MCAV", "SSID", "PSTR"))) %>%
  group_by(Species, name) %>%
  summarize(maxw = max(Width2)) %>%
  distinct(Species, name, maxw)

ggplot(tdf, aes(x = Width2, y = response, group = Species)) +
  coord_trans(x = "log") +
  scale_x_continuous(breaks = c(4, 16, 64, 256), expand = expansion(mult = c(0.05, 0.1))) +
  facet_wrap(~Species, scales = "free_x", labeller = labeller(Species = abbrev_names)) +
  geom_line()+#aes(color = response)) +
  #scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
  #                      limits = c(0, 1), midpoint = 0.5) +
  #geom_ribbon(aes(ymin = asymp.LCL.x, ymax = asymp.UCL), alpha = 0.1, lwd = 0) +
  #geom_text(data = mynames2, aes(label = name, x = maxw), y = 0.6, hjust = 1, vjust = 0, size = 3, fontface = "italic") +
  #geom_errorbar(aes(ymin = response - SE, ymax = response + SE)) +
  #ylim(0, 1) +
  labs(x = "Colony width (cm)", y = "Resistance to bleaching (prevalence)") +
  theme_classic() +
  theme(legend.position = "none",
        strip.text = element_text(face = "italic"),
        strip.background = element_blank())

tdf %>%
  filter(Width2 %in% c(4, 40)) %>%
  group_by(Species) %>%
  summarize(relprob = response[Width2==4] / response[Width2==40]) %>%
  mutate(pctdiff = round((relprob - 1) * 100))

ggsave(filename = "biota_sizediffs_short.png", width = 100, height = 80, units = "mm")


# Ridges?
# ggplot(pred2, aes(x = log(Width2), y = Species)) +
#   #coord_trans(x = "log") +
#   scale_x_continuous(breaks = log(c(4, 16, 64, 256))) +
#   ggridges::geom_ridgeline_gradient(aes(height = response, fill = response), alpha = 0.5) +
#   scale_fill_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
#                         limits = c(0, 1), midpoint = 0.5) +
#   theme_classic()

# Sanity checks for size effects
# Plot actual proportions binned by size class a confirmation
# filter(df23.abund) %>%
#   filter(Species %in% sig$Species) %>%
#   group_by(Species) %>%
#   mutate(Width.bin = cut(log(Width), breaks = 5)) %>%
#   ggplot(aes(x = Width.bin, fill = Bleaching2 > 1)) +
#   geom_bar(position = "fill") +
#   facet_wrap(~Species, scales = "free")

# sanity check on dlab size effect
# dlab <- df23.abund %>%
#   filter(Species == "DLAB")
# ggplot(dlab, aes(x = (Width2 > 25), fill = (Bleaching2 > 1))) +
#   geom_bar(position = "stack") +
#   facet_wrap(~Subregion)

# filter(df23.abund) %>%
#   filter(Species %in% sig$Species) %>%
#   ggplot(aes(x = Bleaching2 > 1, y = Width2)) +
#   geom_jitter(width = 0.1, alpha = 0.1) +
#   geom_violin(draw_quantiles = 0.5, alpha = 0.5) +
#   facet_wrap(~Species, scales = "free_y") +
#   #scale_y_continuous(trans = "log10") +
#   coord_trans(y = "log2")
```

## 2014 - probability at 8 DHWs

```{r size_effects_2014}
# Model bleaching severity by Width, species, and dhw. 
# There are some corals with Width < 4 -- these were included because Height should have been at least 4. In these cases change Width to 4.
df14.abund <- df14 %>%
  group_by(Species) %>%
  dplyr::filter(n() > 30) %>%
  ungroup() %>%
  mutate(Width2 = case_when(Width >= 4 ~ Width,
                            Width < 4 ~ 4)) %>%
  droplevels()

# Fit model
mod <- glmer(Bleaching2 > 1 ~ Species * Width2 * dhw + Week2 + (1|Subregion), 
             family = "binomial", data = df14.abund,
             nAGQ = 0, control = glmerControl(optimizer = "nloptwrap"), verbose = FALSE)
#plot(mod, which = 1)
#summary(mod)

# Test if significant effect of width for each species at DHW = 15
res <- emtrends(mod, specs = c("Species", "dhw"), var = "Width2", at = list(dhw = 8))

# Get significant species
sig <- as.tibble(summary(res, infer = TRUE)) %>%
  filter(p.value < 0.01)

# Get fitted values for bleaching probability as a function of size for significant species
pred <- as.tibble(emmeans(mod, specs = c("Width2", "dhw"), by = "Species", 
                          at = list(Width2 = seq(4,500,1), dhw = 8), 
                          type = "response", rg.limit = 100000)) %>%
  filter(Species %in% sig$Species) %>%
  left_join(dplyr::select(sig, dhw, Species, asymp.LCL), by = c("dhw", "Species"))
# Get actual observed size ranges for these species
actual <- filter(df14.abund) %>%
  drop_na(Species) %>%
  group_by(Species) %>%
  summarize(min = min(Width2, na.rm = T), max = max(Width2, na.rm = T)) %>%
  mutate(ad = map(max, ~expand_grid(Width2 = seq(4, ., 1)))) %>%
  unnest(ad)
pred2 <- pred %>%
  semi_join(actual, by = c("Species", "Width2"))
  
# Get species full names for plotting
mynames <- pred2 %>%
  left_join(tibble(name = abbrev_names, Species = names(abbrev_names))) %>%
  group_by(Species, name) %>%
  summarize(maxw = max(Width2)) %>%
  distinct(Species, name, maxw)
# Plot fitted probabilities within the range of observed Widths for each significant species
(sizeplot <- ggplot(pred2, aes(x = Width2, y = response, group = Species)) +
  coord_trans(x = "log") +
  scale_x_continuous(breaks = c(4, 16, 64, 256), expand = expansion(mult = c(0.05, 0.1))) +
  facet_wrap(~Species, scales = "free_x", labeller = labeller(Species = abbrev_names)) +
  geom_line(aes(color = response)) +
  scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
                        limits = c(0, 1), midpoint = 0.5) +
  geom_ribbon(aes(ymin = asymp.LCL.x, ymax = asymp.UCL), alpha = 0.1, lwd = 0) +
  geom_text(data = mynames, aes(label = name, x = maxw), y = 0, hjust = 1, vjust = 0, size = 3, fontface = "italic") +
  #geom_errorbar(aes(ymin = response - SE, ymax = response + SE)) +
  ylim(0, 1) +
  labs(x = "Colony width (cm)", y = "Probability of bleaching at 10 DHWs") +
  theme_classic() +
  theme(legend.position = "none",
        strip.text = element_blank(),
        strip.background = element_blank()))

# ggsave(filename = "output/sizeplot.png", plot = sizeplot,
#        width = 120, height = 100, units = "mm")


# sanity check on sside size effect
# dlab <- df14.abund %>%
#   filter(Species == "SSID")
# ggplot(dlab, aes(x = (Width2 > 25), fill = (Bleaching2 > 1))) +
#   geom_bar(position = "fill") +
#   facet_wrap(~Subregion)
```

## 2015 - probability at 8 DHWs

```{r size_effects_2015}
# Model bleaching severity by Width, species, and dhw. 
# There are some corals with Width < 4 -- these were included because Height should have been at least 4. In these cases change Width to 4.
df15.abund <- df15 %>%
  group_by(Species) %>%
  dplyr::filter(n() > 30) %>%
  ungroup() %>%
  mutate(Width2 = case_when(Width >= 4 ~ Width,
                            Width < 4 ~ 4)) %>%
  droplevels()

# Fit model
mod <- glmer(Bleaching2 > 1 ~ Species * Width2 * dhw + Week2 + (1|Subregion), 
             family = "binomial", data = df15.abund,
             nAGQ = 0, control = glmerControl(optimizer = "nloptwrap"), verbose = FALSE)
#plot(mod, which = 1)
#summary(mod)

# Test if significant effect of width for each species at DHW = 15
res <- emtrends(mod, specs = c("Species", "dhw"), var = "Width2", at = list(dhw = 8))

# Get significant species
sig <- as.tibble(summary(res, infer = TRUE)) %>%
  filter(p.value < 0.01)

# Get fitted values for bleaching probability as a function of size for significant species
pred <- as.tibble(emmeans(mod, specs = c("Width2", "dhw"), by = "Species", 
                          at = list(Width2 = seq(4,500,1), dhw = 8), 
                          type = "response", rg.limit = 100000)) %>%
  filter(Species %in% sig$Species) %>%
  left_join(dplyr::select(sig, dhw, Species, asymp.LCL), by = c("dhw", "Species"))
# Get actual observed size ranges for these species
actual <- filter(df15.abund) %>%
  drop_na(Species) %>%
  group_by(Species) %>%
  summarize(min = min(Width2, na.rm = T), max = max(Width2, na.rm = T)) %>%
  mutate(ad = map(max, ~expand_grid(Width2 = seq(4, ., 1)))) %>%
  unnest(ad)
pred2 <- pred %>%
  semi_join(actual, by = c("Species", "Width2"))
  
# Get species full names for plotting
mynames <- pred2 %>%
  left_join(tibble(name = abbrev_names, Species = names(abbrev_names))) %>%
  group_by(Species, name) %>%
  summarize(maxw = max(Width2)) %>%
  distinct(Species, name, maxw)
# Plot fitted probabilities within the range of observed Widths for each significant species
(sizeplot <- ggplot(pred2, aes(x = Width2, y = response, group = Species)) +
  coord_trans(x = "log") +
  scale_x_continuous(breaks = c(4, 16, 64, 256), expand = expansion(mult = c(0.05, 0.1))) +
  facet_wrap(~Species, scales = "free_x", labeller = labeller(Species = abbrev_names)) +
  geom_line(aes(color = response)) +
  scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
                        limits = c(0, 1), midpoint = 0.5) +
  geom_ribbon(aes(ymin = asymp.LCL.x, ymax = asymp.UCL), alpha = 0.1, lwd = 0) +
  geom_text(data = mynames, aes(label = name, x = maxw), y = 0, hjust = 1, vjust = 0, size = 3, fontface = "italic") +
  #geom_errorbar(aes(ymin = response - SE, ymax = response + SE)) +
  ylim(0, 1) +
  labs(x = "Colony width (cm)", y = "Probability of bleaching at 10 DHWs") +
  theme_classic() +
  theme(legend.position = "none",
        strip.text = element_blank(),
        strip.background = element_blank()))

# ggsave(filename = "output/sizeplot.png", plot = sizeplot,
#        width = 120, height = 100, units = "mm")


# sanity check on sside size effect
# dlab <- df14.abund %>%
#   filter(Species == "SSID")
# ggplot(dlab, aes(x = (Width2 > 25), fill = (Bleaching2 > 1))) +
#   geom_bar(position = "fill") +
#   facet_wrap(~Subregion)
```

# Code scratchpad below

## Bleaching by subregion across years

```{r regional_bleaching_vs_dhw_by_year_modeledalltogether, eval = FALSE}
# Model bleaching severity by subregion across years
### (This replicates what was done individually by year and then combined -- use THIS.)

subregion.mod <- glmer(cbind(BL, NB) ~ Subregion * year + year:Week2 + (year|Species),
                       family = "binomial", data = allg)

# Get fitted values across dhw
subregion.res <- emmeans(subregion.mod, specs = c("Subregion", "year", "Week2"), 
                         rg.limit = 20000, type = "response")

# Get emmeans for just the specific 2-week windows of interest in each year (corresp. to max. bleaching)
subregion.res2 <- subset(subregion.res,
  (year == "2014" & Week2 == "(36,38]") |
  (year == "2015" & Week2 == "(36,38]") |
  (year == "2023" & Week2 == "(33,35]")
)

as.tibble(subregion.res2) %>%
  ggplot(aes(x =))

regional <- bind_rows(
  `2014` = regional14,
  `2015` = regional15,
  `2023` = regional23,
  .id = "year"
)

as.tibble(subregion.res2) %>%
  left_join(regional, by = c("Subregion", "year")) %>%
  ggplot(aes(x = maxDHW, y = prob.y, shape = year, group = year, color = Subregion)) +
  geom_point(aes(color = Subregion, shape = year), size = 3) +
  geom_smooth(aes(group = year), method = "loess", span = 1.1, se = FALSE)

# This is good, but probably makes more sense to look at bleaching as a function of DHW across years. This is of more general interest than "Subregions"...
```

## Old code....

```{r, eval = F}
# Trying to get overall bleaching (avg across species) but emmeans are nonEst
m <- glm(cbind(BL, NB) ~ year * dhw.bin * Species, family = "binomial", data = allg)
res <- emmeans(m, specs = c("dhw.bin", "year"), type = "response", rg.limit = 15000)
as.tibble(res) %>%
  ggplot(aes(x = dhw.bin, y = prob, color = year, group = year)) +
  geom_point() +
  geom_line()

# Will it work if species is a random factor instead of fixed? YES!!!
library(lme4)
m <- glmer(cbind(BL, NB) ~ year * dhw.bin + (dhw.bin+year|Species), 
           family = "binomial", data = allg)
res <- emmeans(m, specs = c("dhw.bin", "year"), type = "response", rg.limit = 15000)
as.tibble(res) %>%
  ggplot(aes(x = dhw.bin, y = prob, color = year, group = year)) +
  geom_point() +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL), lwd = 0, alpha = 0.2) +
  geom_line()

### NEW: try with Week2 to be able to adjust for that
dhw.bin.mod <- glmer(cbind(BL, NB) ~ dhw.bin * year * Week2 + (dhw.bin+year|Species),
                       family = "binomial", data = allg)
dhw.bin.res <- emmeans(dhw.bin.mod, specs = c("dhw.bin", "year", "Week2"), 
                       rg.limit = 20000, type = "response")
# Get emmeans for just the specific 2-week windows of interest in each year (corresp. to max. bleaching)
dhw.bin.res2 <- subset(dhw.bin.res,
  (year == "2014" & Week2 == "(36,38]") |
  (year == "2015" & Week2 == "(36,38]") |
  (year == "2023" & Week2 == "(33,35]")
)
as.tibble(dhw.bin.res2) %>%
  ggplot(aes(x = dhw.bin, y = prob, color = year, group = year)) +
  geom_point() +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL), lwd = 0, alpha = 0.2) +
  geom_line()

```




```{r}
# Maps of site performance for each year
```



```{r, eval = F}
# Try random forests to find outlier sites or individuals?
load("output/2014.RData")
load("output/2015.RData")
load("output/2023.RData")
df23 <- df23 %>% rename(Depth = EndDepth)
all <- bind_rows(
  `2014` = df14,
  `2015` = df15,
  `2023` = df23,
  .id = "year"
)
library(randomForest)
data <- all %>%
  filter(Species %in% c("CNAT", "DLAB", "MCAV", "OANN", "OFAV", "PAST", "PSTR", "SSID")) %>%
  mutate(Bleaching4 = factor(case_when(Bleaching3 %in% c("Healthy", "Pale") ~ "Healthy",
                                Bleaching3 %in% c("Partially Bleached", "Bleached", "Dead") ~ "Bleached"))) %>%
  droplevels() %>%
  drop_na(year, Species, Depth, dhw) %>%
  group_by(Species) %>%
  filter(n() > 500) %>%
  droplevels()

# Run random forest classification with species, depth, and dhw as predictors
rf <- randomForest(Bleaching4~year+Species+Depth+dhw+Width, 
                   data = data, ntree = 5, do.trace = TRUE, proximity=TRUE)
print(rf)
rf$confusion

str(rf)

# Get rf model predictions for Bleaching4
data <- data %>%
  mutate(pred = rf$predicted)

# How accurate were predictions for each species?
data %>%
  drop_na(pred) %>%
  group_by(Species) %>%
  count(acc = pred == Bleaching4) %>%
  ggplot(aes(x = Species, y = n, fill = acc)) +
  geom_col(position= "fill")

# Can you get confidence?
str(rf)
score(rf)

data %>%
  drop_na(pred) %>%
  ggplot(aes(x = Species, fill = Bleaching4:pred)) +
  geom_bar(position = "fill")
  
  

# Which corals were predicted to be bleached, but were actually healthy?
outhealthy <- data %>%
  filter(pred == "Bleached", Bleaching4 == "Healthy") 

ggplot(outhealthy, aes(x = Longitude, y = Latitude)) +
  geom_point(color = "red", alpha = 0.005, pch = 20)

outhealthy %>%
  filter(Species == "OFAV") %>%
  ggplot(aes(x = Longitude, y = Latitude)) +
  geom_point(aes(color = Species))
```

```{r, eval = FALSE}
# Bleaching vs. dhw for each coral species by year -- binned dhw
# Data are from modeling data for each year separately, using the Week2 period at the peak of each year's bleaching
# Results are nearly (completely?) identical to a singular model fit with year and year:Week2... so use that because it also allows posthoc testing 
sppbleachprob14 <- readRDS(file = "output/sppbleachprob14.rds")
sppbleachprob15 <- readRDS(file = "output/sppbleachprob15.rds")
sppbleachprob23 <- readRDS(file = "output/sppbleachprob23.rds")

sppbleachprob <- bind_rows(`2014` = sppbleachprob14,
                           `2015` = sppbleachprob15,
                           `2023` = sppbleachprob23,
                           .id = "year")

sppbleachprob %>%
  ggplot(aes(x = dhw.bin, y = response, color = year, group = year)) +
  geom_point(position = position_dodge(width = 0.25), size = 0.5) +
  geom_line(position = position_dodge(width = 0.25)) +
  geom_errorbar(aes(ymin = response - SE, ymax = response + SE), width = 0.1,
                position = position_dodge(width = 0.25)) +
  facet_wrap(~Species) +
  ylim(0,1)
```


```{r, eval = F }
# I don't like this
# Overall Bleaching vs. dhw (all corals) by year
bleachprob14 <- readRDS(file = "output/bleachprob14.rds")
bleachprob15 <- readRDS(file = "output/bleachprob15.rds")
bleachprob23 <- readRDS(file = "output/bleachprob23.rds")

bleachprob <- bind_rows(`2014` = bleachprob14,
                        `2015` = bleachprob15,
                        `2023` = bleachprob23,
                        .id = "year")

ggplot(bleachprob, aes(x = dhw, y = response, color = year, group = year)) +
  geom_line() +
  geom_ribbon(aes(ymin = asymp.LCL, ymax = asymp.UCL), lwd = 0, alpha = 0.3) +
  scale_y_continuous(limits = c(0, 1))

# This is more or less the same thing as the breakdown by region above, but I think the regional one is more interesting

# What about doing this by dhw bins?
```

```{r regional_bleaching_vs_dhw_by_year, eval = FALSE}
# This was superseded by modeling this all together for all years instead of each year separately.
# Overall pct. bleaching vs. dhw (all corals) by Subregion for each year
## Subregion averages
load(file = "output/regional23.RData")
load(file = "output/regional14.RData")
load(file = "output/regional15.RData")

df <- bind_rows(`2014` = regional14, `2015` = regional15, `2023` = regional23, .id = "year")

ggplot(df, aes(x = maxDHW, y = prob)) +
  geom_point(aes(color = Subregion, shape = year), size = 3) +
  geom_smooth(aes(group = year), method = "loess", span = 1.1, se = FALSE)

## Why not do this for all sites? Probably would be too all over the place.
```









```{r, eval = F}

###trying to plot "adjusted" bleaching levels for each site -- adjusted for date surveyed
# Can we adjust pctbl for survey date and plot everything? (e.g., Marquesas were in Oct...)
df23.g <- df23 %>%
  group_by(Site, Subregion, Latitude, Longitude, Date, Week2, dhw) %>%
  summarize(BL = sum(Bleaching2 > 1),
            NB = sum(Bleaching2 <= 1))
mod <- glm(cbind(BL, NB) ~ dhw + Week2, family = "binomial", data = df23.g)
plot(mod, which = 1)

df23.g <- df23.g %>%
  ungroup() %>%
  mutate(resid = residuals(mod, type = "response")) %>%
  mutate(adj = (BL/(BL+NB)+resid))

hi <- broom::augment(mod, type.predict = "response") %>%
  mutate(resid2 = residuals(mod, type = "response"),
         adj = .fitted + resid2)

newdat <- tibble(
  Site = df23.g$Site,
  Subregion = df23.g$Subregion,
  pctbl = df23.g$BL / (df23.g$BL + df23.g$NB),
  dhw = df23.g$dhw,
  Longitude = df23.g$Longitude,
  Latitude = df23.g$Latitude,
  Week2 = factor("(33,35]")
)
newdat <- bind_cols(
  newdat,
  fit = predict(mod, type = "response", newdata = newdat)
)

# test <- df23.g %>%
#   mutate(.fitted = predict(mod, type = "response", newdata = newdat),
#          .resid = residuals(mod, type = "response"),
#          actual = BL / (BL + NB),
#          adj = .fitted + .resid)
# View(test)

ggplot(newdat) +
  geom_point(aes(x = Longitude, y = Latitude, fill = fit), 
             alpha = 0.5, stroke = 0.1, pch = 21) +
  scale_fill_gradient2(high = "red", mid = NA, low = "blue", midpoint = 0.5,
                       limits = c(0, 1))

hist(newdat$pctbl)

mod <- glm(cbind(BL, NB) ~ Subregion + Week2, family = "binomial", data = df23.g)
res <- emmeans(mod, specs = c("Subregion"), at = list(Week2 = factor("(33,35]")), type = "response")
test <- as.tibble(res) %>%
  right_join(df23.g) %>%
  mutate(resid = residuals(mod, type = "response"),
         actual = (BL/(BL+NB)),
         adj = actual + resid)

ggplot(test) +
  geom_point(aes(x = Longitude, y = Latitude, fill = actual), 
             alpha = 0.5, stroke = 0.1, pch = 21) +
  scale_fill_gradient2(high = "red", mid = NA, low = "blue", midpoint = 0.5,
                       limits = c(0, 1))
hist(test$adj)
```



```{r, eval = F}
### TRYING TO GET LD50 OR SOMETHING BETTER

spp50.2 <- spp50[spp50.thresh$ind, ]
spp50.2 <- subset(spp50, spp50.thresh$ind)

as.tibble(spp50.2) %>%
  arrange(dhw) %>%
  mutate(Species = fct_reorder(Species, dhw)) %>%
  ggplot(aes(y = Species, x = dhw)) +
  geom_point()


LD <- MASS::dose.p(m2, p = 0.5)

dose.p.glmm <-  function(obj, cf = c(1, 4), p = 0.5) {
  f <- family(obj)
  eta <- f$linkfun(p)
  b <- fixef(obj)[cf]
  x.p <- (eta - b[1L])/b[2L]
  names(x.p) <- paste("p = ", format(p), ":", sep = "")
  pd <- -cbind(1, x.p)/b[2L]
    SE <- sqrt(((pd %*% vcov(obj)[cf, cf]) * pd) %*% c(1, 1))
  res <- structure(x.p, SE = matrix(SE), p = p)
  class(res) <- "glm.dose"
  res
}

dose.p.glmm(m2)
fixef(m2)

library(medrc)
df23f <- df23.abund %>%
  group_by(Site, Subregion, Week2, Species, dhw) %>%
  summarize(BL = sum(Bleaching2 > 1),
            NB = sum(Bleaching2 <= 1),
            pctNB = NB / (NB + BL),
            n = n())

m <- medrm(pctNB ~ dhw, data = df23f, 
           curveid = b + d + e ~ Species,
           random = b + d + e ~ 1|Subregion,
           fct = LL.3(), start = coefs)

lmm <- lm(pctNB ~ dhw, data = df23f)
coefs <- coef(lmm)

sm <- metadrm(pctNB ~ dhw,
              data = df23f,
              fct = LL.3(),
              ind = Species,
              cid2 = Subregion,
              struct = "UN")

ggplot(df23f, aes(x = dhw, y = pctNB)) +
  geom_point() +
  facet_wrap(~Species)
```
