---
title: "DRM bleaching analysis"
author: "R. Cunning"
date: "2024-12-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE)
```

```{r libraries}
# Load libraries
library(sf)
library(sp)
library(gstat)
library(lme4)
library(emmeans)
library(terra)
library(tidyterra)
library(drc)
library(tidyverse)
```

```{r labellers, include = FALSE}
# Create species labeller
species_names <- c(
  AAGA = "Agaricia agaricites",
  AFRA = "Agaricia fragilis",
  AGAR = "Agaricia sp.",
  AGRA = "Agaricia grahamae",
  AHUM = "Agaricia humilis",
  ALAM = "Agaricia lamarcki",
  ACER = "Acropora cervicornis",
  AGAR = "Agaricia sp.",
  APAL = "Acropora palmata",
  APRO = "Acropora prolifera",
  CNAT = "Colpophyllia natans",
  DCYL = "Dendrogyra cylindrus",
  DLAB = "Diploria labyrinthiformis",
  DSTO = "Dichocoenia stokesii",
  EFAS = "Eusmilia fastigiata",
  FFRA = "Favia fragum",
  HCUC = "Helioseris cucullata",
  ISIN = "Isophyllia sinuosa",
  IRIG = "Isophyllia rigida",
  ISOP = "Isophyllia sp.",
  MADR = "Madracis sp.",
  MANG = "Mussa angulosa",
  MARE = "Manicina areolata",
  MAUR = "Madriacis auretenra",
  MCAV = "Montastraea cavernosa",
  MDEC = "Madracis decactis",
  MFER = "Mycetophyllia ferox",
  MALI = "Mycetophyllia aliciae",
  MLAM = "Mycetophyllia lamarckiana",
  MFOR = "Madracis formosa",
  MJAC = "Meandrina jacksoni",
  MMEA = "Meandrina meandrites",
  MSEN = "Madracis senaria",
  MYCE = "Mycetophyllia sp.",
  OANN = "Orbicella annularis",
  OCUL = "Oculina sp.",
  ODIF = "Oculina diffusa",
  OFAV = "Orbicella faveolata",
  OFRA = "Orbicella franksi",
  ORBI = "Orbicella sp.",
  PAST = "Porites astreoides",
  PBRA = "Porites branneri",
  PCLI = "Pseudodiploria clivosa",
  PDIV = "Porites divaricata",
  PFUR = "Porites furcata",
  PORI = "Porites sp.",
  PPOR = "Porites porites",
  PSTR = "Pseudodiploria strigosa",
  SBOU = "Solenastrea bournoni",
  SCOL = "Scolymia sp.",
  SHYA = "Solenastrea hyades",
  SIDE = "Siderastrea sp.",
  SINT = "Stephanocoenia intersepta",
  SOLE = "Solenastrea sp.",
  SRAD = "Siderastrea radians",
  SSID = "Siderastrea siderea",
  UNKN = "Unknown"
)

species_names_2l <- gsub(" ", "\n", species_names)
abbrev_names <- as_tibble(species_names) %>%
  separate(value, into = c("genus", "species"), sep = " ") %>%
  mutate(genus = case_when(species == "sp." ~ genus,
                           species != "sp." ~ gsub("[a-z]+", ".", genus))) %>%
  unite(genus, species, col = "name", sep = " ")
abbrev_names <- c(abbrev_names$name)
names(abbrev_names) <- names(species_names)
```

# Import data

## DRM and DHW data (2014, 2015, 2023)
```{r import_data}
# Load all QC'd data from 2014, 2015, and 2023
load("output/2014.RData")
load("output/2015.RData")
load("output/2023.RData")
df23 <- df23 %>% rename(Depth = EndDepth, Transect = TransectNum)

# Combine all years
all0 <- bind_rows(
  `2014` = df14,
  `2015` = df15,
  `2023` = df23,
  .id = "year"
) %>%
  mutate(dhw.bin = cut(dhw, breaks = c(-1, 3, 6, 9, 12, 15, 18, 22)))

# Count number of sites per subregion per year
nsites <- all0 %>%
  distinct(year, Subregion, Site) %>%
  count(year, Subregion) %>%
  pivot_wider(names_from = year, values_from = n)

# Combine North and South Palm Beach subregions due to low survey numbers
all0 <- all0 %>%
  mutate(Subregion = case_when(Subregion %in% c("North Palm Beach", "South Palm Beach") ~ "Palm Beach",
                               TRUE ~ Subregion))

# Reorder subregion factor levels from north to south
all0 <- all0 %>%
  mutate(Subregion = factor(Subregion, levels = c("Martin", "Palm Beach", "Broward-Miami",
                                                  "Biscayne", "Upper Keys", "Mid-Upper Keys Transition",
                                                  "Middle Keys", "Lower Keys", "Marquesas",
                                                  "Tortugas--Dry Tortugas NP")))

df23 <- all0 %>% filter(year == 2023)

# Plot sites surveyed in each year
all0 %>%
  distinct(year, Subregion, Latitude, Longitude, Site) %>%
  ggplot(aes(x = Longitude, y = Latitude, color = Subregion)) +
  geom_point() +
  facet_wrap(~year)

# Number of corals surveyed each year
all0 %>% count(year)
```

## Symbiont metadata for Florida corals
```{r}
# Import symbiont metadata
library(gsheet)
sheet_url <- "https://docs.google.com/spreadsheets/d/1r1MyUA4Vk50SMjkuRM4XfLcv2-Ve1afp/edit?usp=sharing&ouid=100793581009007740691&rtpof=true&sd=true"
sym0 <- gsheet2tbl(sheet_url)

# Summarize symbiont data (get all genera detected in each spp in Florida)
symsumm <- sym0 %>% 
  filter(location == "FL") %>%
  group_by(Species) %>%
  summarize(domsyms = paste0(unique(most_dom_sym_study), collapse = "")) %>%
  mutate(ngen = nchar(domsyms))

# Aggregate symbiont metadata to match coral taxa to match aggregation in DRM dataset
symsumm.ag <- sym0  %>%
  filter(location == "FL") %>%
  mutate(Species = case_when(Species %in% c("AFRA", "AGAR", "AGRA", "AHUM", "ALAM") ~ "AGAR",
                             Species %in% c("MALI", "MLAM", "MYCE", "MFER") ~ "MYCE",
                             Species %in% c("IRIG", "ISIN", "ISOP") ~ "ISOP",
                             Species %in% c("OCUL", "ODIF") ~ "OCUL",
                             Species %in% c("SHYA", "SBOU") ~ "SOLE",
                             Species %in% c("SCOL", "SCUB", "SLAC", "SWEL") ~ "SCOL",
                             Species %in% c("OFAV", "OFRA", "OANN") ~ "ORBI",
                             TRUE ~ Species)) %>%
  drop_na(Species) %>% 
  group_by(Species) %>%
  summarize(domsyms = paste0(unique(most_dom_sym_study), collapse = "")) %>%
  mutate(ngen = nchar(domsyms)) %>%
  print(n = nrow(.)) %>%
  mutate(D = grepl("D", domsyms)) 
```

```{r}
# Plot surveys vs. DHW
(surveys.by.dhw <- all0 %>%
  distinct(year, Site, Date, Subregion, dhw) %>%
  ggplot(aes(x = dhw, fill = Subregion)) +
  geom_histogram(breaks = seq(0,22,1)) +
  facet_grid(year ~ ., scales = "free_y") +
  theme_classic() +
  labs(x = "Degree Heating Weeks", y = "Number of surveys",
       title = "Timing of surveys relative to heat stress accumulation"))

ggsave(filename = "figures/FigS1.png", plot = surveys.by.dhw, width = 183, height = 90, units = "mm")
```

# Bleaching severity 2023

## Map bleaching (all corals)
```{r map_bleaching}
# Get percent of colonies surveyed that were bleached at each site 
pctbl23 <- df23 %>%
  group_by(Site, Subregion, Latitude, Longitude, Week2) %>%
  summarize(BL = sum(Bleaching2 > 1),
            NB = sum(Bleaching2 <= 1),
            pctbl = BL / (BL + NB)) %>%
  ungroup()

pctbl23 <- pctbl23 %>%
  mutate(n = BL + NB)

# Model proportion of bleached colonies in each subregion in each 2-week window of survey
mod <- glm(cbind(BL, NB) ~ Subregion + Week2, family = "binomial", data = pctbl23)
#mod2 <- glm(cbind(BL, NB) ~ Week2, family = "binomial", data = pctbl23)

# Predict proportion of bleached colonies in each Subregion at weeks 34-35 (Week2 = "(33,35]" => (August 20-September 2))) = peak of bleaching
## Get these Subregion probabilities at this time on the log-odds scale (NOT type = 'response')
res <- emmeans(mod, specs = c("Subregion"), at = list(Week2 = factor("(33,35]")))

# Get residuals for each Site at the time it was surveyed (e.g., difference from Subregion mean at time surveyed)...
# ...and then add these residuals to the Subregion's predicted bleaching probability for Weeks 34-35 (peak of bleaching)
# ...to get predicted bleaching severity at that site, if it had been surveyed at peak of bleaching
pctbl23.adj <- pctbl23 %>%
  # Get residuals on the 'working' /logit scale
  mutate(resid = residuals(mod, type = "working")) %>%
  # Join site residuals with logit means for Subregion at weeks 34-35
  left_join(as_tibble(res)) %>%
  # Add residuals to logit mean for Subregion weeks 34-35, then convert to probability scale
  mutate(adj = emmean + resid,
         ## Function to convert logit to probability
         adjprob = exp(adj) / (1 + exp(adj)))

# Plot adjusted bleaching probabilities by subregion
ggplot(pctbl23.adj, aes(x = Subregion, y = adjprob)) +
  geom_violin() +
  geom_jitter(width = 0.15, height = 0)

# Get median adjusted bleaching prevalence by subregion
pctbl23.adj %>%
  group_by(Subregion) %>%
  summarize(medpctbl23.adj = median(adjprob))

# Summarize bleaching prevalence for north (miami up) and south (biscayne to drto) regions
# # Get confidence intervals on site-level bleaching prevalence by subregion and for all keys/drto
pctbl23.adj <- pctbl23.adj %>%
  mutate(region = case_when(Subregion %in% c("Martin", "Palm Beach", "Broward-Miami") ~ "north",
                              TRUE ~ "south"))
north <- filter(pctbl23.adj, region == "north") %>% pull(adjprob)
south <- filter(pctbl23.adj, region == "south") %>% pull(adjprob)

ggplot(pctbl23.adj, aes(x = region, y = adjprob)) + geom_violin()
#ggplot(pctbl23.adj, aes(x = region, y = pctbl)) + geom_violin()

# Test if bleaching prevalence data are normally distributed
shapiro.test(north) # not normal
shapiro.test(south) # not normal

median(north)
quantile(north, c(0.25, 0.75))
IQR(north)
mad(north)

median(south)
quantile(south, c(0.25, 0.75))
mad(south)
```

```{r interpolation}
# Interpolate percent bleaching for whole reef tract
# https://geobgu.xyz/r/spatial-interpolation-of-point-data.html

# Create SpatialPointsDataFrame of survey sites
sites23 <- pctbl23.adj %>%
  distinct(Site, Longitude, Latitude, adjprob)
spdat <- sp::SpatialPointsDataFrame(
    coords=sites23[,c('Longitude','Latitude')], 
    data=sites23[,c('Site', 'adjprob')], 
    proj4string = CRS("+init=epsg:4326")
)

# Create empty raster to hold interpolated values
samplegrid <- raster::raster(spdat, res = c(0.005, 0.005))
raster::crs(samplegrid) <- raster::crs(spdat) <- sp::CRS("+init=epsg:4326")
# Run interpolation
idw.model <- gstat(formula=spdat$adjprob~1, locations=spdat, weights = pctbl23.adj$n)
idw.spp <- raster::interpolate(samplegrid, idw.model)

# Clip interpolated raster to just area of hull/polygon surrounding the reef tract
# Create hull/polygon surrounding surveyed sites
pts1 <- st_as_sf(x = sites23, coords = c('Longitude', 'Latitude'))
my_hull <- st_concave_hull(st_union(pts1), ratio = 0.09)
my_hull <- st_buffer(my_hull, dist = 0.015)
my_hull <- my_hull %>% st_set_crs(4326)
idw.spp.reef <- raster::mask(idw.spp, (as_Spatial(my_hull)))

# Convert clipped interpolation to spatraster for plotting
x <- rast(idw.spp.reef)

# PLOT
# Download satellite map for Florida
world <- rnaturalearth::ne_countries(scale = "large", returnclass = "sf")
# Create base map of Florida
basemap <- ggplot() +
  geom_sf(data = world, lwd = 0.1, fill = "gray90") +
  coord_sf(xlim = c(-83.2, -79.8), ylim = c(24.3, 27.3), expand = FALSE) +
  scale_fill_gradient2(high = "firebrick1", mid = "yellow", low = "forestgreen", 
                       midpoint = 0.5, limits = c(0, 1), na.value = NA,
                       labels = scales::label_percent(), name = "Corals\nbleached") +
  theme(text = element_text(size = 10),
        axis.title = element_blank(),
        panel.background = element_rect(fill = "lightsteelblue1"),
        panel.border = element_rect(colour = "black", fill=NA),
        panel.grid = element_blank(),
        legend.position = c(0.2, 0.5),
        legend.background = element_blank())

# Map with interpolated raster
rasterplot <- basemap +
  geom_spatraster(data = x) +
  geom_sf(data = world, lwd = 0.1, fill = "gray90") +
  coord_sf(xlim = c(-83.2, -79.8), ylim = c(24.3, 27.3), expand = FALSE)

ggsave(filename = "figures/Fig1.png", plot = rasterplot, width = 90, height = 90, units = "mm")
```

## Map DHWs
```{r map_dhw}
dhw <- read_csv("data/dhw/2023/dhw_processed.csv") %>%
  mutate(across(where(is.character), as_factor)) %>%
  rename(Date = date) %>%
  dplyr::select(Site, Date, dhw)

maxdhw <- dhw %>%
  group_by(Site) %>%
  summarize(maxdhw = max(dhw)) %>%
  right_join(sites23, by = "Site")

# Create SpatialPointsDataFrame of survey sites
dhwdat <- sp::SpatialPointsDataFrame(
    coords=maxdhw[,c('Longitude','Latitude')], 
    data=maxdhw[,c('Site', 'maxdhw')], 
    proj4string = CRS("+init=epsg:4326")
)

# Create empty raster to hold interpolated values
dhwgrid <- raster::raster(dhwdat, res = c(0.005, 0.005))
raster::crs(dhwgrid) <- raster::crs(dhwdat) <- sp::CRS("+init=epsg:4326")
# Run interpolation
dhw.idw.model <- gstat(formula=dhwdat$maxdhw~1, locations=dhwdat)
dhw.idw.spp <- raster::interpolate(dhwgrid, dhw.idw.model)
# Clip
dhw.idw.spp.reef <- raster::mask(dhw.idw.spp, (as_Spatial(my_hull)))

# Convert clipped interpolation to spatraster for plotting
x2 <- rast(dhw.idw.spp.reef)

dhwmap <- basemap +
  geom_spatraster(data = x2) +
  geom_sf(data = world, lwd = 0.1, fill = "gray90") +
  coord_sf(xlim = c(-83.2, -79.8), ylim = c(24.3, 27.3), expand = FALSE) +
  scale_fill_distiller(palette = "Spectral", 
                       limits = c(0, 23), na.value = NA,
                       name = "Max.\nDHW      ")

# Save DHW map as supplementary figure
ggsave(filename = "figures/FigS2.png", plot = dhwmap, width = 90, height = 90, units = "mm")

```

## Species variation in bleaching

### Species ED50s
```{r bleaching_by_species, fig.width = 5, fig.height = 6}
## Modeling species-level bleaching susceptibility vs. dhw
# Get subsetted dataset of coral species observed >80 times
df23.abund <- df23 %>%
  group_by(Species) %>%
  filter(n() > 80)
df23f <- df23.abund %>%
  group_by(Site, Subregion, Week2, Species, dhw) %>%
  summarize(BL = sum(Bleaching2 > 1),
            NB = sum(Bleaching2 <= 1),
            pctNB = NB / (NB + BL),
            n = n()) %>%
  drop_na() %>%
  droplevels()

#### DRC (tried 3par, 4par, and 5par -- all work, just slight diffs. )
# More pars = less estimable standard errors on ED50... depends how important ED50 inference is
m3 <- drm(pctNB ~ dhw, data = df23f, curveid = Species, weights = n, type = "binomial",
         logDose = NULL, fct = LL.5(
           names = c("hill", "min", "max", "ED50", "f"),
           ## Max parameter is fixed to 1, min is set to 0
           fixed = c(NA, 0, 1, NA, NA)),
    # Hill parameter must be positive (must decrease with incr. dhw)
    #lowerl = c(rep(0, 22), rep(-Inf, 22), rep(0, 22), rep(-Inf, 22)),
    control = drmc(relTol = 1e-7))
AIC(m3)

# Get fitted values
nd <- expand.grid(Species = levels(df23f$Species), dhw = seq(0, 23, 0.1))
pred <- predict(m3, newdata = nd)
drc.res <- as_tibble(bind_cols(nd, prob = pred))
drc.ord <- ED(m3, 0.5, type = "absolute", display = FALSE) %>%
  as_tibble() %>%
  mutate(Species = levels(df23f$Species),
         Species = fct_reorder(Species, Estimate))

# Stats on ED50s
# compParm(m3, "ED50", operator = "-")

# Extract slopes? coef 'hill'
# coef(m3)

# # # Sanity check barplot
# ggplot(df23.abund, aes(x = cut(dhw, breaks = seq(0,24,3)), fill = Bleaching3)) +
#   geom_bar(position = "fill") +
#   geom_text(stat = "count", aes(label = after_stat(count)), vjust = "inward", position = "fill", size = 2) +
#   facet_wrap(~Species, scales = "free_y")


# Ridgeline plot
drc.res.ridges <- drc.res %>%
  mutate(Species = factor(Species, levels = levels(drc.ord$Species))) %>%
  ggplot(aes(x = dhw, y = Species)) +
  ggridges::geom_ridgeline_gradient(aes(height = (1 - prob), fill = prob)) +
  scale_y_discrete(labels = species_names[as.character(drc.ord$Species)]) +
  scale_fill_gradient2(high = "forestgreen", mid = "yellow", low = "firebrick1", 
                       limits = c(0, 1), midpoint = 0.5) +
  geom_point(data = drc.ord, aes(x = Estimate), pch = 5, size = 0.5) +
  theme_classic() +
  theme(legend.position = "none",
        axis.text.y = element_text(face = "italic")) +
  labs(x = "Degree Heating Weeks", y = "")

# Save as Figure2
ggsave(filename = "figures/Fig2.png", plot = drc.res.ridges,
       width = 100, height = 120, units = "mm")
```


### Within-species variation (ED90-ED10)
```{r within_spp_bleaching_variability, fig.width = 8, fig.height = 5}
# Tolerance range within species - from 10% to 90% of colonies bleached, by Species
span1090 <- drc.res %>%
  group_by(Species) %>%
  slice(which.min(abs(prob - 0.9)),
        which.min(abs(prob - 0.1))) %>%
  summarize(min = min(dhw), max = max(dhw)) %>%
  mutate(span = max - min) %>%
  arrange(-span)

# # Calculate percent of colonies of each species bleached at 23 DHW
# pbleach <- drc.res %>%
#   filter(dhw == 23) %>%
#   mutate(pbleach = 1 - prob)

# Join within-species variation with symbiont metadata
out <- drc.ord %>%
  left_join(span1090) %>%
  left_join(symsumm)

# Plot species' range vs. ed50, size points by number of symbiont genera
set.seed(12344)
plot1090 <- ggplot(out, aes(x = Estimate, y = span)) +
  geom_point(aes(size = ngen^4), alpha = 0.7) + #, color = most_dom_sym)) +
  #geom_point(aes(color = factor(n_symbiont_genera))) +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]),
                           fontface = "italic", size = 3, lineheight = 0.75) +
  labs(x = "Median tolerance (DHW ED50)",
       y = "Range in tolerance (DHW ED90 - ED10)") +
  theme_classic() +
  scale_size_continuous(breaks = c(1^4,2^4,3^4,4^4)) +
  theme(legend.position = "none")

ggsave(filename = "figures/Fig3.png", plot = plot1090, width = 90, height = 90, units = "mm")




# Test relationship between number of symbiont genera and tolerance range
mod <- lm(span ~ ngen, data = out)
p_value <- summary(mod)$coefficients[2, 4]

set.seed(1231)
ngen <- ggplot(out, aes(x = ngen, y = span)) +
  geom_point() +
  stat_smooth(geom = "line", method = "lm", se = FALSE, alpha = 0.3, linewidth = 1) +
  ggpubr::stat_cor() +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]),
                           fontface = "italic", size = 4, lineheight = 0.75) +
  labs(x = "Number of Symbiodiniaceae genera", y = "Intraspecific bleaching variability (ED90-ED10)") +
  theme_classic()

ggsave(filename = "figures/FigS3.png", plot = ngen, width = 140, height = 120, units = "mm")
```


# Temporal shifts in bleaching, 2014-15-23

```{r aggregate_subset_data}
# Aggregate Agaricia spp. other than AAGA, Mycetophyllia spp., Isophyllia spp., Oculina spp., Solenastrea spp., Scolymia spp.
all1 <- all0 %>%
  mutate(Species = case_when(Species %in% c("AFRA", "AGAR", "AGRA", "AHUM", "ALAM") ~ "AGAR",
                             Species %in% c("MALI", "MLAM", "MYCE", "MFER") ~ "MYCE",
                             Species %in% c("IRIG", "ISIN", "ISOP") ~ "ISOP",
                             Species %in% c("OCUL", "ODIF") ~ "OCUL",
                             Species %in% c("SHYA", "SBOU") ~ "SOLE",
                             Species %in% c("SCOL", "SCUB", "SLAC", "SWEL") ~ "SCOL",
                             Species %in% c("OFAV", "OFRA", "OANN") ~ "ORBI",
                             TRUE ~ Species)) %>%
  drop_na(Species)

# Keep only those species observed at least 20 times in each year
spp_to_include <- all1 %>%
  count(Species, year) %>%
  group_by(Species) %>%
  dplyr::filter(min(n) >= 20)  # 20 is a good cutoff

allf <- all1 %>%
  filter(Species %in% spp_to_include$Species)

## Group data at species+site-level to fit group-level models instead of subject-level models -- fits faster
allg <- allf %>%
  group_by(year, Week2, Subregion, Site, dhw, dhw.bin, Species) %>%
  summarize(BL = sum(Bleaching2 > 1),
            NB = sum(Bleaching2 <= 1)) %>%
  ungroup()

# How many observations including 2014/2015/2023 filtered?
nrow(allf)
allf %>% count(year)
```

## All corals - ED50s (glmer)
```{r bleaching_by_dhw_across_years}
# Model differences in bleaching severity between years with DHW as continuous predictor
dhw.mod <- glmer(cbind(BL, NB) ~ dhw + year + year:Week2 + (dhw + year | Species) + (year | Subregion),  
                     family = "binomial", data = allg, verbose = FALSE,
                     nAGQ = 0, control = glmerControl(optimizer = "nloptwrap"))

# Function to get DHW's that cause 50% bleaching for each year
ed50s.fun <- function(dhw.mod) {
  dhw.res <- emmeans(dhw.mod, specs = c("dhw", "year", "Week2"), type = "response",
                     at = list(dhw = seq(0, 23, 0.01), Week2 = c("(36,38]", "(33,35]")), 
                     rg.limit = 20000, level = 0.84)
  dhw.res2 <- subset(dhw.res,
                     (year == "2014" & Week2 == "(36,38]") |
                     (year == "2015" & Week2 == "(36,38]") |
                     (year == "2023" & Week2 == "(33,35]"))
  bleach50 <- as.tibble(dhw.res2) %>%
    group_by(year) %>%
    slice(which.min(abs(prob - 0.5))) %>%
    pull(dhw)
  diff2015 <- bleach50[2]-bleach50[1]
  diff2023 <- bleach50[3]-bleach50[1]
  res <- c(bleach50, diff2015, diff2023)
  res <- setNames(res, c("2014", "2015", "2023", "2015-2014", "2023-2014"))
  return(res)
}

# Get point estimates for ED50s (DHW's that cause 50% bleaching)
bleach50 <- ed50s.fun(dhw.mod)
bleach50

# Bootstrap the calculation of ED50
## re.form = NA: does not account for random effects (conf interval), re.form = NULL: does (prediction interval)
## https://stackoverflow.com/questions/67098467/on-the-predict-mermod-function-arguments
# boot.out <- bootMer(dhw.mod, FUN = ed50s.fun, nsim = 200, seed = 123, re.form = NULL,
#                     parallel = "multicore", ncpus = 20)
# saveRDS(boot.out, file = "output/boot.out.rds")
boot.out <- readRDS(file = "output/boot.out.rds")
## Get confidence intervals from Bootstrap
lower <- apply(boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE)))
upper <- apply(boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))
se <- apply(boot.out$t, 2, sd)

ed50conf <- tibble(
  year = names(bleach50), 
  ed50 = bleach50,
  se = se,
  lower = lower,
  upper = upper)


# For plotting, Get emmeans for just the specific 2-week windows of interest in each year (corresp. to max. bleaching), And select just the range of peak DHWs experienced across sites in each year
# Get max and min DHW for conducted surveys as bounds
all0 %>% group_by(year) %>%
  summarize(maxdhw = max(dhw),
            mindhw = min(dhw))
dhw.res <- emmeans(dhw.mod, specs = c("dhw", "year", "Week2"), type = "response",
                   at = list(dhw = seq(0, 23, 0.1)), rg.limit = 20000, level = 0.84)
dhw.res2 <- subset(dhw.res,
  (year == "2014" & Week2 == "(36,38]" & dhw <= 8.11 & dhw > 0.48) |
  (year == "2015" & Week2 == "(36,38]" & dhw <= 8.90 & dhw > 0) |
  (year == "2023" & Week2 == "(33,35]" & dhw <= 21.5 & dhw > 1.06) 
)

# Plot
(dhw.bleach.plot <- ggplot(as.tibble(dhw.res2), aes(x = dhw, y = prob, group = year)) +
  # Add lines and conf intervals for each year
  geom_ribbon(aes(ymin = prob - SE, ymax = prob + SE), lwd = 0, alpha = 0.1) +
  geom_line(aes(color = prob), lwd = 2) +
  geom_text(data = slice(ed50conf, 1:3), 
            aes(x = c(8,9.5,20.5), y = c(0.8, 0.65, 0.97), label = year)) +
  # Add line segments at ED50s
  geom_segment(data = slice(ed50conf, 1:3),
               aes(x = ed50, xend = ed50, y = 0.492, yend = 0), lty = 2, lwd = 0.2) +
  geom_point(data = slice(ed50conf, 1:3), aes(y = 0.5, x = ed50), pch = 1, stroke = 0.2) +
  # Annotate increase in heat tolerance
  annotate("segment", x = 3.9, xend = 11.5, y = 0.05, lwd = 0.2, 
           arrow = arrow(type = "closed", length = unit(3, "mm"))) +
  annotate("text", x = 11.7, y = 0.082, hjust = 0, size = 3, label = "Bleaching threshold\n+7.6 DHW = +0.97°C") +
  # Annotate extreme bleaching in 2023
  # annotate("point", x = 21.4, y = 0.906, pch = 1, stroke = 0.2) +
  # annotate("segment", x = 21.4, y = 0.9, yend = 0.47, lty = 2, lwd = 0.2) +
  # annotate("text", x = 21.2, y = 0.51, hjust = 1, size = 3, label = "Extreme bleaching\n>2x threshold") +
  scale_x_continuous(limits = c(-1, 22), breaks = seq(0, 24, 4), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0), breaks = seq(0, 1, 0.1), 
                     labels = scales::label_percent()) +
  scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
                        limits = c(0, 1), midpoint = 0.5) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(x = "Degree Heating Weeks (°C-weeks)", y = "Bleaching prevalence") +
  coord_cartesian(clip = "off"))

# Add error bars (± SE) around ED50 estimates
# dhw.bleach.plot +
#   geom_errorbar(data = slice(ed50conf, 1:3),
#                aes(x = ed50, y = 0.5, xmin = ed50 - se, xmax = ed50 + se),
#                width = 0.02, alpha = 0.5)

# Save plot
ggsave(filename = "figures/Fig4.png", plot = dhw.bleach.plot, width = 100, height = 90, units = "mm")
```


## All corals - ∆ED50, ∆°C
```{r change_degC_thresh}
# Specify degC per DHW
degC.per.DHW <- 0.1273714

# Back-calculate change in ed50s (DHW) to change in tolerance (°C) 
degC <- ed50conf %>%
  filter(year %in% c("2023-2014", "2015-2014")) %>%
  mutate(ed50.degC = ed50 * degC.per.DHW,
         se.degC = se * degC.per.DHW,
         lower.degC = lower * degC.per.DHW,
         upper.degC = upper * degC.per.DHW) %>%
  separate(year, into = c("year", "2014"))

# Plot overall change in heat tolerance relative to 2014 in degC
degC %>%
  select(year, ed50.degC, se.degC, lower.degC, upper.degC) %>%
  ggplot(aes(x = year, y = ed50.degC)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower.degC, ymax = upper.degC), width = 0.2) +
  ylim(0, 1.2) +
  labs(y = "Change in heat tolerance from 2014 (°C)") +
  theme_classic()

# Change over time from 2014-2023 in degC
ed50conf %>%
  filter(year == "2023-2014") %>%
  mutate(across(c("ed50", "se", "lower", "upper"), ~ . * degC.per.DHW, .names = "{.col}.degC"))

# 0.97°C [95% C.I. = 0.777-1.06°C]
```

## Species - ∆ED50 2014-15-23

```{r species_bleaching_by_year_dhw, fig.width = 7, fig.height = 7}
# Model differences in bleaching severity between years with DHW
dhw.sp.mod <- glmer(
  cbind(BL, NB) ~ Species + dhw + Species:dhw + year + Species:year + year:Week2 + (year|Subregion),  
  family = "binomial", data = allg, verbose = FALSE,
  nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))
#### relevant reading: https://stats.oarc.ucla.edu/stata/seminars/deciphering-interactions-in-logistic-regression/#:~:text=If%20the%20differences%20are%20not,or%20odds%20ratios%20or%20probability%3F

# Get emmeans for just the specific 2-week windows of interest in each year (corresp. to max. bleaching)
# And select just the range of peak DHWs experienced across sites in each year
dhw.sp.res <- emmeans(dhw.sp.mod, specs = c("Species", "dhw", "year", "Week2"), type = "response",
                      at = list(dhw = seq(0, 23, 0.05), Week2 = c("(36,38]", "(33,35]")), 
                      rg.limit = 200000, level = 0.84)
dhw.sp.res2 <- subset(dhw.sp.res,
  (year == "2014" & Week2 == "(36,38]" & dhw <= 8.11 & dhw > 0.48) |
  (year == "2015" & Week2 == "(36,38]" & dhw <= 8.90 & dhw > 0) |
  (year == "2023" & Week2 == "(33,35]" & dhw <= 21.5 & dhw > 1.06) 
)
dhw.sp.res22 <- subset(dhw.sp.res,
  (year == "2014" & Week2 == "(36,38]") |
  (year == "2015" & Week2 == "(36,38]") |
  (year == "2023" & Week2 == "(33,35]")
)

# Plot
(dhw.sp.bleach.plot <- ggplot(as.tibble(dhw.sp.res2), aes(x = dhw, y = prob, group = year)) +
  facet_wrap(~Species, labeller = labeller(Species = abbrev_names)) +
  geom_ribbon(aes(ymin = prob - SE, ymax = prob + SE), lwd = 0, alpha = 0.2) +
  geom_line(aes(color = year), lwd = 0.5, alpha = 0.9) +
  geom_hline(aes(yintercept = 0.5), lty = 2, lwd = 0.25) +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0), breaks = seq(0, 1, 0.25),
                     labels = scales::label_percent()) +
  # scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
  #                       limits = c(0, 1), midpoint = 0.5) +
  theme_classic() +
  theme(legend.position = c(0.8, 0.04),
        legend.direction = "horizontal",
        strip.background = element_blank(),
        strip.text = element_text(face = "italic")) +
  labs(x = "Degree Heating Weeks (°C-weeks)", y = "Bleaching prevalence", color = "") +
  coord_cartesian(clip = "off"))

ggsave(filename = "figures/FigS4.png", plot = dhw.sp.bleach.plot, width = 140, height = 140, units = "mm")


# Function to get ED50s (DHW's that cause 50% bleaching for each year for each species) AND
## change in ED50s from 2014-2015, and 2014-2023
sp.ed50s.fun <- function(dhw.sp.mod) {
  dhw.sp.res <- emmeans(dhw.sp.mod, specs = c("Species", "dhw", "year", "Week2"), type = "response",
                   at = list(dhw = seq(0, 23, 0.05), Week2 = c("(36,38]", "(33,35]")), 
                   rg.limit = 200000, level = 0.84)
  dhw.sp.res22 <- subset(dhw.sp.res,
    (year == "2014" & Week2 == "(36,38]") |
    (year == "2015" & Week2 == "(36,38]") |
    (year == "2023" & Week2 == "(33,35]") 
  )
  bleach50 <- as.tibble(dhw.sp.res22) %>%
    group_by(Species, year) %>%
    slice(which.min(abs(prob - 0.5)))
  bleachdiffs <- bleach50 %>%
    group_by(Species) %>%
    summarize("2015-2014" = dhw[year=="2015"] - dhw[year=="2014"],
              "2023-2014" = dhw[year=="2023"] - dhw[year=="2014"]) %>%
    pivot_longer(2:3)
  names <- c(paste(bleach50$Species, bleach50$year), paste(bleachdiffs$Species, bleachdiffs$name))
  vals <- c(bleach50$dhw, bleachdiffs$value)
  vals <- setNames(vals, names)
  return(vals)
}

# Get point estimates for ED50s and ∆ED50s
sp.bleach50 <- sp.ed50s.fun(dhw.sp.mod)

# Bootstrap ED50s for SE/confidence intervals
## re.form = NA: does not account for random effects (conf interval), re.form = NULL: does (prediction interval)
## https://stackoverflow.com/questions/67098467/on-the-predict-mermod-function-arguments
# sp.boot.out <- bootMer(dhw.sp.mod, FUN = sp.ed50s.fun, nsim = 1000, seed = 123, re.form = NULL,
#                        parallel = "multicore", ncpus = 20)
# saveRDS(sp.boot.out, file = "output/sp.boot.out.rds")
sp.boot.out <- readRDS(file = "output/sp.boot.out.rds")
## Get confidence intervals from Bootstrap
sp.lower <- apply(sp.boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.025, na.rm=TRUE)))
sp.upper <- apply(sp.boot.out$t, 2, function(x) as.numeric(quantile(x, probs=.975, na.rm=TRUE)))
## Get standard error from Bootstrap
sp.se <- apply(sp.boot.out$t, 2, sd)

sp.ed50conf <- tibble(
  year = names(sp.bleach50), 
  ed50 = sp.bleach50,
  se = sp.se,
  lower = sp.lower,
  upper = sp.upper) %>%
  separate(year, into = c("Species", "year"), sep = " ")

# # Plot ED50s for each species for each year
# sp.ed50conf %>%
#   filter(year %in% c("2014", "2015", "2023")) %>%
#   ggplot(aes(x = year, y = ed50)) +
#     geom_point() +
#     geom_errorbar(aes(ymin = ed50 - se, ymax = ed50 + se), width = 0.2) +
#     facet_wrap(~Species, scales = "free_y") +
#     labs(y = "ED50 (DHWs to 50% bleaching)") +
#     theme_classic()
```

### ∆ED50 --> ∆°C
```{r sp.changeED50, fig.width = 7, fig.height = 8}
degC.per.DHW <- 0.1273714
# Convert ∆ED50s to degC
sp.degC <- sp.ed50conf %>%
  filter(year %in% c("2015-2014", "2023-2014")) %>%
  mutate(across(c("ed50", "se", "lower", "upper"), ~ . * degC.per.DHW, .names = "{.col}.degC")) %>%
  separate(year, into = c("year", "2014"))

# # Plot ED50 vs. year for all Species
# sp.ed50conf %>%
#   filter(year %in% c("2014", "2015", "2023")) %>%
#   ggplot(aes(x = as.numeric(year), y = ed50)) + 
#   geom_point() +
#   #geom_errorbar(aes(ymin = lower, ymax = upper)) +
#   #geom_smooth(method = "lm", se = FALSE) +
#   geom_path(data = filter(sp.ed50conf, year != "2015")) +
#   facet_wrap(~Species) +
#   theme_classic()

# Get net change in ∆DHW/year from 2014 - 2023, convert to degC
nets <- sp.ed50conf %>%
  filter(year == "2023-2014") %>%
  mutate(neted50 = ed50, neted50.SE = se) %>%
  dplyr::select(Species, neted50, neted50.SE) %>%
  mutate(degC = neted50 * degC.per.DHW, degC.se = neted50.SE * degC.per.DHW) %>%
  dplyr::select(Species, degC, degC.se)

# Plot change in tolerance for all Species
findat <- nets %>%
  mutate(Species = fct_reorder(Species, degC)) 

(finplot <- findat %>%
  ggplot(aes(x = Species, y = degC)) +
  geom_point() +
  #geom_errorbar(aes(ymin = lower.degC, ymax = upper.degC), width = 0) +
  geom_errorbar(aes(ymin = degC - degC.se, ymax = degC + degC.se), width = 0.2) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(y = "Change in heat tolerance (°C)        "))

ggsave(finplot, filename = "figures/FigS5.png", width = 100, height = 100, units = "mm")
```

### ∆°C vs. density + symbionts

```{r bleachthresh_vs_density, fig.width = 10}
#densres <- readRDS("output/density.rds")
densdiffs <- readRDS("output/dens20142023.rds")

# Combine net changes in heat tolerance with changes in density and levels of symbiont diversity across species
net <- findat %>%
  left_join(select(as.tibble(densdiffs), Species, estimate, SE)) %>%
  left_join(symsumm.ag) %>%
  drop_na(estimate)

# Model change in tolerance vs. change in density
# Passing Bablok regression
PBreg <- mcr::mcreg(net$estimate+3, net$degC+3,
               method.reg = "PaBa",  method.ci = "bootstrap", nsamples = 9999)
summary(PBreg)

PBfit <- mcr::calcResponse(PBreg, x.levels = seq(1.645, 4.178, 0.1), 
                      alpha = 0.1) %>% as_tibble()
PBfit <- PBfit %>%
  mutate(estimate = X - 3, degC = Y - 3)

# Plot
myticks <- c(-0.9, -0.75, -0.5, -0.25, 0, 0.5, 1, 2)
myticks2 <- log(myticks + 1)
set.seed(8)
library(RColorBrewer)


(dens_sym_viz <- net %>%
  ggplot(aes(x = estimate, y = degC)) + 
  geom_line(data = PBfit, color = "black", lwd = 1, alpha = 0.4) +
  geom_errorbar(aes(ymin = degC - degC.se, 
                    ymax = degC + degC.se), width = 0, alpha = 0.7, lwd = 0.3) +
  geom_errorbar(aes(xmin = estimate - SE, xmax = estimate + SE), width = 0, alpha = 0.7, lwd = 0.3) +
  geom_point(aes(color = factor(ngen)), size = 4, alpha = 0.7, stroke = 0) + 
  
  #geom_smooth(method = "lm", se = FALSE) +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]),
                           fontface = "italic", size = 3, lineheight = 0.75) +
  scale_x_continuous(labels = ~ paste0(round(100 * (exp(.x) - 1), 0), "%"), breaks = myticks2) +
  scale_color_brewer(name = "Symbiont\nGenera",
                     palette = "RdYlBu", direction = -1,
                     na.translate = FALSE) +
  labs(x = "Change in population size (2014-2023)", 
       y = "Change in bleaching threshold (°C)") +
  theme_classic() +
  theme(legend.position = c(0.075,0.1),
        legend.key.spacing.x = unit(1, "mm"),
        legend.key.spacing.y = unit(-3, "mm"), 
        legend.spacing.y = unit(-5, "mm"),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 8, margin = margin(b = -2)),
        legend.margin = margin(-10, 0, 0, 0),
        legend.background = element_blank(),
        legend.key = element_blank()) +
   guides(
    color = guide_legend(
      reverse = TRUE,
      title.hjust = 0.5,  # Further adjusts alignment
      override.aes = list(size = 3)  # Adjusts point size in legend
    )))



# For main text: use this fig showing absolute degC and estimate on x-axis and ngen as color.
# Then, model and produce effect plots for either supplement or as multipanel?



# STATISTICALLY MODEL DENSITY AND SYMBIONT EFFECTS

# Remove missing values
net_clean <- na.omit(net[, c("Species", "degC", "estimate", "ngen", "degC.se", "SE", "D")])

# Center ngen so that the intercept represents `degC = 0` when `estimate = 0` and `ngen = 1`
net_clean$ngen_centered <- net_clean$ngen - 1

# Fit the model, with intercept zero at estimate = 0 and ngen = 1
#  Weight observations using the standard error of the degC response
ols_model_adjusted <- lm(degC ~ 0 + estimate + ngen_centered, data = net_clean, weights = 1/degC.se^2)
# Check intercept
predict(ols_model_adjusted, newdata = data.frame(estimate = 0, ngen_centered = 0))
# Check residuals
#plot(ols_model_adjusted)

# Check model summary
(summary_ols <- summary(ols_model_adjusted))

# Extract model coefficients
ols_slope_estimate <- coef(ols_model_adjusted)["estimate"]
ols_slope_ngen <- coef(ols_model_adjusted)["ngen_centered"]

# Compute contributions of each predictor
net_clean$Estimate_Contribution <- ols_slope_estimate * net_clean$estimate
net_clean$Ngen_Contribution <- ols_slope_ngen * (net_clean$ngen - 1)

# Compute residual variation (unexplained variation)
net_clean$Unexplained_Variation <- net_clean$degC - (net_clean$Estimate_Contribution + net_clean$Ngen_Contribution)

# Verify that the sum matches observed degC exactly
net_clean$Check_Sum <- net_clean$Estimate_Contribution + net_clean$Ngen_Contribution + net_clean$Unexplained_Variation
all.equal(net_clean$Check_Sum, net_clean$degC)  # Should return TRUE

# Plot contributions of each predictor to observed degC values
out <- net_clean %>%
  select("Species", "degC", "degC.se", 
         "Estimate_Contribution", "Ngen_Contribution", "Unexplained_Variation") %>%
  pivot_longer(cols = 4:6) %>%
  arrange(degC) %>%
  mutate(Species = fct_reorder(Species, degC))

(decomp <- ggplot(out, aes(x = Species, y = value, fill = name)) +
  geom_col(position = "stack", alpha = 1) +
  geom_point(aes(y = degC, shape = "Net change (±SE)"), size = 2) +
  geom_errorbar(aes(ymin = degC - degC.se, ymax = degC + degC.se), width = 0) +
  scale_x_discrete(labels = abbrev_names[as.character(out$Species)]) +
  scale_fill_manual(name = "Modeled contributions", 
                      labels = c("Population size", "Symbiont genera", "Unexplained"),
                      values = c("#67a9cf", "#ef8a62", "#C0C0C0")) +
  scale_shape_manual(name = "", values = 16) +
  theme_classic() +
  theme(axis.text.x = element_text(face = "italic", angle = 45, hjust = 1, size = 10),
        axis.title.y = element_text(size = 12),
        legend.text = element_text(size = 10),  # Decrease legend text size
        legend.title = element_text(size = 10),  # Decrease legend title size
        legend.key.size = unit(0.4, "cm"),  # Reduce legend key size
        legend.spacing.y = unit(-0.2, "cm")) +  # Reduce vertical space between legend items +
  theme(legend.position = c(0.12, 0.86),
        legend.background = element_blank(),  # Transparent legend panel
        legend.key = element_blank()) +
  labs(x = "", y = "Change in bleaching threshold (°C)") +
  guides(fill = guide_legend(ncol = 1, override.aes = list(shape = NA)),
         shape = guide_legend(order = 1, label.theme = element_text(size = 10))))

# Create partial residual effect plots showing density changes and symbiont diversity effects while controlling for the other predictor
# Compute adjusted degC while preserving species-level variation
# net_clean$Adj_degC_Estimate1 <- (ols_slope_estimate * net_clean$estimate) + residuals(ols_model_adjusted)
# net_clean$Adj_degC_Ngen1 <- (ols_slope_ngen * (net_clean$ngen - 1)) + residuals(ols_model_adjusted)
# net_clean$Residual_Variation1 <- residuals(ols_model_adjusted)
#^^^ one way to calculate. 
#VVV another way. equivalent, but more explicit because ngen_centered = 0 and estimate = 0 are specified in predict
net_clean$Adj_degC_Estimate <- predict(ols_model_adjusted, newdata = data.frame(estimate = net_clean$estimate, ngen_centered = 0)) + residuals(ols_model_adjusted)
net_clean$Adj_degC_Ngen <- predict(ols_model_adjusted, newdata = data.frame(estimate = 0, ngen_centered = net_clean$ngen_centered)) + residuals(ols_model_adjusted)
net_clean$Residual_Variation <- residuals(ols_model_adjusted)
### We're adding the total residuals for both effect plots. is this correct? or do we need get partial residuals?

# Add jitter to ngen to prevent overlap
set.seed(42)
net_clean$Jittered_Ngen <- jitter(net_clean$ngen, amount = 0.15)

# Generate regression lines data using correct centering
estimate_seq <- seq(min(net_clean$estimate), max(net_clean$estimate), length.out = 100)
ngen_seq <- seq(min(net_clean$ngen), max(net_clean$ngen), length.out = 100)

regression_line_estimate <- data.frame(
  estimate = estimate_seq,
  predicted_degC = ols_slope_estimate * estimate_seq
)

regression_line_ngen <- data.frame(
  ngen = ngen_seq,
  predicted_degC = ols_slope_ngen * (ngen_seq - 1)
)

# Plot Effect of Estimate on Adjusted degC (Holding ngen = 1, with residuals)
p1 <- ggplot(net_clean, aes(x = estimate, y = Adj_degC_Estimate)) +
  geom_line(data = regression_line_estimate, aes(x = estimate, y = predicted_degC), 
            color = "#67a9cf", linewidth = 1.5, alpha = 1) +
  geom_point(size = 3, alpha = 0.7, color = "#7F7F7F", stroke = 0) +
  geom_errorbar(aes(ymin = Adj_degC_Estimate - degC.se, ymax = Adj_degC_Estimate + degC.se), 
                width = 0, alpha = 0.7, lwd = 0.3) +
  geom_errorbar(aes(xmin = estimate - SE, xmax = estimate + SE), width = 0, alpha = 0.7, lwd = 0.3) +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]),
                           fontface = "italic", size = 3, lineheight = 0.75) +
  scale_x_continuous(labels = ~ paste0(round(100 * (exp(.x) - 1), 0), "%"), breaks = myticks2) +
  
  labs(x = "Change in population size (2014-2023)", 
       y = "Change in bleaching threshold (°C)\n(adjusted for symbiont genera = 1)") +
  theme_classic()

# Plot Effect of Ngen on Adjusted degC (Holding estimate = 0, with residuals)
p2 <- ggplot(net_clean, aes(x = Jittered_Ngen, y = Adj_degC_Ngen)) +
  geom_line(data = regression_line_ngen, aes(x = ngen, y = predicted_degC), 
            color = "#ef8a62", linewidth = 1.5, alpha = 1) +
  geom_point(size = 3, alpha = 0.7, color = "#7F7F7F", stroke = 0) +
  geom_errorbar(aes(ymin = Adj_degC_Ngen - degC.se, ymax = Adj_degC_Ngen + degC.se), 
                width = 0, alpha = 0.7, lwd = 0.3) +
  ggrepel::geom_text_repel(aes(label = abbrev_names[as.character(Species)]),
                           fontface = "italic", size = 3, lineheight = 0.75) +
  labs(x = "Number of symbiont genera", 
       y = "Change in bleaching threshold (°C)\n(adjusted for density change = 0)") +
  scale_size_continuous(range = c(2, 5)) +
  theme_classic()

ps <- cowplot::plot_grid(p1, p2, nrow = 1, labels = c("B", "C"))

s7 <- cowplot::plot_grid(decomp, ps, nrow = 2, rel_heights = c(0.55, 0.45), labels = "A")
s7
ggsave(filename = "figures/FigS7.png", plot = s7, width = 190, height = 200, units = "mm")



# Add statistical info to Fig5
# Extract coefficients and p-values for plotting
estimate_coef <- round(summary_ols$coefficients["estimate", "Estimate"], 3)
estimate_pval <- signif(summary_ols$coefficients["estimate", "Pr(>|t|)"], 3)
ngen_coef <- round(summary_ols$coefficients["ngen_centered", "Estimate"], 3)
ngen_pval <- signif(summary_ols$coefficients["ngen_centered", "Pr(>|t|)"], 3)
r2_value <- round(summary_ols$r.squared, 3)

# ✅ Define annotation text
stat_text <- paste0(
  "Population Effect: ", "p = ", estimate_pval, "\n",
  "Symbiont Effect: ", "p = ", ngen_pval, "\n",
  "R² = ", r2_value
)

# ✅ Add right-aligned annotations in the top-right corner
(fig5 <- dens_sym_viz +
  annotate("text", 
           x = max(net$estimate + net$SE), y = max(PBfit$degC),  # Top-right corner
           label = stat_text, 
           hjust = 1, vjust = 1,  # Right-align text
           size = 2.5))

ggsave(filename = "figures/Fig5.png", plot = fig5,
       width = 110, height = 100, units = "mm")
```

# Size diffs

## 2023 - probability at 15 DHWs

```{r size_effects_2023}
# Model bleaching severity by Width, species, and dhw. 
# There are some corals with Width < 4 -- these were included because Height should have been at least 4. In these cases change Width to 4.
df23.abund <- df23.abund %>%
  mutate(Width2 = case_when(Width >= 4 ~ Width,
                            Width < 4 ~ 4)) %>%
  droplevels()

# Fit model
mod <- glmer(Bleaching2 > 1 ~ Species * Width2 * dhw + Week2 + (1|Subregion), 
             family = "binomial", data = df23.abund,
             nAGQ = 0, control = glmerControl(optimizer = "nloptwrap"), verbose = FALSE)

# Test for significant effect of width for each species at DHW = 15
res <- emtrends(mod, specs = c("Species", "dhw"), var = "Width2", 
                at = list(dhw = 15))

# Get significant species
sig <- as.tibble(summary(res, infer = TRUE)) %>%
  filter(p.value < 0.01)

# Get fitted values for bleaching probability as a function of size for significant species
pred0 <- as.tibble(emmeans(mod, specs = c("Width2", "dhw"), by = "Species", 
                          at = list(Width2 = seq(4,500,1), dhw = 15), 
                          type = "response", rg.limit = 103000)) 
pred <- pred0 %>%
  filter(Species %in% sig$Species) %>%
  left_join(dplyr::select(sig, dhw, Species, asymp.LCL), by = c("dhw", "Species"))

# Get actual observed size ranges for these species
actual <- filter(df23.abund) %>%
  drop_na(Species) %>%
  group_by(Species) %>%
  summarize(min = min(Width2, na.rm = T), max = max(Width2, na.rm = T)) %>%
  mutate(ad = map(max, ~expand_grid(Width2 = seq(4, ., 1)))) %>%
  unnest(ad)
pred2 <- pred %>%
  semi_join(actual, by = c("Species", "Width2"))
  
# Get species full names for plotting
mynames <- pred2 %>%
  left_join(tibble(name = abbrev_names, Species = names(abbrev_names))) %>%
  group_by(Species, name) %>%
  summarize(maxw = max(Width2)) %>%
  distinct(Species, name, maxw)

# Calculate relative risk of large (90th percentile) and small (4cm) colonies of each species
p90 <- actual %>%
  group_by(Species) %>%
  summarize(Width2 = round(quantile(Width2, 0.90))) %>%
  bind_rows(filter(actual, Width2 == 4)) %>%
  filter(Species %in% sig$Species)
p90andsmall <- pred2 %>%
  right_join(p90, by = c("Species", "Width2"))
RR <- p90andsmall %>%
  group_by(Species) %>%
  summarize(max = max(response),
            RR = max(response) / response[Width2 == 4]) %>%
  inner_join(p90 %>% filter(Width2 != 4), by = "Species")


# Plot fitted probabilities within the range of observed Widths for each significant species
(sizeplot <- ggplot(pred2, aes(x = Width2, y = response, group = Species)) +
  coord_trans(x = "log") +
  scale_x_continuous(breaks = c(4, 16, 64, 256), expand = expansion(mult = c(0.05, 0.1))) +
  facet_wrap(~Species, scales = "free_x", labeller = labeller(Species = abbrev_names)) +
  geom_line(aes(color = response)) +
  geom_text(aes(x = Width2, y = max.x - 0.2, label = paste0(round(RR, 1), "x")), data = RR, 
            hjust = 0.5, fontface = "italic") +
  scale_color_gradient2(low = "forestgreen", mid = "yellow", high = "firebrick1", 
                        limits = c(0, 1), midpoint = 0.5) +
  geom_ribbon(aes(ymin = asymp.LCL.x, ymax = asymp.UCL), alpha = 0.1, lwd = 0) +
  geom_text(data = mynames, aes(label = name, x = maxw), y = 0, hjust = 1, vjust = 0, size = 3, fontface = "italic") +
  #geom_errorbar(aes(ymin = response - SE, ymax = response + SE)) +
  ylim(0, 1) +
  labs(x = "Colony width (cm)", y = "Probability of bleaching at 15 DHWs") +
  theme_classic() +
  theme(legend.position = "none",
        strip.text = element_blank(),
        strip.background = element_blank()))

ggsave(filename = "figures/FigS8.png", plot = sizeplot,
       width = 120, height = 100, units = "mm")


# Sanity checks for size effects
# Plot actual proportions binned by size class a confirmation
# filter(df23.abund) %>%
#   filter(Species %in% sig$Species) %>%
#   group_by(Species) %>%
#   mutate(Width.bin = cut(log(Width), breaks = 10)) %>%
#   ggplot(aes(x = Width.bin, fill = Bleaching2 > 1)) +
#   geom_bar(position = "fill") +
#   facet_wrap(~Species, scales = "free")
```

